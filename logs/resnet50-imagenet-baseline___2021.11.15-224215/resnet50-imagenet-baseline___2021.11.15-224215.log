2021-11-15 22:42:15,745 - Log file for this run: /home/th.nguyen/drift-encode/logs/resnet50-imagenet-baseline___2021.11.15-224215/resnet50-imagenet-baseline___2021.11.15-224215.log
2021-11-15 22:42:15,745 - Number of CPUs: 56
2021-11-15 22:42:15,935 - Number of GPUs: 6
2021-11-15 22:42:15,935 - CUDA version: 10.0.130
2021-11-15 22:42:15,937 - CUDNN version: 7603
2021-11-15 22:42:15,937 - Kernel: 5.4.0-86-generic
2021-11-15 22:42:15,937 - Python: 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) 
[GCC 7.5.0]
2021-11-15 22:42:15,938 - pip freeze: {'absl-py': '0.12.0', 'aiohttp': '3.7.4.post0', 'argon2-cffi': '21.1.0', 'astor': '0.8.1', 'astunparse': '1.6.3', 'async-generator': '1.10', 'async-timeout': '3.0.1', 'atomicwrites': '1.4.0', 'attrs': '21.2.0', 'backcall': '0.2.0', 'black': '21.9b0', 'bleach': '4.1.0', 'blessed': '1.19.0', 'blessings': '1.7', 'blinker': '1.4', 'bqplot': '0.11.5', 'brotlipy': '0.7.0', 'cachetools': '4.2.2', 'certifi': '2020.12.5', 'cffi': '1.14.6', 'chardet': '4.0.0', 'charset-normalizer': '2.0.4', 'click': '8.0.1', 'coverage': '5.5', 'cryptography': '3.4.7', 'cycler': '0.10.0', 'cython': '0.29.24', 'dataclasses': '0.8', 'decorator': '5.1.0', 'defusedxml': '0.7.1', 'distiller': '0.4.0rc0', 'entrypoints': '0.3', 'gast': '0.2.2', 'gitdb': '4.0.9', 'gitdb2': '3.0.3.post1', 'gitpython': '3.1.0', 'google-auth': '1.30.1', 'google-auth-oauthlib': '0.4.4', 'google-pasta': '0.2.0', 'gpustat': '1.0.0.dev1', 'graphviz': '0.10.1', 'grpcio': '1.38.0', 'gym': '0.12.5', 'h5py': '2.10.0', 'idna': '2.10', 'idna-ssl': '1.1.0', 'importlib-metadata': '4.8.1', 'ipykernel': '5.5.6', 'ipython': '7.16.1', 'ipython-genutils': '0.2.0', 'ipywidgets': '7.4.2', 'jedi': '0.17.2', 'jinja2': '3.0.2', 'joblib': '1.1.0', 'jsonpatch': '1.32', 'jsonpointer': '2.1', 'jsonschema': '3.2.0', 'jupyter': '1.0.0', 'jupyter-client': '7.0.6', 'jupyter-console': '6.4.0', 'jupyter-core': '4.8.1', 'jupyterlab-pygments': '0.1.2', 'keras-applications': '1.0.8', 'keras-preprocessing': '1.1.2', 'kiwisolver': '1.3.1', 'markdown': '3.3.4', 'markupsafe': '2.0.1', 'matplotlib': '3.3.4', 'mistune': '0.8.4', 'mkl-fft': '1.3.0', 'mkl-random': '1.1.1', 'mkl-service': '2.3.0', 'more-itertools': '8.10.0', 'multidict': '5.1.0', 'munch': '2.5.0', 'mypy-extensions': '0.4.3', 'nbclient': '0.5.4', 'nbconvert': '6.0.7', 'nbformat': '5.1.3', 'nest-asyncio': '1.5.1', 'notebook': '6.4.4', 'numpy': '1.18.5', 'nvidia-ml-py3': '7.352.0', 'oauthlib': '3.1.0', 'olefile': '0.46', 'opt-einsum': '3.3.0', 'packaging': '21.0', 'pandas': '1.1.5', 'pandocfilters': '1.5.0', 'parse': '1.19.0', 'parso': '0.7.1', 'pathspec': '0.9.0', 'pexpect': '4.8.0', 'pickle5': '0.0.11', 'pickleshare': '0.7.5', 'pillow': '6.2.2', 'pip': '21.2.2', 'platformdirs': '2.4.0', 'pluggy': '0.13.1', 'pretrainedmodels': '0.7.4', 'prometheus-client': '0.11.0', 'prompt-toolkit': '3.0.20', 'protobuf': '3.17.1', 'psutil': '5.8.0', 'ptyprocess': '0.7.0', 'py': '1.10.0', 'pyasn1': '0.4.8', 'pyasn1-modules': '0.2.8', 'pycparser': '2.20', 'pydot': '1.4.1', 'pyglet': '1.5.21', 'pygments': '2.10.0', 'pyjwt': '2.1.0', 'pyopenssl': '20.0.1', 'pyparsing': '2.4.7', 'pyrsistent': '0.18.0', 'pysocks': '1.7.1', 'pytest': '4.6.11', 'python-dateutil': '2.8.2', 'python-jsonrpc-server': '0.4.0', 'python-language-server': '0.36.2', 'pytz': '2021.3', 'pyyaml': '6.0', 'pyzmq': '22.3.0', 'qgrid': '1.1.1', 'qtconsole': '5.1.1', 'qtpy': '1.11.2', 'ranger-fm': '1.9.3', 'regex': '2021.10.21', 'requests': '2.25.1', 'requests-oauthlib': '1.3.0', 'rsa': '4.7.2', 'scikit-learn': '0.21.2', 'scipy': '1.5.4', 'seaborn': '0.11.2', 'send2trash': '1.8.0', 'setuptools': '57.0.0', 'six': '1.16.0', 'smmap': '4.0.0', 'smmap2': '2.0.5', 'tabulate': '0.8.3', 'tensorboard': '1.15.0', 'tensorboard-data-server': '0.6.1', 'tensorboard-plugin-wit': '1.8.0', 'tensorflow': '1.15.0', 'tensorflow-estimator': '1.15.1', 'termcolor': '1.1.0', 'terminado': '0.12.1', 'testpath': '0.5.0', 'timm': '0.4.9', 'tomli': '1.2.1', 'torch': '1.3.1', 'torchfile': '0.1.0', 'torchnet': '0.0.4', 'torchsummary': '1.5.1', 'torchvision': '0.4.2', 'tornado': '6.1', 'tqdm': '4.33.0', 'traitlets': '4.3.3', 'traittypes': '0.2.1', 'typed-ast': '1.4.3', 'typing-extensions': '3.10.0.1', 'ujson': '4.1.0', 'urllib3': '1.26.4', 'visdom': '0.1.8.9', 'wcwidth': '0.2.5', 'webencodings': '0.5.1', 'websocket-client': '1.2.1', 'werkzeug': '2.0.1', 'wheel': '0.36.2', 'widgetsnbextension': '3.4.2', 'wrapt': '1.12.1', 'xlsxwriter': '3.0.1', 'yarl': '1.6.3', 'zipp': '3.5.0'}
2021-11-15 22:42:16,027 - Git is dirty
2021-11-15 22:42:16,028 - Active Git branch: master
2021-11-15 22:42:16,072 - Git commit: f401db9403c1608e10258733e013b6c087e3ef34
2021-11-15 22:42:16,072 - Command line: compress_classifier.py --arch resnet50 -p 10 -j 22 /home/imagenet/ --pretrained --run --qe-config-file ./conf/resnet50_conf.yaml --gpus 3 --name resnet50-imagenet-baseline --method baseline --mlc 8 --num_bits 8 --save_data
2021-11-15 22:42:16,073 - Distiller: 0.4.0rc0
2021-11-15 22:42:16,075 - Random seed: 41491
2021-11-15 22:42:16,734 - => created a pretrained resnet50 model with the imagenet dataset
2021-11-15 22:42:19,393 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2021-11-15 22:42:19,395 - Optimizer Args: {'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.0001, 'nesterov': False}
2021-11-15 22:42:19,589 - Dataset sizes:
	test=50000
2021-11-15 22:42:19,590 - Reading configuration from: ./conf/resnet50_conf.yaml
2021-11-15 22:42:19,596 - Found component of class PostTrainLinearQuantizer: Name: post_train_quantizer ; Section: quantizers
2021-11-15 22:42:19,598 - Loading activation stats from: ./quant_stats/resnet50.yaml
2021-11-15 22:42:20,209 - Preparing model for quantization using PostTrainLinearQuantizer
2021-11-15 22:42:22,674 - Applying batch-norm folding ahead of post-training quantization
2021-11-15 22:42:22,675 - Fusing sequence ['module.conv1', 'module.bn1']
2021-11-15 22:42:22,676 - Fusing sequence ['module.layer1.0.conv1', 'module.layer1.0.bn1']
2021-11-15 22:42:22,677 - Fusing sequence ['module.layer1.0.conv2', 'module.layer1.0.bn2']
2021-11-15 22:42:22,677 - Fusing sequence ['module.layer1.0.conv3', 'module.layer1.0.bn3']
2021-11-15 22:42:22,677 - Fusing sequence ['module.layer1.0.downsample.0', 'module.layer1.0.downsample.1']
2021-11-15 22:42:22,678 - Fusing sequence ['module.layer1.1.conv1', 'module.layer1.1.bn1']
2021-11-15 22:42:22,678 - Fusing sequence ['module.layer1.1.conv2', 'module.layer1.1.bn2']
2021-11-15 22:42:22,678 - Fusing sequence ['module.layer1.1.conv3', 'module.layer1.1.bn3']
2021-11-15 22:42:22,679 - Fusing sequence ['module.layer1.2.conv1', 'module.layer1.2.bn1']
2021-11-15 22:42:22,679 - Fusing sequence ['module.layer1.2.conv2', 'module.layer1.2.bn2']
2021-11-15 22:42:22,679 - Fusing sequence ['module.layer1.2.conv3', 'module.layer1.2.bn3']
2021-11-15 22:42:22,680 - Fusing sequence ['module.layer2.0.conv1', 'module.layer2.0.bn1']
2021-11-15 22:42:22,680 - Fusing sequence ['module.layer2.0.conv2', 'module.layer2.0.bn2']
2021-11-15 22:42:22,680 - Fusing sequence ['module.layer2.0.conv3', 'module.layer2.0.bn3']
2021-11-15 22:42:22,681 - Fusing sequence ['module.layer2.0.downsample.0', 'module.layer2.0.downsample.1']
2021-11-15 22:42:22,681 - Fusing sequence ['module.layer2.1.conv1', 'module.layer2.1.bn1']
2021-11-15 22:42:22,681 - Fusing sequence ['module.layer2.1.conv2', 'module.layer2.1.bn2']
2021-11-15 22:42:22,681 - Fusing sequence ['module.layer2.1.conv3', 'module.layer2.1.bn3']
2021-11-15 22:42:22,682 - Fusing sequence ['module.layer2.2.conv1', 'module.layer2.2.bn1']
2021-11-15 22:42:22,682 - Fusing sequence ['module.layer2.2.conv2', 'module.layer2.2.bn2']
2021-11-15 22:42:22,682 - Fusing sequence ['module.layer2.2.conv3', 'module.layer2.2.bn3']
2021-11-15 22:42:22,683 - Fusing sequence ['module.layer2.3.conv1', 'module.layer2.3.bn1']
2021-11-15 22:42:22,683 - Fusing sequence ['module.layer2.3.conv2', 'module.layer2.3.bn2']
2021-11-15 22:42:22,683 - Fusing sequence ['module.layer2.3.conv3', 'module.layer2.3.bn3']
2021-11-15 22:42:22,684 - Fusing sequence ['module.layer3.0.conv1', 'module.layer3.0.bn1']
2021-11-15 22:42:22,684 - Fusing sequence ['module.layer3.0.conv2', 'module.layer3.0.bn2']
2021-11-15 22:42:22,684 - Fusing sequence ['module.layer3.0.conv3', 'module.layer3.0.bn3']
2021-11-15 22:42:22,685 - Fusing sequence ['module.layer3.0.downsample.0', 'module.layer3.0.downsample.1']
2021-11-15 22:42:22,685 - Fusing sequence ['module.layer3.1.conv1', 'module.layer3.1.bn1']
2021-11-15 22:42:22,685 - Fusing sequence ['module.layer3.1.conv2', 'module.layer3.1.bn2']
2021-11-15 22:42:22,685 - Fusing sequence ['module.layer3.1.conv3', 'module.layer3.1.bn3']
2021-11-15 22:42:22,686 - Fusing sequence ['module.layer3.2.conv1', 'module.layer3.2.bn1']
2021-11-15 22:42:22,686 - Fusing sequence ['module.layer3.2.conv2', 'module.layer3.2.bn2']
2021-11-15 22:42:22,687 - Fusing sequence ['module.layer3.2.conv3', 'module.layer3.2.bn3']
2021-11-15 22:42:22,687 - Fusing sequence ['module.layer3.3.conv1', 'module.layer3.3.bn1']
2021-11-15 22:42:22,687 - Fusing sequence ['module.layer3.3.conv2', 'module.layer3.3.bn2']
2021-11-15 22:42:22,687 - Fusing sequence ['module.layer3.3.conv3', 'module.layer3.3.bn3']
2021-11-15 22:42:22,688 - Fusing sequence ['module.layer3.4.conv1', 'module.layer3.4.bn1']
2021-11-15 22:42:22,688 - Fusing sequence ['module.layer3.4.conv2', 'module.layer3.4.bn2']
2021-11-15 22:42:22,688 - Fusing sequence ['module.layer3.4.conv3', 'module.layer3.4.bn3']
2021-11-15 22:42:22,689 - Fusing sequence ['module.layer3.5.conv1', 'module.layer3.5.bn1']
2021-11-15 22:42:22,689 - Fusing sequence ['module.layer3.5.conv2', 'module.layer3.5.bn2']
2021-11-15 22:42:22,689 - Fusing sequence ['module.layer3.5.conv3', 'module.layer3.5.bn3']
2021-11-15 22:42:22,690 - Fusing sequence ['module.layer4.0.conv1', 'module.layer4.0.bn1']
2021-11-15 22:42:22,690 - Fusing sequence ['module.layer4.0.conv2', 'module.layer4.0.bn2']
2021-11-15 22:42:22,690 - Fusing sequence ['module.layer4.0.conv3', 'module.layer4.0.bn3']
2021-11-15 22:42:22,691 - Fusing sequence ['module.layer4.0.downsample.0', 'module.layer4.0.downsample.1']
2021-11-15 22:42:22,691 - Fusing sequence ['module.layer4.1.conv1', 'module.layer4.1.bn1']
2021-11-15 22:42:22,691 - Fusing sequence ['module.layer4.1.conv2', 'module.layer4.1.bn2']
2021-11-15 22:42:22,692 - Fusing sequence ['module.layer4.1.conv3', 'module.layer4.1.bn3']
2021-11-15 22:42:22,692 - Fusing sequence ['module.layer4.2.conv1', 'module.layer4.2.bn1']
2021-11-15 22:42:22,692 - Fusing sequence ['module.layer4.2.conv2', 'module.layer4.2.bn2']
2021-11-15 22:42:22,693 - Fusing sequence ['module.layer4.2.conv3', 'module.layer4.2.bn3']
2021-11-15 22:42:23,538 - Propagating output statistics from BN modules to folded modules
2021-11-15 22:42:23,539 -   bn1 --> module.conv1
2021-11-15 22:42:23,539 -   layer1.0.bn1 --> module.layer1.0.conv1
2021-11-15 22:42:23,539 -   layer1.0.bn2 --> module.layer1.0.conv2
2021-11-15 22:42:23,539 -   layer1.0.bn3 --> module.layer1.0.conv3
2021-11-15 22:42:23,539 -   layer1.0.downsample.1 --> module.layer1.0.downsample.0
2021-11-15 22:42:23,539 -   layer1.1.bn1 --> module.layer1.1.conv1
2021-11-15 22:42:23,539 -   layer1.1.bn2 --> module.layer1.1.conv2
2021-11-15 22:42:23,539 -   layer1.1.bn3 --> module.layer1.1.conv3
2021-11-15 22:42:23,539 -   layer1.2.bn1 --> module.layer1.2.conv1
2021-11-15 22:42:23,539 -   layer1.2.bn2 --> module.layer1.2.conv2
2021-11-15 22:42:23,539 -   layer1.2.bn3 --> module.layer1.2.conv3
2021-11-15 22:42:23,539 -   layer2.0.bn1 --> module.layer2.0.conv1
2021-11-15 22:42:23,539 -   layer2.0.bn2 --> module.layer2.0.conv2
2021-11-15 22:42:23,539 -   layer2.0.bn3 --> module.layer2.0.conv3
2021-11-15 22:42:23,540 -   layer2.0.downsample.1 --> module.layer2.0.downsample.0
2021-11-15 22:42:23,540 -   layer2.1.bn1 --> module.layer2.1.conv1
2021-11-15 22:42:23,540 -   layer2.1.bn2 --> module.layer2.1.conv2
2021-11-15 22:42:23,540 -   layer2.1.bn3 --> module.layer2.1.conv3
2021-11-15 22:42:23,540 -   layer2.2.bn1 --> module.layer2.2.conv1
2021-11-15 22:42:23,540 -   layer2.2.bn2 --> module.layer2.2.conv2
2021-11-15 22:42:23,540 -   layer2.2.bn3 --> module.layer2.2.conv3
2021-11-15 22:42:23,540 -   layer2.3.bn1 --> module.layer2.3.conv1
2021-11-15 22:42:23,540 -   layer2.3.bn2 --> module.layer2.3.conv2
2021-11-15 22:42:23,540 -   layer2.3.bn3 --> module.layer2.3.conv3
2021-11-15 22:42:23,540 -   layer3.0.bn1 --> module.layer3.0.conv1
2021-11-15 22:42:23,540 -   layer3.0.bn2 --> module.layer3.0.conv2
2021-11-15 22:42:23,540 -   layer3.0.bn3 --> module.layer3.0.conv3
2021-11-15 22:42:23,540 -   layer3.0.downsample.1 --> module.layer3.0.downsample.0
2021-11-15 22:42:23,540 -   layer3.1.bn1 --> module.layer3.1.conv1
2021-11-15 22:42:23,540 -   layer3.1.bn2 --> module.layer3.1.conv2
2021-11-15 22:42:23,540 -   layer3.1.bn3 --> module.layer3.1.conv3
2021-11-15 22:42:23,540 -   layer3.2.bn1 --> module.layer3.2.conv1
2021-11-15 22:42:23,540 -   layer3.2.bn2 --> module.layer3.2.conv2
2021-11-15 22:42:23,540 -   layer3.2.bn3 --> module.layer3.2.conv3
2021-11-15 22:42:23,540 -   layer3.3.bn1 --> module.layer3.3.conv1
2021-11-15 22:42:23,540 -   layer3.3.bn2 --> module.layer3.3.conv2
2021-11-15 22:42:23,540 -   layer3.3.bn3 --> module.layer3.3.conv3
2021-11-15 22:42:23,541 -   layer3.4.bn1 --> module.layer3.4.conv1
2021-11-15 22:42:23,541 -   layer3.4.bn2 --> module.layer3.4.conv2
2021-11-15 22:42:23,541 -   layer3.4.bn3 --> module.layer3.4.conv3
2021-11-15 22:42:23,541 -   layer3.5.bn1 --> module.layer3.5.conv1
2021-11-15 22:42:23,541 -   layer3.5.bn2 --> module.layer3.5.conv2
2021-11-15 22:42:23,541 -   layer3.5.bn3 --> module.layer3.5.conv3
2021-11-15 22:42:23,541 -   layer4.0.bn1 --> module.layer4.0.conv1
2021-11-15 22:42:23,541 -   layer4.0.bn2 --> module.layer4.0.conv2
2021-11-15 22:42:23,541 -   layer4.0.bn3 --> module.layer4.0.conv3
2021-11-15 22:42:23,541 -   layer4.0.downsample.1 --> module.layer4.0.downsample.0
2021-11-15 22:42:23,541 -   layer4.1.bn1 --> module.layer4.1.conv1
2021-11-15 22:42:23,541 -   layer4.1.bn2 --> module.layer4.1.conv2
2021-11-15 22:42:23,541 -   layer4.1.bn3 --> module.layer4.1.conv3
2021-11-15 22:42:23,541 -   layer4.2.bn1 --> module.layer4.2.conv1
2021-11-15 22:42:23,541 -   layer4.2.bn2 --> module.layer4.2.conv2
2021-11-15 22:42:23,541 -   layer4.2.bn3 --> module.layer4.2.conv3
2021-11-15 22:42:23,541 - Optimizing output statistics for modules followed by ReLU/Tanh/Sigmoid
2021-11-15 22:42:23,542 -   Module conv1 followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer1.0.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer1.0.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer1.0.add followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer1.1.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer1.1.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer1.1.add followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer1.2.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer1.2.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer1.2.add followed by Relu, updating stats
2021-11-15 22:42:23,542 -   Module layer2.0.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.0.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.0.add followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.1.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.1.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.1.add followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.2.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.2.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.2.add followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.3.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.3.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer2.3.add followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer3.0.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,543 -   Module layer3.0.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.0.add followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.1.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.1.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.1.add followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.2.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.2.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.2.add followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.3.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.3.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.3.add followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.4.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.4.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,544 -   Module layer3.4.add followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer3.5.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer3.5.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer3.5.add followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer4.0.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer4.0.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer4.0.add followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer4.1.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer4.1.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer4.1.add followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer4.2.conv1 followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer4.2.conv2 followed by Relu, updating stats
2021-11-15 22:42:23,545 -   Module layer4.2.add followed by Relu, updating stats
2021-11-15 22:42:23,723 - Updated stats saved to logs/resnet50-imagenet-baseline___2021.11.15-224215/quant_stats_after_prepare_model.yaml
2021-11-15 22:42:23,724 - Module module
2021-11-15 22:42:23,724 - 	Skipping
2021-11-15 22:42:23,726 - Module module.conv1
2021-11-15 22:42:23,726 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,726 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,728 - Module module.relu
2021-11-15 22:42:23,728 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,728 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,730 - Module module.maxpool
2021-11-15 22:42:23,730 - 	Replacing: torch.nn.modules.pooling.MaxPool2d
2021-11-15 22:42:23,730 - 	With:      distiller.quantization.range_linear.RangeLinearFakeQuantWrapper
2021-11-15 22:42:23,732 - Module module.layer1
2021-11-15 22:42:23,732 - 	Skipping
2021-11-15 22:42:23,732 - Module module.layer1.0
2021-11-15 22:42:23,732 - 	Skipping
2021-11-15 22:42:23,733 - Module module.layer1.0.conv1
2021-11-15 22:42:23,733 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,733 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,735 - Module module.layer1.0.relu1
2021-11-15 22:42:23,735 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,735 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,738 - Module module.layer1.0.conv2
2021-11-15 22:42:23,738 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,738 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,739 - Module module.layer1.0.relu2
2021-11-15 22:42:23,739 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,739 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,742 - Module module.layer1.0.conv3
2021-11-15 22:42:23,742 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,742 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,743 - Module module.layer1.0.downsample
2021-11-15 22:42:23,743 - 	Skipping
2021-11-15 22:42:23,744 - Module module.layer1.0.downsample.0
2021-11-15 22:42:23,744 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,744 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,746 - Module module.layer1.0.add
2021-11-15 22:42:23,746 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,747 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,748 - Module module.layer1.0.relu3
2021-11-15 22:42:23,748 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,748 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,750 - Module module.layer1.1
2021-11-15 22:42:23,750 - 	Skipping
2021-11-15 22:42:23,751 - Module module.layer1.1.conv1
2021-11-15 22:42:23,751 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,751 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,753 - Module module.layer1.1.relu1
2021-11-15 22:42:23,753 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,753 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,755 - Module module.layer1.1.conv2
2021-11-15 22:42:23,755 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,755 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,757 - Module module.layer1.1.relu2
2021-11-15 22:42:23,757 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,757 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,760 - Module module.layer1.1.conv3
2021-11-15 22:42:23,760 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,760 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,762 - Module module.layer1.1.add
2021-11-15 22:42:23,762 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,762 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,764 - Module module.layer1.1.relu3
2021-11-15 22:42:23,764 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,764 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,765 - Module module.layer1.2
2021-11-15 22:42:23,765 - 	Skipping
2021-11-15 22:42:23,766 - Module module.layer1.2.conv1
2021-11-15 22:42:23,766 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,766 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,768 - Module module.layer1.2.relu1
2021-11-15 22:42:23,768 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,768 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,770 - Module module.layer1.2.conv2
2021-11-15 22:42:23,771 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,771 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,772 - Module module.layer1.2.relu2
2021-11-15 22:42:23,772 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,772 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,775 - Module module.layer1.2.conv3
2021-11-15 22:42:23,775 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,775 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,777 - Module module.layer1.2.add
2021-11-15 22:42:23,777 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,777 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,779 - Module module.layer1.2.relu3
2021-11-15 22:42:23,779 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,779 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,780 - Module module.layer2
2021-11-15 22:42:23,780 - 	Skipping
2021-11-15 22:42:23,781 - Module module.layer2.0
2021-11-15 22:42:23,781 - 	Skipping
2021-11-15 22:42:23,782 - Module module.layer2.0.conv1
2021-11-15 22:42:23,782 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,782 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,784 - Module module.layer2.0.relu1
2021-11-15 22:42:23,784 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,784 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,786 - Module module.layer2.0.conv2
2021-11-15 22:42:23,786 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,786 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,788 - Module module.layer2.0.relu2
2021-11-15 22:42:23,788 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,788 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,791 - Module module.layer2.0.conv3
2021-11-15 22:42:23,791 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,791 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,792 - Module module.layer2.0.downsample
2021-11-15 22:42:23,792 - 	Skipping
2021-11-15 22:42:23,794 - Module module.layer2.0.downsample.0
2021-11-15 22:42:23,794 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,794 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,796 - Module module.layer2.0.add
2021-11-15 22:42:23,796 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,796 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,798 - Module module.layer2.0.relu3
2021-11-15 22:42:23,798 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,798 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,799 - Module module.layer2.1
2021-11-15 22:42:23,799 - 	Skipping
2021-11-15 22:42:23,800 - Module module.layer2.1.conv1
2021-11-15 22:42:23,801 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,801 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,802 - Module module.layer2.1.relu1
2021-11-15 22:42:23,803 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,803 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,805 - Module module.layer2.1.conv2
2021-11-15 22:42:23,805 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,805 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,807 - Module module.layer2.1.relu2
2021-11-15 22:42:23,807 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,807 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,810 - Module module.layer2.1.conv3
2021-11-15 22:42:23,810 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,810 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,813 - Module module.layer2.1.add
2021-11-15 22:42:23,813 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,813 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,815 - Module module.layer2.1.relu3
2021-11-15 22:42:23,815 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,815 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,816 - Module module.layer2.2
2021-11-15 22:42:23,816 - 	Skipping
2021-11-15 22:42:23,817 - Module module.layer2.2.conv1
2021-11-15 22:42:23,818 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,818 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,820 - Module module.layer2.2.relu1
2021-11-15 22:42:23,820 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,820 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,822 - Module module.layer2.2.conv2
2021-11-15 22:42:23,822 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,822 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,825 - Module module.layer2.2.relu2
2021-11-15 22:42:23,825 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,825 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,827 - Module module.layer2.2.conv3
2021-11-15 22:42:23,828 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,828 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,830 - Module module.layer2.2.add
2021-11-15 22:42:23,830 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,830 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,832 - Module module.layer2.2.relu3
2021-11-15 22:42:23,832 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,832 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,834 - Module module.layer2.3
2021-11-15 22:42:23,834 - 	Skipping
2021-11-15 22:42:23,835 - Module module.layer2.3.conv1
2021-11-15 22:42:23,835 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,835 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,837 - Module module.layer2.3.relu1
2021-11-15 22:42:23,837 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,837 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,840 - Module module.layer2.3.conv2
2021-11-15 22:42:23,840 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,840 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,842 - Module module.layer2.3.relu2
2021-11-15 22:42:23,842 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,842 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,845 - Module module.layer2.3.conv3
2021-11-15 22:42:23,845 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,845 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,848 - Module module.layer2.3.add
2021-11-15 22:42:23,848 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,848 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,850 - Module module.layer2.3.relu3
2021-11-15 22:42:23,850 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,850 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,852 - Module module.layer3
2021-11-15 22:42:23,852 - 	Skipping
2021-11-15 22:42:23,852 - Module module.layer3.0
2021-11-15 22:42:23,852 - 	Skipping
2021-11-15 22:42:23,853 - Module module.layer3.0.conv1
2021-11-15 22:42:23,853 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,853 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,855 - Module module.layer3.0.relu1
2021-11-15 22:42:23,855 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,855 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,858 - Module module.layer3.0.conv2
2021-11-15 22:42:23,858 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,858 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,860 - Module module.layer3.0.relu2
2021-11-15 22:42:23,860 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,860 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,864 - Module module.layer3.0.conv3
2021-11-15 22:42:23,864 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,864 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,866 - Module module.layer3.0.downsample
2021-11-15 22:42:23,866 - 	Skipping
2021-11-15 22:42:23,867 - Module module.layer3.0.downsample.0
2021-11-15 22:42:23,867 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,867 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,869 - Module module.layer3.0.add
2021-11-15 22:42:23,869 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,869 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,872 - Module module.layer3.0.relu3
2021-11-15 22:42:23,872 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,872 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,874 - Module module.layer3.1
2021-11-15 22:42:23,874 - 	Skipping
2021-11-15 22:42:23,875 - Module module.layer3.1.conv1
2021-11-15 22:42:23,875 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,875 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,877 - Module module.layer3.1.relu1
2021-11-15 22:42:23,877 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,877 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,880 - Module module.layer3.1.conv2
2021-11-15 22:42:23,880 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,880 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,882 - Module module.layer3.1.relu2
2021-11-15 22:42:23,883 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,883 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,885 - Module module.layer3.1.conv3
2021-11-15 22:42:23,885 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,885 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,888 - Module module.layer3.1.add
2021-11-15 22:42:23,888 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,888 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,890 - Module module.layer3.1.relu3
2021-11-15 22:42:23,890 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,890 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,892 - Module module.layer3.2
2021-11-15 22:42:23,892 - 	Skipping
2021-11-15 22:42:23,894 - Module module.layer3.2.conv1
2021-11-15 22:42:23,894 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,894 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,896 - Module module.layer3.2.relu1
2021-11-15 22:42:23,896 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,896 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,899 - Module module.layer3.2.conv2
2021-11-15 22:42:23,899 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,899 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,902 - Module module.layer3.2.relu2
2021-11-15 22:42:23,903 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,903 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,906 - Module module.layer3.2.conv3
2021-11-15 22:42:23,906 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,906 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,908 - Module module.layer3.2.add
2021-11-15 22:42:23,908 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,908 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,911 - Module module.layer3.2.relu3
2021-11-15 22:42:23,911 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,911 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,913 - Module module.layer3.3
2021-11-15 22:42:23,913 - 	Skipping
2021-11-15 22:42:23,914 - Module module.layer3.3.conv1
2021-11-15 22:42:23,914 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,914 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,916 - Module module.layer3.3.relu1
2021-11-15 22:42:23,917 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,917 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,920 - Module module.layer3.3.conv2
2021-11-15 22:42:23,920 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,920 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,922 - Module module.layer3.3.relu2
2021-11-15 22:42:23,922 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,922 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,926 - Module module.layer3.3.conv3
2021-11-15 22:42:23,926 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,926 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,928 - Module module.layer3.3.add
2021-11-15 22:42:23,928 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,928 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,931 - Module module.layer3.3.relu3
2021-11-15 22:42:23,931 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,931 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,933 - Module module.layer3.4
2021-11-15 22:42:23,933 - 	Skipping
2021-11-15 22:42:23,934 - Module module.layer3.4.conv1
2021-11-15 22:42:23,934 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,934 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,936 - Module module.layer3.4.relu1
2021-11-15 22:42:23,936 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,936 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,939 - Module module.layer3.4.conv2
2021-11-15 22:42:23,939 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,940 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,942 - Module module.layer3.4.relu2
2021-11-15 22:42:23,942 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,942 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,945 - Module module.layer3.4.conv3
2021-11-15 22:42:23,945 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,945 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,948 - Module module.layer3.4.add
2021-11-15 22:42:23,948 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,948 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,950 - Module module.layer3.4.relu3
2021-11-15 22:42:23,950 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,950 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,953 - Module module.layer3.5
2021-11-15 22:42:23,953 - 	Skipping
2021-11-15 22:42:23,954 - Module module.layer3.5.conv1
2021-11-15 22:42:23,954 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,954 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,956 - Module module.layer3.5.relu1
2021-11-15 22:42:23,957 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,957 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,960 - Module module.layer3.5.conv2
2021-11-15 22:42:23,960 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,960 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,962 - Module module.layer3.5.relu2
2021-11-15 22:42:23,962 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,962 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,965 - Module module.layer3.5.conv3
2021-11-15 22:42:23,966 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,966 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,968 - Module module.layer3.5.add
2021-11-15 22:42:23,968 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,968 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,971 - Module module.layer3.5.relu3
2021-11-15 22:42:23,971 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,971 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,973 - Module module.layer4
2021-11-15 22:42:23,973 - 	Skipping
2021-11-15 22:42:23,973 - Module module.layer4.0
2021-11-15 22:42:23,973 - 	Skipping
2021-11-15 22:42:23,974 - Module module.layer4.0.conv1
2021-11-15 22:42:23,974 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,975 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,977 - Module module.layer4.0.relu1
2021-11-15 22:42:23,977 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,977 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,980 - Module module.layer4.0.conv2
2021-11-15 22:42:23,980 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,980 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,983 - Module module.layer4.0.relu2
2021-11-15 22:42:23,983 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,983 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,987 - Module module.layer4.0.conv3
2021-11-15 22:42:23,987 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,987 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,989 - Module module.layer4.0.downsample
2021-11-15 22:42:23,989 - 	Skipping
2021-11-15 22:42:23,990 - Module module.layer4.0.downsample.0
2021-11-15 22:42:23,990 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:23,990 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:23,994 - Module module.layer4.0.add
2021-11-15 22:42:23,994 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:23,994 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:23,996 - Module module.layer4.0.relu3
2021-11-15 22:42:23,997 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:23,997 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:23,999 - Module module.layer4.1
2021-11-15 22:42:23,999 - 	Skipping
2021-11-15 22:42:24,000 - Module module.layer4.1.conv1
2021-11-15 22:42:24,000 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:24,000 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:24,003 - Module module.layer4.1.relu1
2021-11-15 22:42:24,003 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:24,003 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:24,006 - Module module.layer4.1.conv2
2021-11-15 22:42:24,006 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:24,006 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:24,009 - Module module.layer4.1.relu2
2021-11-15 22:42:24,009 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:24,009 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:24,012 - Module module.layer4.1.conv3
2021-11-15 22:42:24,012 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:24,012 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:24,015 - Module module.layer4.1.add
2021-11-15 22:42:24,015 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:24,015 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:24,018 - Module module.layer4.1.relu3
2021-11-15 22:42:24,018 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:24,018 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:24,020 - Module module.layer4.2
2021-11-15 22:42:24,020 - 	Skipping
2021-11-15 22:42:24,022 - Module module.layer4.2.conv1
2021-11-15 22:42:24,022 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:24,022 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:24,024 - Module module.layer4.2.relu1
2021-11-15 22:42:24,025 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:24,025 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:24,028 - Module module.layer4.2.conv2
2021-11-15 22:42:24,028 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:24,028 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:24,031 - Module module.layer4.2.relu2
2021-11-15 22:42:24,031 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:24,031 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:24,034 - Module module.layer4.2.conv3
2021-11-15 22:42:24,034 - 	Replacing: torch.nn.modules.conv.Conv2d
2021-11-15 22:42:24,034 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:24,037 - Module module.layer4.2.add
2021-11-15 22:42:24,037 - 	Replacing: distiller.modules.eltwise.EltwiseAdd
2021-11-15 22:42:24,037 - 	With:      distiller.quantization.range_linear.RangeLinearQuantEltwiseAddWrapper
2021-11-15 22:42:24,040 - Module module.layer4.2.relu3
2021-11-15 22:42:24,040 - 	Replacing: torch.nn.modules.activation.ReLU
2021-11-15 22:42:24,040 - 	With:      torch.nn.modules.linear.Identity
2021-11-15 22:42:24,043 - Module module.avgpool
2021-11-15 22:42:24,043 - 	Replacing: torch.nn.modules.pooling.AdaptiveAvgPool2d
2021-11-15 22:42:24,043 - 	With:      distiller.quantization.range_linear.RangeLinearFakeQuantWrapper
2021-11-15 22:42:24,046 - Module module.fc
2021-11-15 22:42:24,047 - 	Replacing: torch.nn.modules.linear.Linear
2021-11-15 22:42:24,047 - 	With:      distiller.quantization.range_linear.RangeLinearQuantParamLayerWrapper
2021-11-15 22:42:24,050 - Parameter 'module.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,050 - Parameter 'module.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,050 - Parameter 'module.layer1.0.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,050 - Parameter 'module.layer1.0.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,050 - Parameter 'module.layer1.0.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.0.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.0.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.0.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.0.downsample.0.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.0.downsample.0.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.1.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.1.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.1.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.1.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.1.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.1.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.2.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.2.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.2.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.2.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.2.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,051 - Parameter 'module.layer1.2.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.0.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.0.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.0.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.0.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.0.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.0.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.0.downsample.0.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.0.downsample.0.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.1.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.1.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.1.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.1.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.1.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.1.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.2.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.2.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.2.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.2.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.2.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.2.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,052 - Parameter 'module.layer2.3.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer2.3.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer2.3.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer2.3.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer2.3.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer2.3.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.0.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.0.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.0.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.0.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.0.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.0.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.0.downsample.0.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.0.downsample.0.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.1.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.1.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.1.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,053 - Parameter 'module.layer3.1.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.1.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.1.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.2.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.2.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.2.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.2.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.2.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.2.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.3.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.3.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.3.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.3.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.3.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.3.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.4.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.4.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.4.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.4.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.4.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,054 - Parameter 'module.layer3.4.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer3.5.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer3.5.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer3.5.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer3.5.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer3.5.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer3.5.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.0.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.0.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.0.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.0.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.0.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.0.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.0.downsample.0.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.0.downsample.0.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.1.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.1.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.1.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,055 - Parameter 'module.layer4.1.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,056 - Parameter 'module.layer4.1.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,056 - Parameter 'module.layer4.1.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,056 - Parameter 'module.layer4.2.conv1.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,056 - Parameter 'module.layer4.2.conv1.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,056 - Parameter 'module.layer4.2.conv2.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,056 - Parameter 'module.layer4.2.conv2.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,056 - Parameter 'module.layer4.2.conv3.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,056 - Parameter 'module.layer4.2.conv3.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,056 - Parameter 'module.fc.wrapped_module.weight' will be quantized to 8 bits
2021-11-15 22:42:24,056 - Parameter 'module.fc.wrapped_module.bias' will be quantized to 32 bits
2021-11-15 22:42:24,072 - Quantized model:

DataParallel(
  (module): ResNet(
    (conv1): RangeLinearQuantParamLayerWrapper(
      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
      accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
      scale_approx_mult_bits=None
      preset_activation_stats=True
        output_scale=76.314362, output_zero_point=0.000000
      weights_scale=309.716522, weights_zero_point=-153.000000
      (wrapped_module): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
    )
    (bn1): Identity()
    (relu): Identity()
    (maxpool): RangeLinearFakeQuantWrapper(
      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
      accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
      scale_approx_mult_bits=None
      preset_activation_stats=True
        output_scale=76.314369, output_zero_point=0.000000
      wrapped_module_float_dtype=torch.float32.
      (wrapped_module): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
    (layer1): Sequential(
      (0): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=202.452362, output_zero_point=0.000000
          weights_scale=192.523788, weights_zero_point=-165.000000
          (wrapped_module): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=149.640030, output_zero_point=0.000000
          weights_scale=335.675415, weights_zero_point=-111.000000
          (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=93.623878, output_zero_point=-116.000000
          weights_scale=132.834869, weights_zero_point=-104.000000
          (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (downsample): Sequential(
          (0): RangeLinearQuantParamLayerWrapper(
            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
            scale_approx_mult_bits=None
            preset_activation_stats=True
              output_scale=54.578442, output_zero_point=-145.000000
            weights_scale=91.953682, weights_zero_point=-123.000000
            (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): Identity()
        )
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=112.423798, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (1): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=190.108200, output_zero_point=0.000000
          weights_scale=326.063599, weights_zero_point=-92.000000
          (wrapped_module): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=134.566086, output_zero_point=0.000000
          weights_scale=217.689285, weights_zero_point=-108.000000
          (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=103.417084, output_zero_point=-128.000000
          weights_scale=127.874222, weights_zero_point=-127.000000
          (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=93.685059, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (2): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=188.027359, output_zero_point=0.000000
          weights_scale=393.401642, weights_zero_point=-141.000000
          (wrapped_module): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=113.214050, output_zero_point=0.000000
          weights_scale=200.475327, weights_zero_point=-69.000000
          (wrapped_module): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=69.077072, output_zero_point=-138.000000
          weights_scale=126.852081, weights_zero_point=-120.000000
          (wrapped_module): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=95.319214, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
    )
    (layer2): Sequential(
      (0): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=115.523026, output_zero_point=0.000000
          weights_scale=245.739792, weights_zero_point=-102.000000
          (wrapped_module): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=171.919067, output_zero_point=0.000000
          weights_scale=347.482300, weights_zero_point=-168.000000
          (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=66.666504, output_zero_point=-113.000000
          weights_scale=97.182014, weights_zero_point=-106.000000
          (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (downsample): Sequential(
          (0): RangeLinearQuantParamLayerWrapper(
            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
            scale_approx_mult_bits=None
            preset_activation_stats=True
              output_scale=90.857582, output_zero_point=-114.000000
            weights_scale=166.199631, weights_zero_point=-117.000000
            (wrapped_module): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
          )
          (1): Identity()
        )
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=114.899010, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (1): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=331.259308, output_zero_point=0.000000
          weights_scale=657.691895, weights_zero_point=-87.000000
          (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=192.341324, output_zero_point=0.000000
          weights_scale=255.814560, weights_zero_point=-105.000000
          (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=64.800430, output_zero_point=-114.000000
          weights_scale=126.008141, weights_zero_point=-123.000000
          (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=86.104538, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (2): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=209.841064, output_zero_point=0.000000
          weights_scale=525.140442, weights_zero_point=-128.000000
          (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=227.464676, output_zero_point=0.000000
          weights_scale=355.190155, weights_zero_point=-97.000000
          (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=92.014252, output_zero_point=-131.000000
          weights_scale=134.780914, weights_zero_point=-111.000000
          (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=81.861839, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (3): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=191.900879, output_zero_point=0.000000
          weights_scale=456.028473, weights_zero_point=-86.000000
          (wrapped_module): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=197.868942, output_zero_point=0.000000
          weights_scale=357.245514, weights_zero_point=-137.000000
          (wrapped_module): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=94.590790, output_zero_point=-125.000000
          weights_scale=120.772308, weights_zero_point=-95.000000
          (wrapped_module): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=80.790489, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
    )
    (layer3): Sequential(
      (0): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=112.272530, output_zero_point=0.000000
          weights_scale=263.541260, weights_zero_point=-109.000000
          (wrapped_module): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=194.774536, output_zero_point=0.000000
          weights_scale=482.902527, weights_zero_point=-132.000000
          (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=82.143326, output_zero_point=-112.000000
          weights_scale=135.952927, weights_zero_point=-130.000000
          (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (downsample): Sequential(
          (0): RangeLinearQuantParamLayerWrapper(
            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
            scale_approx_mult_bits=None
            preset_activation_stats=True
              output_scale=115.818336, output_zero_point=-119.000000
            weights_scale=242.965057, weights_zero_point=-134.000000
            (wrapped_module): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))
          )
          (1): Identity()
        )
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=127.171211, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (1): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=165.146164, output_zero_point=0.000000
          weights_scale=421.759155, weights_zero_point=-92.000000
          (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=219.473846, output_zero_point=0.000000
          weights_scale=417.351227, weights_zero_point=-101.000000
          (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=74.461113, output_zero_point=-124.000000
          weights_scale=93.775642, weights_zero_point=-126.000000
          (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=97.407700, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (2): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=219.130310, output_zero_point=0.000000
          weights_scale=438.512848, weights_zero_point=-85.000000
          (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=274.205719, output_zero_point=0.000000
          weights_scale=433.063385, weights_zero_point=-127.000000
          (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=126.801300, output_zero_point=-130.000000
          weights_scale=142.829025, weights_zero_point=-121.000000
          (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=102.290245, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (3): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=197.905746, output_zero_point=0.000000
          weights_scale=401.145142, weights_zero_point=-116.000000
          (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=252.665329, output_zero_point=0.000000
          weights_scale=378.823639, weights_zero_point=-91.000000
          (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=92.691887, output_zero_point=-130.000000
          weights_scale=106.624992, weights_zero_point=-83.000000
          (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=89.601845, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (4): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=196.544342, output_zero_point=0.000000
          weights_scale=389.477478, weights_zero_point=-92.000000
          (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=242.208862, output_zero_point=0.000000
          weights_scale=379.009308, weights_zero_point=-79.000000
          (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=107.356262, output_zero_point=-138.000000
          weights_scale=83.625671, weights_zero_point=-104.000000
          (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=87.914017, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (5): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=161.216522, output_zero_point=0.000000
          weights_scale=375.412018, weights_zero_point=-112.000000
          (wrapped_module): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=160.947433, output_zero_point=0.000000
          weights_scale=336.583344, weights_zero_point=-108.000000
          (wrapped_module): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=84.507507, output_zero_point=-152.000000
          weights_scale=116.734207, weights_zero_point=-104.000000
          (wrapped_module): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=109.208725, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
    )
    (layer4): Sequential(
      (0): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=149.072815, output_zero_point=0.000000
          weights_scale=286.792725, weights_zero_point=-97.000000
          (wrapped_module): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=163.396027, output_zero_point=0.000000
          weights_scale=324.073486, weights_zero_point=-120.000000
          (wrapped_module): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=36.546757, output_zero_point=-99.000000
          weights_scale=48.860126, weights_zero_point=-91.000000
          (wrapped_module): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (downsample): Sequential(
          (0): RangeLinearQuantParamLayerWrapper(
            weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
              inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
            scale_approx_mult_bits=None
            preset_activation_stats=True
              output_scale=42.311848, output_zero_point=-110.000000
            weights_scale=33.423954, weights_zero_point=-111.000000
            (wrapped_module): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))
          )
          (1): Identity()
        )
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=41.802349, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (1): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=189.979401, output_zero_point=0.000000
          weights_scale=1021.163513, weights_zero_point=-100.000000
          (wrapped_module): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=243.201523, output_zero_point=0.000000
          weights_scale=431.719666, weights_zero_point=-139.000000
          (wrapped_module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=43.842846, output_zero_point=-106.000000
          weights_scale=47.366165, weights_zero_point=-95.000000
          (wrapped_module): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=33.071167, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
      (2): DistillerBottleneck(
        (conv1): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=189.059372, output_zero_point=0.000000
          weights_scale=858.630920, weights_zero_point=-179.000000
          (wrapped_module): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn1): Identity()
        (relu1): Identity()
        (conv2): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=217.052673, output_zero_point=0.000000
          weights_scale=583.753845, weights_zero_point=-112.000000
          (wrapped_module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): Identity()
        (relu2): Identity()
        (conv3): RangeLinearQuantParamLayerWrapper(
          weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=20.011677, output_zero_point=-77.000000
          weights_scale=25.240526, weights_zero_point=-76.000000
          (wrapped_module): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn3): Identity()
        (add): RangeLinearQuantEltwiseAddWrapper(
          output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=True ; per_channel=False)
          accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
            inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
          scale_approx_mult_bits=None
          preset_activation_stats=True
            output_scale=18.665882, output_zero_point=0.000000
          (wrapped_module): EltwiseAdd()
        )
        (relu3): Identity()
      )
    )
    (avgpool): RangeLinearFakeQuantWrapper(
      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
      accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
      scale_approx_mult_bits=None
      preset_activation_stats=True
        output_scale=56.292549, output_zero_point=0.000000
      wrapped_module_float_dtype=torch.float32.
      (wrapped_module): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (fc): RangeLinearQuantParamLayerWrapper(
      weights_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
      output_quant_settings=(num_bits=8 ; quant_mode=ASYMMETRIC_UNSIGNED ; clip_mode=AVG ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
      accum_quant_settings=(num_bits=32 ; quant_mode=SYMMETRIC ; clip_mode=NONE ; clip_n_stds=None ; clip_half_range=False ; per_channel=False)
        inputs_quant_auto_fallback=True, forced_quant_settings_for_inputs=None
      scale_approx_mult_bits=None
      preset_activation_stats=True
        output_scale=11.161633, output_zero_point=-64.000000
      weights_scale=260.071014, weights_zero_point=-63.000000
      (wrapped_module): Linear(in_features=2048, out_features=1000, bias=True)
    )
  )
)

2021-11-15 22:42:24,468 - Per-layer quantization parameters saved to logs/resnet50-imagenet-baseline___2021.11.15-224215/layer_quant_params.yaml
2021-11-15 22:42:27,989 - --- test ---------------------
2021-11-15 22:42:27,989 - 50000 samples (256 per mini-batch)
2021-11-15 22:42:53,957 - Test: [   10/  195]    Loss 1.056069    Top1 72.265625    Top5 91.796875    
2021-11-15 22:43:11,680 - Test: [   20/  195]    Loss 1.044653    Top1 72.343750    Top5 91.972656    
2021-11-15 22:43:29,532 - Test: [   30/  195]    Loss 1.023642    Top1 72.799479    Top5 92.460938    
2021-11-15 22:43:47,380 - Test: [   40/  195]    Loss 1.030952    Top1 72.714844    Top5 92.324219    
2021-11-15 22:44:05,296 - Test: [   50/  195]    Loss 1.037684    Top1 72.484375    Top5 92.187500    
2021-11-15 22:44:23,386 - Test: [   60/  195]    Loss 1.044501    Top1 72.337240    Top5 92.089844    
2021-11-15 22:44:41,514 - Test: [   70/  195]    Loss 1.043344    Top1 72.427455    Top5 92.070312    
2021-11-15 22:44:59,570 - Test: [   80/  195]    Loss 1.050090    Top1 72.358398    Top5 92.016602    
2021-11-15 22:45:18,068 - Test: [   90/  195]    Loss 1.048065    Top1 72.413194    Top5 92.087674    
2021-11-15 22:45:36,469 - Test: [  100/  195]    Loss 1.049395    Top1 72.339844    Top5 92.109375    
2021-11-15 22:45:54,729 - Test: [  110/  195]    Loss 1.048949    Top1 72.407670    Top5 92.109375    
2021-11-15 22:46:12,956 - Test: [  120/  195]    Loss 1.045061    Top1 72.565104    Top5 92.174479    
2021-11-15 22:46:31,216 - Test: [  130/  195]    Loss 1.043963    Top1 72.548077    Top5 92.172476    
2021-11-15 22:46:49,387 - Test: [  140/  195]    Loss 1.043969    Top1 72.539062    Top5 92.184710    
2021-11-15 22:47:07,802 - Test: [  150/  195]    Loss 1.043382    Top1 72.502604    Top5 92.192708    
2021-11-15 22:47:26,085 - Test: [  160/  195]    Loss 1.041637    Top1 72.451172    Top5 92.189941    
2021-11-15 22:47:44,306 - Test: [  170/  195]    Loss 1.041557    Top1 72.472426    Top5 92.212776    
2021-11-15 22:48:02,564 - Test: [  180/  195]    Loss 1.042553    Top1 72.500000    Top5 92.191840    
2021-11-15 22:48:20,773 - Test: [  190/  195]    Loss 1.044391    Top1 72.419819    Top5 92.158717    
2021-11-15 22:48:32,335 - ==> Top1: 72.452    Top5: 92.194    Loss: 1.042

2021-11-15 22:48:36,157 - --- test ---------------------
2021-11-15 22:48:36,158 - 50000 samples (256 per mini-batch)
2021-11-15 22:48:57,924 - Test: [   10/  195]    Loss 1.018878    Top1 73.125000    Top5 92.343750    
2021-11-15 22:49:16,185 - Test: [   20/  195]    Loss 1.021017    Top1 73.359375    Top5 92.109375    
2021-11-15 22:49:34,583 - Test: [   30/  195]    Loss 1.032565    Top1 73.059896    Top5 92.135417    
2021-11-15 22:49:52,952 - Test: [   40/  195]    Loss 1.033444    Top1 72.617188    Top5 92.207031    
2021-11-15 22:50:11,379 - Test: [   50/  195]    Loss 1.047104    Top1 72.257812    Top5 92.046875    
2021-11-15 22:50:29,729 - Test: [   60/  195]    Loss 1.050173    Top1 72.154948    Top5 92.031250    
2021-11-15 22:50:48,291 - Test: [   70/  195]    Loss 1.055795    Top1 71.947545    Top5 91.981027    
2021-11-15 22:51:06,681 - Test: [   80/  195]    Loss 1.049319    Top1 72.065430    Top5 92.114258    
2021-11-15 22:51:25,128 - Test: [   90/  195]    Loss 1.047127    Top1 72.135417    Top5 92.144097    
2021-11-15 22:51:43,477 - Test: [  100/  195]    Loss 1.046569    Top1 72.164062    Top5 92.167969    
2021-11-15 22:52:01,999 - Test: [  110/  195]    Loss 1.043923    Top1 72.294034    Top5 92.187500    
2021-11-15 22:52:20,333 - Test: [  120/  195]    Loss 1.046827    Top1 72.216797    Top5 92.151693    
2021-11-15 22:52:38,859 - Test: [  130/  195]    Loss 1.042119    Top1 72.334736    Top5 92.220553    
2021-11-15 22:52:57,168 - Test: [  140/  195]    Loss 1.045458    Top1 72.310268    Top5 92.170759    
2021-11-15 22:53:15,644 - Test: [  150/  195]    Loss 1.047053    Top1 72.302083    Top5 92.143229    
2021-11-15 22:53:33,932 - Test: [  160/  195]    Loss 1.046001    Top1 72.280273    Top5 92.150879    
2021-11-15 22:53:52,228 - Test: [  170/  195]    Loss 1.046347    Top1 72.302390    Top5 92.146140    
2021-11-15 22:54:10,520 - Test: [  180/  195]    Loss 1.044015    Top1 72.337240    Top5 92.167969    
2021-11-15 22:54:29,008 - Test: [  190/  195]    Loss 1.041531    Top1 72.444490    Top5 92.191612    
2021-11-15 22:54:39,004 - ==> Top1: 72.452    Top5: 92.192    Loss: 1.042

2021-11-15 22:54:43,237 - --- test ---------------------
2021-11-15 22:54:43,238 - 50000 samples (256 per mini-batch)
2021-11-15 22:55:04,211 - Test: [   10/  195]    Loss 1.085772    Top1 71.796875    Top5 91.757812    
2021-11-15 22:55:22,770 - Test: [   20/  195]    Loss 1.045589    Top1 72.460938    Top5 92.324219    
2021-11-15 22:55:41,155 - Test: [   30/  195]    Loss 1.042014    Top1 72.148438    Top5 92.408854    
2021-11-15 22:55:59,621 - Test: [   40/  195]    Loss 1.045391    Top1 72.216797    Top5 92.353516    
2021-11-15 22:56:18,048 - Test: [   50/  195]    Loss 1.041562    Top1 72.320312    Top5 92.437500    
2021-11-15 22:56:36,502 - Test: [   60/  195]    Loss 1.044268    Top1 72.174479    Top5 92.363281    
2021-11-15 22:56:54,872 - Test: [   70/  195]    Loss 1.045992    Top1 72.120536    Top5 92.354911    
2021-11-15 22:57:13,513 - Test: [   80/  195]    Loss 1.051582    Top1 72.065430    Top5 92.202148    
2021-11-15 22:57:31,938 - Test: [   90/  195]    Loss 1.051440    Top1 72.109375    Top5 92.165799    
2021-11-15 22:57:50,280 - Test: [  100/  195]    Loss 1.052319    Top1 71.968750    Top5 92.199219    
2021-11-15 22:58:08,904 - Test: [  110/  195]    Loss 1.044421    Top1 72.194602    Top5 92.308239    
2021-11-15 22:58:27,480 - Test: [  120/  195]    Loss 1.046160    Top1 72.190755    Top5 92.262370    
2021-11-15 22:58:45,978 - Test: [  130/  195]    Loss 1.041961    Top1 72.334736    Top5 92.274639    
2021-11-15 22:59:04,605 - Test: [  140/  195]    Loss 1.046493    Top1 72.273996    Top5 92.218192    
2021-11-15 22:59:23,008 - Test: [  150/  195]    Loss 1.042620    Top1 72.333333    Top5 92.239583    
2021-11-15 22:59:41,357 - Test: [  160/  195]    Loss 1.044496    Top1 72.373047    Top5 92.182617    
2021-11-15 22:59:59,589 - Test: [  170/  195]    Loss 1.044335    Top1 72.433364    Top5 92.178309    
2021-11-15 23:00:18,039 - Test: [  180/  195]    Loss 1.041937    Top1 72.452257    Top5 92.224392    
2021-11-15 23:00:36,519 - Test: [  190/  195]    Loss 1.042629    Top1 72.434211    Top5 92.201891    
2021-11-15 23:00:46,513 - ==> Top1: 72.452    Top5: 92.194    Loss: 1.042

2021-11-15 23:00:50,298 - --- test ---------------------
2021-11-15 23:00:50,299 - 50000 samples (256 per mini-batch)
2021-11-15 23:01:11,785 - Test: [   10/  195]    Loss 1.050033    Top1 72.265625    Top5 92.109375    
2021-11-15 23:01:30,249 - Test: [   20/  195]    Loss 1.049098    Top1 72.578125    Top5 92.031250    
2021-11-15 23:01:48,751 - Test: [   30/  195]    Loss 1.041474    Top1 72.473958    Top5 92.161458    
2021-11-15 23:02:07,216 - Test: [   40/  195]    Loss 1.047332    Top1 72.343750    Top5 92.080078    
2021-11-15 23:02:25,683 - Test: [   50/  195]    Loss 1.056427    Top1 72.187500    Top5 92.093750    
2021-11-15 23:02:44,164 - Test: [   60/  195]    Loss 1.051233    Top1 72.233073    Top5 92.167969    
2021-11-15 23:03:02,646 - Test: [   70/  195]    Loss 1.038207    Top1 72.410714    Top5 92.349330    
2021-11-15 23:03:21,159 - Test: [   80/  195]    Loss 1.043547    Top1 72.348633    Top5 92.275391    
2021-11-15 23:03:39,555 - Test: [   90/  195]    Loss 1.041217    Top1 72.322049    Top5 92.309028    
2021-11-15 23:03:57,956 - Test: [  100/  195]    Loss 1.044193    Top1 72.316406    Top5 92.269531    
2021-11-15 23:04:16,488 - Test: [  110/  195]    Loss 1.049118    Top1 72.212358    Top5 92.173295    
2021-11-15 23:04:34,923 - Test: [  120/  195]    Loss 1.047565    Top1 72.366536    Top5 92.148438    
2021-11-15 23:04:53,313 - Test: [  130/  195]    Loss 1.047324    Top1 72.355769    Top5 92.145433    
2021-11-15 23:05:11,514 - Test: [  140/  195]    Loss 1.043465    Top1 72.416295    Top5 92.179129    
2021-11-15 23:05:29,879 - Test: [  150/  195]    Loss 1.039758    Top1 72.479167    Top5 92.247396    
2021-11-15 23:05:48,301 - Test: [  160/  195]    Loss 1.042559    Top1 72.441406    Top5 92.172852    
2021-11-15 23:06:06,859 - Test: [  170/  195]    Loss 1.042870    Top1 72.444853    Top5 92.164522    
2021-11-15 23:06:25,089 - Test: [  180/  195]    Loss 1.042862    Top1 72.378472    Top5 92.187500    
2021-11-15 23:06:43,409 - Test: [  190/  195]    Loss 1.044828    Top1 72.372533    Top5 92.164885    
2021-11-15 23:06:53,502 - ==> Top1: 72.456    Top5: 92.194    Loss: 1.042

2021-11-15 23:06:57,236 - --- test ---------------------
2021-11-15 23:06:57,237 - 50000 samples (256 per mini-batch)
2021-11-15 23:07:17,997 - Test: [   10/  195]    Loss 0.985860    Top1 73.085938    Top5 93.242188    
2021-11-15 23:07:36,424 - Test: [   20/  195]    Loss 1.008747    Top1 73.203125    Top5 92.773438    
2021-11-15 23:07:54,817 - Test: [   30/  195]    Loss 1.005150    Top1 73.372396    Top5 92.877604    
2021-11-15 23:08:13,282 - Test: [   40/  195]    Loss 1.014482    Top1 73.125000    Top5 92.646484    
2021-11-15 23:08:31,869 - Test: [   50/  195]    Loss 1.019086    Top1 72.804688    Top5 92.679688    
2021-11-15 23:08:50,289 - Test: [   60/  195]    Loss 1.026101    Top1 72.721354    Top5 92.558594    
2021-11-15 23:09:08,527 - Test: [   70/  195]    Loss 1.025522    Top1 72.739955    Top5 92.505580    
2021-11-15 23:09:27,209 - Test: [   80/  195]    Loss 1.034752    Top1 72.514648    Top5 92.480469    
2021-11-15 23:09:45,454 - Test: [   90/  195]    Loss 1.038806    Top1 72.530382    Top5 92.447917    
2021-11-15 23:10:04,116 - Test: [  100/  195]    Loss 1.050284    Top1 72.265625    Top5 92.273438    
2021-11-15 23:10:22,609 - Test: [  110/  195]    Loss 1.050715    Top1 72.240767    Top5 92.286932    
2021-11-15 23:10:41,034 - Test: [  120/  195]    Loss 1.048910    Top1 72.252604    Top5 92.304688    
2021-11-15 23:10:59,517 - Test: [  130/  195]    Loss 1.047376    Top1 72.265625    Top5 92.304688    
2021-11-15 23:11:17,841 - Test: [  140/  195]    Loss 1.044148    Top1 72.385603    Top5 92.296317    
2021-11-15 23:11:36,435 - Test: [  150/  195]    Loss 1.045090    Top1 72.351562    Top5 92.252604    
2021-11-15 23:11:54,695 - Test: [  160/  195]    Loss 1.043130    Top1 72.473145    Top5 92.238770    
2021-11-15 23:12:13,250 - Test: [  170/  195]    Loss 1.042715    Top1 72.477022    Top5 92.226562    
2021-11-15 23:12:31,585 - Test: [  180/  195]    Loss 1.044673    Top1 72.452257    Top5 92.194010    
2021-11-15 23:12:49,968 - Test: [  190/  195]    Loss 1.042583    Top1 72.430099    Top5 92.195724    
2021-11-15 23:13:00,245 - ==> Top1: 72.454    Top5: 92.194    Loss: 1.043

2021-11-15 23:13:04,945 - --- test ---------------------
2021-11-15 23:13:04,946 - 50000 samples (256 per mini-batch)
2021-11-15 23:13:26,761 - Test: [   10/  195]    Loss 1.037668    Top1 72.812500    Top5 92.031250    
2021-11-15 23:13:44,999 - Test: [   20/  195]    Loss 1.053618    Top1 72.402344    Top5 91.992188    
2021-11-15 23:14:03,668 - Test: [   30/  195]    Loss 1.053366    Top1 72.304688    Top5 91.966146    
2021-11-15 23:14:22,182 - Test: [   40/  195]    Loss 1.054939    Top1 72.119141    Top5 91.972656    
2021-11-15 23:14:40,925 - Test: [   50/  195]    Loss 1.051472    Top1 72.054687    Top5 92.078125    
2021-11-15 23:14:59,396 - Test: [   60/  195]    Loss 1.046251    Top1 72.246094    Top5 92.187500    
2021-11-15 23:15:18,007 - Test: [   70/  195]    Loss 1.047525    Top1 72.142857    Top5 92.137277    
2021-11-15 23:15:36,620 - Test: [   80/  195]    Loss 1.056650    Top1 71.958008    Top5 92.099609    
2021-11-15 23:15:55,201 - Test: [   90/  195]    Loss 1.056291    Top1 71.961806    Top5 92.074653    
2021-11-15 23:16:13,718 - Test: [  100/  195]    Loss 1.054217    Top1 72.042969    Top5 92.074219    
2021-11-15 23:16:32,214 - Test: [  110/  195]    Loss 1.048503    Top1 72.187500    Top5 92.151989    
2021-11-15 23:16:50,713 - Test: [  120/  195]    Loss 1.048832    Top1 72.203776    Top5 92.145182    
2021-11-15 23:17:09,014 - Test: [  130/  195]    Loss 1.048014    Top1 72.280649    Top5 92.106370    
2021-11-15 23:17:27,651 - Test: [  140/  195]    Loss 1.047234    Top1 72.271205    Top5 92.179129    
2021-11-15 23:17:46,051 - Test: [  150/  195]    Loss 1.046446    Top1 72.265625    Top5 92.190104    
2021-11-15 23:18:04,459 - Test: [  160/  195]    Loss 1.050080    Top1 72.216797    Top5 92.153320    
2021-11-15 23:18:22,860 - Test: [  170/  195]    Loss 1.045732    Top1 72.329963    Top5 92.210478    
2021-11-15 23:18:41,249 - Test: [  180/  195]    Loss 1.042120    Top1 72.408854    Top5 92.230903    
2021-11-15 23:18:59,762 - Test: [  190/  195]    Loss 1.041306    Top1 72.452714    Top5 92.201891    
2021-11-15 23:19:09,724 - ==> Top1: 72.454    Top5: 92.194    Loss: 1.041

2021-11-15 23:19:13,717 - --- test ---------------------
2021-11-15 23:19:13,718 - 50000 samples (256 per mini-batch)
2021-11-15 23:19:34,313 - Test: [   10/  195]    Loss 1.056674    Top1 72.929688    Top5 91.523438    
2021-11-15 23:19:52,724 - Test: [   20/  195]    Loss 1.069049    Top1 72.265625    Top5 91.992188    
2021-11-15 23:20:11,273 - Test: [   30/  195]    Loss 1.048513    Top1 72.265625    Top5 92.083333    
2021-11-15 23:20:29,606 - Test: [   40/  195]    Loss 1.050986    Top1 72.099609    Top5 92.197266    
2021-11-15 23:20:48,116 - Test: [   50/  195]    Loss 1.049836    Top1 72.007812    Top5 92.140625    
2021-11-15 23:21:06,556 - Test: [   60/  195]    Loss 1.044501    Top1 72.122396    Top5 92.343750    
2021-11-15 23:21:24,993 - Test: [   70/  195]    Loss 1.036980    Top1 72.321429    Top5 92.393973    
2021-11-15 23:21:43,315 - Test: [   80/  195]    Loss 1.040887    Top1 72.329102    Top5 92.299805    
2021-11-15 23:22:01,916 - Test: [   90/  195]    Loss 1.036544    Top1 72.517361    Top5 92.300347    
2021-11-15 23:22:20,296 - Test: [  100/  195]    Loss 1.039583    Top1 72.496094    Top5 92.281250    
2021-11-15 23:22:38,629 - Test: [  110/  195]    Loss 1.039499    Top1 72.421875    Top5 92.315341    
2021-11-15 23:22:57,167 - Test: [  120/  195]    Loss 1.039671    Top1 72.451172    Top5 92.255859    
2021-11-15 23:23:15,601 - Test: [  130/  195]    Loss 1.041011    Top1 72.515024    Top5 92.229567    
2021-11-15 23:23:33,990 - Test: [  140/  195]    Loss 1.037589    Top1 72.564174    Top5 92.265625    
2021-11-15 23:23:52,510 - Test: [  150/  195]    Loss 1.039642    Top1 72.518229    Top5 92.244792    
2021-11-15 23:24:10,892 - Test: [  160/  195]    Loss 1.042994    Top1 72.448730    Top5 92.175293    
2021-11-15 23:24:29,259 - Test: [  170/  195]    Loss 1.041293    Top1 72.460938    Top5 92.203585    
2021-11-15 23:24:47,540 - Test: [  180/  195]    Loss 1.042401    Top1 72.415365    Top5 92.174479    
2021-11-15 23:25:05,861 - Test: [  190/  195]    Loss 1.042238    Top1 72.415707    Top5 92.179276    
2021-11-15 23:25:15,886 - ==> Top1: 72.450    Top5: 92.194    Loss: 1.041

2021-11-15 23:25:19,707 - --- test ---------------------
2021-11-15 23:25:19,707 - 50000 samples (256 per mini-batch)
2021-11-15 23:25:41,107 - Test: [   10/  195]    Loss 1.050468    Top1 72.109375    Top5 91.757812    
2021-11-15 23:25:59,332 - Test: [   20/  195]    Loss 1.060973    Top1 72.441406    Top5 91.503906    
2021-11-15 23:26:17,988 - Test: [   30/  195]    Loss 1.041466    Top1 73.190104    Top5 91.901042    
2021-11-15 23:26:36,420 - Test: [   40/  195]    Loss 1.029068    Top1 73.154297    Top5 92.177734    
2021-11-15 23:26:54,969 - Test: [   50/  195]    Loss 1.036447    Top1 73.000000    Top5 92.101562    
2021-11-15 23:27:13,464 - Test: [   60/  195]    Loss 1.034121    Top1 72.936198    Top5 92.226562    
2021-11-15 23:27:32,049 - Test: [   70/  195]    Loss 1.028192    Top1 73.063616    Top5 92.293527    
2021-11-15 23:27:50,548 - Test: [   80/  195]    Loss 1.031983    Top1 72.993164    Top5 92.216797    
2021-11-15 23:28:09,053 - Test: [   90/  195]    Loss 1.041111    Top1 72.769097    Top5 92.131076    
2021-11-15 23:28:27,565 - Test: [  100/  195]    Loss 1.039636    Top1 72.746094    Top5 92.207031    
2021-11-15 23:28:46,020 - Test: [  110/  195]    Loss 1.042727    Top1 72.627841    Top5 92.151989    
2021-11-15 23:29:04,632 - Test: [  120/  195]    Loss 1.042314    Top1 72.610677    Top5 92.154948    
2021-11-15 23:29:23,115 - Test: [  130/  195]    Loss 1.043308    Top1 72.475962    Top5 92.127404    
2021-11-15 23:29:41,536 - Test: [  140/  195]    Loss 1.046229    Top1 72.393973    Top5 92.101004    
2021-11-15 23:29:59,680 - Test: [  150/  195]    Loss 1.043170    Top1 72.468750    Top5 92.111979    
2021-11-15 23:30:18,168 - Test: [  160/  195]    Loss 1.041729    Top1 72.460938    Top5 92.124023    
2021-11-15 23:30:36,435 - Test: [  170/  195]    Loss 1.045079    Top1 72.366728    Top5 92.148438    
2021-11-15 23:30:54,876 - Test: [  180/  195]    Loss 1.046377    Top1 72.400174    Top5 92.113715    
2021-11-15 23:31:13,303 - Test: [  190/  195]    Loss 1.043381    Top1 72.446546    Top5 92.164885    
2021-11-15 23:31:23,428 - ==> Top1: 72.454    Top5: 92.194    Loss: 1.043

2021-11-15 23:31:27,219 - --- test ---------------------
2021-11-15 23:31:27,219 - 50000 samples (256 per mini-batch)
2021-11-15 23:31:48,633 - Test: [   10/  195]    Loss 1.076958    Top1 71.132812    Top5 91.679688    
2021-11-15 23:32:07,076 - Test: [   20/  195]    Loss 1.086142    Top1 71.542969    Top5 91.445312    
2021-11-15 23:32:25,386 - Test: [   30/  195]    Loss 1.059103    Top1 72.382812    Top5 91.835938    
2021-11-15 23:32:43,973 - Test: [   40/  195]    Loss 1.042381    Top1 72.519531    Top5 92.089844    
2021-11-15 23:33:02,205 - Test: [   50/  195]    Loss 1.034737    Top1 72.695312    Top5 92.218750    
2021-11-15 23:33:20,665 - Test: [   60/  195]    Loss 1.043890    Top1 72.447917    Top5 92.076823    
2021-11-15 23:33:39,449 - Test: [   70/  195]    Loss 1.044790    Top1 72.527902    Top5 92.014509    
2021-11-15 23:33:57,829 - Test: [   80/  195]    Loss 1.046188    Top1 72.568359    Top5 92.041016    
2021-11-15 23:34:16,203 - Test: [   90/  195]    Loss 1.044953    Top1 72.495660    Top5 92.087674    
2021-11-15 23:34:34,832 - Test: [  100/  195]    Loss 1.048233    Top1 72.425781    Top5 92.121094    
2021-11-15 23:34:53,385 - Test: [  110/  195]    Loss 1.049630    Top1 72.294034    Top5 92.144886    
2021-11-15 23:35:11,904 - Test: [  120/  195]    Loss 1.048444    Top1 72.333984    Top5 92.187500    
2021-11-15 23:35:30,445 - Test: [  130/  195]    Loss 1.048054    Top1 72.337740    Top5 92.187500    
2021-11-15 23:35:48,832 - Test: [  140/  195]    Loss 1.045266    Top1 72.393973    Top5 92.190290    
2021-11-15 23:36:07,364 - Test: [  150/  195]    Loss 1.044924    Top1 72.445312    Top5 92.156250    
2021-11-15 23:36:25,705 - Test: [  160/  195]    Loss 1.040870    Top1 72.521973    Top5 92.197266    
2021-11-15 23:36:44,086 - Test: [  170/  195]    Loss 1.040998    Top1 72.513787    Top5 92.176011    
2021-11-15 23:37:02,510 - Test: [  180/  195]    Loss 1.040824    Top1 72.500000    Top5 92.191840    
2021-11-15 23:37:20,902 - Test: [  190/  195]    Loss 1.041342    Top1 72.485609    Top5 92.199836    
2021-11-15 23:37:30,902 - ==> Top1: 72.454    Top5: 92.194    Loss: 1.043

2021-11-15 23:37:34,678 - --- test ---------------------
2021-11-15 23:37:34,679 - 50000 samples (256 per mini-batch)
2021-11-15 23:37:55,610 - Test: [   10/  195]    Loss 1.042867    Top1 72.968750    Top5 92.187500    
2021-11-15 23:38:13,972 - Test: [   20/  195]    Loss 1.040422    Top1 72.949219    Top5 92.050781    
2021-11-15 23:38:32,390 - Test: [   30/  195]    Loss 1.040813    Top1 72.825521    Top5 92.187500    
2021-11-15 23:38:51,012 - Test: [   40/  195]    Loss 1.045368    Top1 72.587891    Top5 92.226562    
2021-11-15 23:39:09,489 - Test: [   50/  195]    Loss 1.045704    Top1 72.734375    Top5 92.070312    
2021-11-15 23:39:28,068 - Test: [   60/  195]    Loss 1.039109    Top1 72.766927    Top5 92.141927    
2021-11-15 23:39:46,726 - Test: [   70/  195]    Loss 1.035527    Top1 72.851562    Top5 92.276786    
2021-11-15 23:40:05,208 - Test: [   80/  195]    Loss 1.038982    Top1 72.758789    Top5 92.265625    
2021-11-15 23:40:23,796 - Test: [   90/  195]    Loss 1.037331    Top1 72.760417    Top5 92.213542    
2021-11-15 23:40:42,232 - Test: [  100/  195]    Loss 1.040724    Top1 72.683594    Top5 92.179688    
2021-11-15 23:41:00,816 - Test: [  110/  195]    Loss 1.036356    Top1 72.748580    Top5 92.272727    
2021-11-15 23:41:19,418 - Test: [  120/  195]    Loss 1.032419    Top1 72.766927    Top5 92.324219    
2021-11-15 23:41:37,933 - Test: [  130/  195]    Loss 1.035594    Top1 72.668269    Top5 92.274639    
2021-11-15 23:41:56,400 - Test: [  140/  195]    Loss 1.035185    Top1 72.670201    Top5 92.296317    
2021-11-15 23:42:14,854 - Test: [  150/  195]    Loss 1.034227    Top1 72.723958    Top5 92.304688    
2021-11-15 23:42:33,279 - Test: [  160/  195]    Loss 1.037834    Top1 72.673340    Top5 92.221680    
2021-11-15 23:42:51,753 - Test: [  170/  195]    Loss 1.041105    Top1 72.506893    Top5 92.201287    
2021-11-15 23:43:10,213 - Test: [  180/  195]    Loss 1.042350    Top1 72.523872    Top5 92.194010    
2021-11-15 23:43:28,546 - Test: [  190/  195]    Loss 1.043345    Top1 72.477385    Top5 92.183388    
2021-11-15 23:43:38,761 - ==> Top1: 72.450    Top5: 92.194    Loss: 1.042

2021-11-15 23:43:42,855 - --- test ---------------------
2021-11-15 23:43:42,856 - 50000 samples (256 per mini-batch)
2021-11-15 23:44:04,116 - Test: [   10/  195]    Loss 1.011557    Top1 73.984375    Top5 92.421875    
2021-11-15 23:44:22,525 - Test: [   20/  195]    Loss 1.025377    Top1 72.968750    Top5 92.597656    
2021-11-15 23:44:40,927 - Test: [   30/  195]    Loss 1.008579    Top1 73.033854    Top5 92.682292    
2021-11-15 23:44:59,461 - Test: [   40/  195]    Loss 1.018987    Top1 72.890625    Top5 92.539062    
2021-11-15 23:45:17,930 - Test: [   50/  195]    Loss 1.014705    Top1 72.812500    Top5 92.546875    
2021-11-15 23:45:36,380 - Test: [   60/  195]    Loss 1.029184    Top1 72.513021    Top5 92.363281    
2021-11-15 23:45:54,897 - Test: [   70/  195]    Loss 1.041713    Top1 72.410714    Top5 92.193080    
2021-11-15 23:46:13,420 - Test: [   80/  195]    Loss 1.039775    Top1 72.558594    Top5 92.182617    
2021-11-15 23:46:31,761 - Test: [   90/  195]    Loss 1.043561    Top1 72.447917    Top5 92.165799    
2021-11-15 23:46:50,252 - Test: [  100/  195]    Loss 1.041823    Top1 72.484375    Top5 92.207031    
2021-11-15 23:47:08,830 - Test: [  110/  195]    Loss 1.043426    Top1 72.468040    Top5 92.215909    
2021-11-15 23:47:27,176 - Test: [  120/  195]    Loss 1.042887    Top1 72.473958    Top5 92.223307    
2021-11-15 23:47:45,763 - Test: [  130/  195]    Loss 1.047448    Top1 72.337740    Top5 92.205529    
2021-11-15 23:48:04,053 - Test: [  140/  195]    Loss 1.045067    Top1 72.354911    Top5 92.204241    
2021-11-15 23:48:22,656 - Test: [  150/  195]    Loss 1.040804    Top1 72.505208    Top5 92.268229    
2021-11-15 23:48:40,996 - Test: [  160/  195]    Loss 1.040073    Top1 72.475586    Top5 92.277832    
2021-11-15 23:48:59,315 - Test: [  170/  195]    Loss 1.041422    Top1 72.454044    Top5 92.224265    
2021-11-15 23:49:17,580 - Test: [  180/  195]    Loss 1.042090    Top1 72.469618    Top5 92.202691    
2021-11-15 23:49:35,981 - Test: [  190/  195]    Loss 1.041703    Top1 72.471217    Top5 92.208059    
2021-11-15 23:49:45,867 - ==> Top1: 72.446    Top5: 92.194    Loss: 1.042

2021-11-15 23:49:49,586 - --- test ---------------------
2021-11-15 23:49:49,586 - 50000 samples (256 per mini-batch)
2021-11-15 23:50:10,419 - Test: [   10/  195]    Loss 1.023398    Top1 71.796875    Top5 92.695312    
2021-11-15 23:50:28,965 - Test: [   20/  195]    Loss 1.052176    Top1 72.109375    Top5 92.089844    
2021-11-15 23:50:47,288 - Test: [   30/  195]    Loss 1.047306    Top1 72.356771    Top5 92.148438    
2021-11-15 23:51:05,835 - Test: [   40/  195]    Loss 1.054572    Top1 71.933594    Top5 92.011719    
2021-11-15 23:51:24,313 - Test: [   50/  195]    Loss 1.056592    Top1 72.171875    Top5 91.984375    
2021-11-15 23:51:42,755 - Test: [   60/  195]    Loss 1.055257    Top1 72.200521    Top5 91.985677    
2021-11-15 23:52:00,989 - Test: [   70/  195]    Loss 1.048242    Top1 72.427455    Top5 92.014509    
2021-11-15 23:52:19,372 - Test: [   80/  195]    Loss 1.052603    Top1 72.333984    Top5 91.938477    
2021-11-15 23:52:37,729 - Test: [   90/  195]    Loss 1.047153    Top1 72.404514    Top5 92.005208    
2021-11-15 23:52:56,196 - Test: [  100/  195]    Loss 1.048832    Top1 72.367188    Top5 92.003906    
2021-11-15 23:53:14,658 - Test: [  110/  195]    Loss 1.045140    Top1 72.357955    Top5 92.045455    
2021-11-15 23:53:32,991 - Test: [  120/  195]    Loss 1.045970    Top1 72.418620    Top5 92.041016    
2021-11-15 23:53:51,275 - Test: [  130/  195]    Loss 1.042111    Top1 72.472957    Top5 92.103365    
2021-11-15 23:54:09,725 - Test: [  140/  195]    Loss 1.045109    Top1 72.380022    Top5 92.106585    
2021-11-15 23:54:28,164 - Test: [  150/  195]    Loss 1.043871    Top1 72.395833    Top5 92.135417    
2021-11-15 23:54:46,440 - Test: [  160/  195]    Loss 1.043324    Top1 72.436523    Top5 92.160645    
2021-11-15 23:55:04,805 - Test: [  170/  195]    Loss 1.044549    Top1 72.426471    Top5 92.130055    
2021-11-15 23:55:23,165 - Test: [  180/  195]    Loss 1.041772    Top1 72.491319    Top5 92.178819    
2021-11-15 23:55:41,697 - Test: [  190/  195]    Loss 1.042705    Top1 72.462993    Top5 92.183388    
2021-11-15 23:55:51,758 - ==> Top1: 72.460    Top5: 92.196    Loss: 1.042

2021-11-15 23:55:55,732 - --- test ---------------------
2021-11-15 23:55:55,732 - 50000 samples (256 per mini-batch)
2021-11-15 23:56:16,738 - Test: [   10/  195]    Loss 1.014953    Top1 72.812500    Top5 92.460938    
2021-11-15 23:56:35,094 - Test: [   20/  195]    Loss 1.060316    Top1 71.757812    Top5 92.050781    
2021-11-15 23:56:53,505 - Test: [   30/  195]    Loss 1.032089    Top1 72.460938    Top5 92.539062    
2021-11-15 23:57:12,072 - Test: [   40/  195]    Loss 1.040545    Top1 72.470703    Top5 92.460938    
2021-11-15 23:57:30,520 - Test: [   50/  195]    Loss 1.033611    Top1 72.500000    Top5 92.656250    
2021-11-15 23:57:49,089 - Test: [   60/  195]    Loss 1.040468    Top1 72.454427    Top5 92.454427    
2021-11-15 23:58:07,492 - Test: [   70/  195]    Loss 1.045761    Top1 72.338170    Top5 92.366071    
2021-11-15 23:58:25,756 - Test: [   80/  195]    Loss 1.047945    Top1 72.441406    Top5 92.255859    
2021-11-15 23:58:44,216 - Test: [   90/  195]    Loss 1.047418    Top1 72.426215    Top5 92.248264    
2021-11-15 23:59:02,493 - Test: [  100/  195]    Loss 1.045677    Top1 72.445312    Top5 92.281250    
2021-11-15 23:59:20,966 - Test: [  110/  195]    Loss 1.038987    Top1 72.581676    Top5 92.333097    
2021-11-15 23:59:39,464 - Test: [  120/  195]    Loss 1.043378    Top1 72.496745    Top5 92.236328    
2021-11-15 23:59:57,659 - Test: [  130/  195]    Loss 1.042838    Top1 72.460938    Top5 92.247596    
2021-11-16 00:00:16,228 - Test: [  140/  195]    Loss 1.042254    Top1 72.483259    Top5 92.265625    
2021-11-16 00:00:34,777 - Test: [  150/  195]    Loss 1.044278    Top1 72.502604    Top5 92.210938    
2021-11-16 00:00:53,185 - Test: [  160/  195]    Loss 1.041854    Top1 72.556152    Top5 92.238770    
2021-11-16 00:01:11,504 - Test: [  170/  195]    Loss 1.045578    Top1 72.437960    Top5 92.164522    
2021-11-16 00:01:29,888 - Test: [  180/  195]    Loss 1.045965    Top1 72.434896    Top5 92.152778    
2021-11-16 00:01:48,151 - Test: [  190/  195]    Loss 1.044809    Top1 72.430099    Top5 92.162829    
2021-11-16 00:01:58,183 - ==> Top1: 72.454    Top5: 92.194    Loss: 1.042

2021-11-16 00:02:02,151 - --- test ---------------------
2021-11-16 00:02:02,152 - 50000 samples (256 per mini-batch)
2021-11-16 00:02:24,053 - Test: [   10/  195]    Loss 1.082335    Top1 72.460938    Top5 92.226562    
2021-11-16 00:02:42,292 - Test: [   20/  195]    Loss 1.058933    Top1 72.031250    Top5 92.109375    
2021-11-16 00:03:00,794 - Test: [   30/  195]    Loss 1.059182    Top1 72.096354    Top5 91.927083    
2021-11-16 00:03:19,446 - Test: [   40/  195]    Loss 1.042159    Top1 72.031250    Top5 92.197266    
2021-11-16 00:03:37,760 - Test: [   50/  195]    Loss 1.043638    Top1 72.195312    Top5 92.156250    
2021-11-16 00:03:56,496 - Test: [   60/  195]    Loss 1.033090    Top1 72.337240    Top5 92.324219    
2021-11-16 00:04:14,931 - Test: [   70/  195]    Loss 1.034719    Top1 72.354911    Top5 92.287946    
2021-11-16 00:04:33,380 - Test: [   80/  195]    Loss 1.031721    Top1 72.573242    Top5 92.358398    
2021-11-16 00:04:51,701 - Test: [   90/  195]    Loss 1.031323    Top1 72.508681    Top5 92.374132    
2021-11-16 00:05:10,292 - Test: [  100/  195]    Loss 1.032774    Top1 72.449219    Top5 92.343750    
2021-11-16 00:05:28,880 - Test: [  110/  195]    Loss 1.031035    Top1 72.560369    Top5 92.386364    
2021-11-16 00:05:47,186 - Test: [  120/  195]    Loss 1.029745    Top1 72.649740    Top5 92.402344    
2021-11-16 00:06:06,005 - Test: [  130/  195]    Loss 1.033937    Top1 72.566106    Top5 92.346755    
2021-11-16 00:06:24,545 - Test: [  140/  195]    Loss 1.035030    Top1 72.589286    Top5 92.324219    
2021-11-16 00:06:42,892 - Test: [  150/  195]    Loss 1.034967    Top1 72.632812    Top5 92.322917    
2021-11-16 00:07:01,501 - Test: [  160/  195]    Loss 1.037782    Top1 72.563477    Top5 92.302246    
2021-11-16 00:07:19,776 - Test: [  170/  195]    Loss 1.036883    Top1 72.571232    Top5 92.313879    
2021-11-16 00:07:38,324 - Test: [  180/  195]    Loss 1.039557    Top1 72.482639    Top5 92.254774    
2021-11-16 00:07:56,646 - Test: [  190/  195]    Loss 1.040458    Top1 72.500000    Top5 92.226562    
2021-11-16 00:08:06,644 - ==> Top1: 72.454    Top5: 92.194    Loss: 1.043

2021-11-16 00:08:10,416 - --- test ---------------------
2021-11-16 00:08:10,416 - 50000 samples (256 per mini-batch)
2021-11-16 00:08:31,229 - Test: [   10/  195]    Loss 1.064686    Top1 72.187500    Top5 92.148438    
2021-11-16 00:08:49,664 - Test: [   20/  195]    Loss 1.051303    Top1 72.675781    Top5 91.835938    
2021-11-16 00:09:08,242 - Test: [   30/  195]    Loss 1.043093    Top1 72.968750    Top5 92.031250    
2021-11-16 00:09:26,637 - Test: [   40/  195]    Loss 1.038858    Top1 72.949219    Top5 92.119141    
2021-11-16 00:09:44,880 - Test: [   50/  195]    Loss 1.040868    Top1 72.914062    Top5 92.015625    
2021-11-16 00:10:03,376 - Test: [   60/  195]    Loss 1.045507    Top1 72.734375    Top5 92.005208    
2021-11-16 00:10:21,797 - Test: [   70/  195]    Loss 1.050110    Top1 72.639509    Top5 91.997768    
2021-11-16 00:10:40,219 - Test: [   80/  195]    Loss 1.047761    Top1 72.656250    Top5 92.016602    
2021-11-16 00:10:58,568 - Test: [   90/  195]    Loss 1.048690    Top1 72.638889    Top5 91.974826    
2021-11-16 00:11:17,055 - Test: [  100/  195]    Loss 1.047601    Top1 72.656250    Top5 91.988281    
2021-11-16 00:11:35,300 - Test: [  110/  195]    Loss 1.050359    Top1 72.599432    Top5 91.999290    
2021-11-16 00:11:53,692 - Test: [  120/  195]    Loss 1.050098    Top1 72.457682    Top5 92.073568    
2021-11-16 00:12:12,128 - Test: [  130/  195]    Loss 1.052783    Top1 72.412861    Top5 92.043269    
2021-11-16 00:12:30,417 - Test: [  140/  195]    Loss 1.048604    Top1 72.472098    Top5 92.101004    
2021-11-16 00:12:48,836 - Test: [  150/  195]    Loss 1.046520    Top1 72.414062    Top5 92.148438    
2021-11-16 00:13:06,981 - Test: [  160/  195]    Loss 1.044301    Top1 72.453613    Top5 92.170410    
2021-11-16 00:13:25,216 - Test: [  170/  195]    Loss 1.044064    Top1 72.483915    Top5 92.162224    
2021-11-16 00:13:43,552 - Test: [  180/  195]    Loss 1.042225    Top1 72.471788    Top5 92.174479    
2021-11-16 00:14:01,866 - Test: [  190/  195]    Loss 1.042644    Top1 72.477385    Top5 92.177220    
2021-11-16 00:14:11,835 - ==> Top1: 72.448    Top5: 92.194    Loss: 1.041

2021-11-16 00:14:15,596 - --- test ---------------------
2021-11-16 00:14:15,597 - 50000 samples (256 per mini-batch)
2021-11-16 00:14:36,715 - Test: [   10/  195]    Loss 1.029621    Top1 72.890625    Top5 92.500000    
2021-11-16 00:14:55,213 - Test: [   20/  195]    Loss 0.999572    Top1 73.183594    Top5 92.929688    
2021-11-16 00:15:13,605 - Test: [   30/  195]    Loss 1.004237    Top1 72.942708    Top5 92.968750    
2021-11-16 00:15:32,010 - Test: [   40/  195]    Loss 1.026955    Top1 72.744141    Top5 92.539062    
2021-11-16 00:15:50,503 - Test: [   50/  195]    Loss 1.032691    Top1 72.750000    Top5 92.390625    
2021-11-16 00:16:08,910 - Test: [   60/  195]    Loss 1.030166    Top1 72.675781    Top5 92.356771    
2021-11-16 00:16:27,348 - Test: [   70/  195]    Loss 1.042292    Top1 72.460938    Top5 92.209821    
2021-11-16 00:16:45,641 - Test: [   80/  195]    Loss 1.038252    Top1 72.519531    Top5 92.211914    
2021-11-16 00:17:04,104 - Test: [   90/  195]    Loss 1.041638    Top1 72.547743    Top5 92.152778    
2021-11-16 00:17:22,602 - Test: [  100/  195]    Loss 1.040570    Top1 72.441406    Top5 92.199219    
2021-11-16 00:17:41,035 - Test: [  110/  195]    Loss 1.041872    Top1 72.539062    Top5 92.201705    
2021-11-16 00:17:59,567 - Test: [  120/  195]    Loss 1.038340    Top1 72.565104    Top5 92.239583    
2021-11-16 00:18:18,117 - Test: [  130/  195]    Loss 1.037773    Top1 72.626202    Top5 92.250601    
2021-11-16 00:18:36,552 - Test: [  140/  195]    Loss 1.038071    Top1 72.712054    Top5 92.237723    
2021-11-16 00:18:54,874 - Test: [  150/  195]    Loss 1.039694    Top1 72.609375    Top5 92.216146    
2021-11-16 00:19:13,304 - Test: [  160/  195]    Loss 1.042232    Top1 72.607422    Top5 92.167969    
2021-11-16 00:19:31,785 - Test: [  170/  195]    Loss 1.039863    Top1 72.610294    Top5 92.169118    
2021-11-16 00:19:50,240 - Test: [  180/  195]    Loss 1.037092    Top1 72.554253    Top5 92.246094    
2021-11-16 00:20:08,682 - Test: [  190/  195]    Loss 1.039988    Top1 72.483553    Top5 92.234786    
2021-11-16 00:20:18,858 - ==> Top1: 72.452    Top5: 92.194    Loss: 1.043

2021-11-16 00:20:22,900 - --- test ---------------------
2021-11-16 00:20:22,900 - 50000 samples (256 per mini-batch)
2021-11-16 00:20:44,081 - Test: [   10/  195]    Loss 1.096663    Top1 71.093750    Top5 91.953125    
2021-11-16 00:21:02,452 - Test: [   20/  195]    Loss 1.093978    Top1 71.523438    Top5 91.601562    
2021-11-16 00:21:21,076 - Test: [   30/  195]    Loss 1.065729    Top1 72.265625    Top5 91.783854    
2021-11-16 00:21:39,704 - Test: [   40/  195]    Loss 1.059602    Top1 72.431641    Top5 91.845703    
2021-11-16 00:21:58,269 - Test: [   50/  195]    Loss 1.051418    Top1 72.593750    Top5 92.000000    
2021-11-16 00:22:16,724 - Test: [   60/  195]    Loss 1.050982    Top1 72.337240    Top5 92.044271    
2021-11-16 00:22:35,137 - Test: [   70/  195]    Loss 1.050321    Top1 72.483259    Top5 92.070312    
2021-11-16 00:22:53,802 - Test: [   80/  195]    Loss 1.040688    Top1 72.534180    Top5 92.177734    
2021-11-16 00:23:12,494 - Test: [   90/  195]    Loss 1.048066    Top1 72.296007    Top5 92.122396    
2021-11-16 00:23:30,900 - Test: [  100/  195]    Loss 1.053853    Top1 72.179688    Top5 92.011719    
2021-11-16 00:23:49,540 - Test: [  110/  195]    Loss 1.051945    Top1 72.215909    Top5 92.027699    
2021-11-16 00:24:07,960 - Test: [  120/  195]    Loss 1.051185    Top1 72.220052    Top5 92.080078    
2021-11-16 00:24:26,843 - Test: [  130/  195]    Loss 1.047936    Top1 72.313702    Top5 92.148438    
2021-11-16 00:24:45,308 - Test: [  140/  195]    Loss 1.046128    Top1 72.377232    Top5 92.201451    
2021-11-16 00:25:03,854 - Test: [  150/  195]    Loss 1.045801    Top1 72.442708    Top5 92.179688    
2021-11-16 00:25:22,265 - Test: [  160/  195]    Loss 1.047776    Top1 72.404785    Top5 92.150879    
2021-11-16 00:25:40,712 - Test: [  170/  195]    Loss 1.047931    Top1 72.440257    Top5 92.166820    
2021-11-16 00:25:59,173 - Test: [  180/  195]    Loss 1.044061    Top1 72.460938    Top5 92.211372    
2021-11-16 00:26:17,556 - Test: [  190/  195]    Loss 1.042789    Top1 72.450658    Top5 92.201891    
2021-11-16 00:26:27,556 - ==> Top1: 72.450    Top5: 92.198    Loss: 1.042

2021-11-16 00:26:31,849 - --- test ---------------------
2021-11-16 00:26:31,850 - 50000 samples (256 per mini-batch)
2021-11-16 00:26:53,537 - Test: [   10/  195]    Loss 1.006268    Top1 72.812500    Top5 92.812500    
2021-11-16 00:27:12,123 - Test: [   20/  195]    Loss 1.019203    Top1 73.007812    Top5 92.363281    
2021-11-16 00:27:30,424 - Test: [   30/  195]    Loss 1.015089    Top1 72.929688    Top5 92.421875    
2021-11-16 00:27:48,985 - Test: [   40/  195]    Loss 1.021904    Top1 72.968750    Top5 92.333984    
2021-11-16 00:28:07,432 - Test: [   50/  195]    Loss 1.020535    Top1 72.875000    Top5 92.468750    
2021-11-16 00:28:26,060 - Test: [   60/  195]    Loss 1.043895    Top1 72.493490    Top5 92.174479    
2021-11-16 00:28:44,688 - Test: [   70/  195]    Loss 1.038151    Top1 72.555804    Top5 92.310268    
2021-11-16 00:29:03,268 - Test: [   80/  195]    Loss 1.035216    Top1 72.592773    Top5 92.333984    
2021-11-16 00:29:21,722 - Test: [   90/  195]    Loss 1.041850    Top1 72.495660    Top5 92.222222    
2021-11-16 00:29:40,120 - Test: [  100/  195]    Loss 1.040045    Top1 72.527344    Top5 92.269531    
2021-11-16 00:29:58,548 - Test: [  110/  195]    Loss 1.039218    Top1 72.528409    Top5 92.269176    
2021-11-16 00:30:16,862 - Test: [  120/  195]    Loss 1.037833    Top1 72.493490    Top5 92.246094    
2021-11-16 00:30:35,125 - Test: [  130/  195]    Loss 1.038925    Top1 72.397837    Top5 92.223558    
2021-11-16 00:30:53,560 - Test: [  140/  195]    Loss 1.040068    Top1 72.357701    Top5 92.207031    
2021-11-16 00:31:11,984 - Test: [  150/  195]    Loss 1.037509    Top1 72.468750    Top5 92.242188    
2021-11-16 00:31:30,514 - Test: [  160/  195]    Loss 1.039776    Top1 72.468262    Top5 92.216797    
2021-11-16 00:31:48,853 - Test: [  170/  195]    Loss 1.042285    Top1 72.460938    Top5 92.169118    
2021-11-16 00:32:07,142 - Test: [  180/  195]    Loss 1.041801    Top1 72.500000    Top5 92.157118    
2021-11-16 00:32:25,423 - Test: [  190/  195]    Loss 1.042621    Top1 72.444490    Top5 92.166941    
2021-11-16 00:32:35,475 - ==> Top1: 72.454    Top5: 92.194    Loss: 1.042

2021-11-16 00:32:39,410 - --- test ---------------------
2021-11-16 00:32:39,410 - 50000 samples (256 per mini-batch)
2021-11-16 00:33:00,997 - Test: [   10/  195]    Loss 1.083852    Top1 71.132812    Top5 91.640625    
2021-11-16 00:33:19,286 - Test: [   20/  195]    Loss 1.084680    Top1 71.582031    Top5 91.425781    
2021-11-16 00:33:37,729 - Test: [   30/  195]    Loss 1.040004    Top1 72.460938    Top5 91.992188    
2021-11-16 00:33:56,024 - Test: [   40/  195]    Loss 1.025301    Top1 72.910156    Top5 92.226562    
2021-11-16 00:34:14,612 - Test: [   50/  195]    Loss 1.045512    Top1 72.484375    Top5 91.992188    
2021-11-16 00:34:33,016 - Test: [   60/  195]    Loss 1.057799    Top1 72.415365    Top5 91.835938    
2021-11-16 00:34:51,644 - Test: [   70/  195]    Loss 1.055491    Top1 72.494420    Top5 91.902902    
2021-11-16 00:35:10,091 - Test: [   80/  195]    Loss 1.054203    Top1 72.514648    Top5 91.943359    
2021-11-16 00:35:28,640 - Test: [   90/  195]    Loss 1.051366    Top1 72.500000    Top5 91.966146    
2021-11-16 00:35:47,127 - Test: [  100/  195]    Loss 1.054318    Top1 72.363281    Top5 91.949219    
2021-11-16 00:36:05,628 - Test: [  110/  195]    Loss 1.049236    Top1 72.443182    Top5 92.024148    
2021-11-16 00:36:24,236 - Test: [  120/  195]    Loss 1.052246    Top1 72.353516    Top5 92.001953    
2021-11-16 00:36:42,652 - Test: [  130/  195]    Loss 1.048484    Top1 72.442909    Top5 92.061298    
2021-11-16 00:37:01,006 - Test: [  140/  195]    Loss 1.047374    Top1 72.424665    Top5 92.103795    
2021-11-16 00:37:19,510 - Test: [  150/  195]    Loss 1.046483    Top1 72.367188    Top5 92.138021    
2021-11-16 00:37:37,798 - Test: [  160/  195]    Loss 1.045276    Top1 72.370605    Top5 92.165527    
2021-11-16 00:37:56,207 - Test: [  170/  195]    Loss 1.044240    Top1 72.421875    Top5 92.198989    
2021-11-16 00:38:14,672 - Test: [  180/  195]    Loss 1.041940    Top1 72.456597    Top5 92.202691    
2021-11-16 00:38:33,055 - Test: [  190/  195]    Loss 1.041045    Top1 72.469161    Top5 92.224507    
2021-11-16 00:38:42,999 - ==> Top1: 72.450    Top5: 92.194    Loss: 1.043

2021-11-16 00:38:46,847 - --- test ---------------------
2021-11-16 00:38:46,848 - 50000 samples (256 per mini-batch)
2021-11-16 00:39:08,257 - Test: [   10/  195]    Loss 1.063993    Top1 71.796875    Top5 92.031250    
2021-11-16 00:39:26,488 - Test: [   20/  195]    Loss 1.040407    Top1 72.636719    Top5 92.304688    
2021-11-16 00:39:45,012 - Test: [   30/  195]    Loss 1.036898    Top1 72.643229    Top5 92.291667    
2021-11-16 00:40:03,776 - Test: [   40/  195]    Loss 1.034000    Top1 72.500000    Top5 92.392578    
2021-11-16 00:40:22,164 - Test: [   50/  195]    Loss 1.035916    Top1 72.523438    Top5 92.414062    
2021-11-16 00:40:40,689 - Test: [   60/  195]    Loss 1.047621    Top1 72.187500    Top5 92.167969    
2021-11-16 00:40:59,116 - Test: [   70/  195]    Loss 1.037912    Top1 72.427455    Top5 92.287946    
2021-11-16 00:41:17,540 - Test: [   80/  195]    Loss 1.042744    Top1 72.319336    Top5 92.207031    
2021-11-16 00:41:36,027 - Test: [   90/  195]    Loss 1.042310    Top1 72.348090    Top5 92.209201    
2021-11-16 00:41:54,608 - Test: [  100/  195]    Loss 1.042351    Top1 72.300781    Top5 92.183594    
2021-11-16 00:42:13,006 - Test: [  110/  195]    Loss 1.044950    Top1 72.347301    Top5 92.176847    
2021-11-16 00:42:31,430 - Test: [  120/  195]    Loss 1.047624    Top1 72.333984    Top5 92.122396    
2021-11-16 00:42:49,966 - Test: [  130/  195]    Loss 1.050185    Top1 72.301683    Top5 92.037260    
2021-11-16 00:43:08,609 - Test: [  140/  195]    Loss 1.046748    Top1 72.343750    Top5 92.117746    
2021-11-16 00:43:26,910 - Test: [  150/  195]    Loss 1.046255    Top1 72.369792    Top5 92.143229    
2021-11-16 00:43:45,464 - Test: [  160/  195]    Loss 1.046841    Top1 72.338867    Top5 92.155762    
2021-11-16 00:44:03,804 - Test: [  170/  195]    Loss 1.045878    Top1 72.355239    Top5 92.166820    
2021-11-16 00:44:22,209 - Test: [  180/  195]    Loss 1.045463    Top1 72.374132    Top5 92.170139    
2021-11-16 00:44:40,593 - Test: [  190/  195]    Loss 1.044029    Top1 72.384868    Top5 92.173109    
2021-11-16 00:44:50,720 - ==> Top1: 72.454    Top5: 92.194    Loss: 1.042

2021-11-16 00:44:54,325 - --- test ---------------------
2021-11-16 00:44:54,326 - 50000 samples (256 per mini-batch)
2021-11-16 00:45:16,501 - Test: [   10/  195]    Loss 1.081480    Top1 71.640625    Top5 91.484375    
2021-11-16 00:45:34,940 - Test: [   20/  195]    Loss 1.067559    Top1 72.089844    Top5 91.699219    
2021-11-16 00:45:53,358 - Test: [   30/  195]    Loss 1.065104    Top1 71.731771    Top5 91.744792    
2021-11-16 00:46:11,872 - Test: [   40/  195]    Loss 1.068913    Top1 71.816406    Top5 91.591797    
2021-11-16 00:46:30,214 - Test: [   50/  195]    Loss 1.070588    Top1 71.742188    Top5 91.679688    
2021-11-16 00:46:48,568 - Test: [   60/  195]    Loss 1.074669    Top1 71.627604    Top5 91.725260    
2021-11-16 00:47:07,141 - Test: [   70/  195]    Loss 1.071118    Top1 71.741071    Top5 91.746652    
2021-11-16 00:47:25,750 - Test: [   80/  195]    Loss 1.068461    Top1 71.660156    Top5 91.782227    
2021-11-16 00:47:44,226 - Test: [   90/  195]    Loss 1.070698    Top1 71.623264    Top5 91.788194    
2021-11-16 00:48:02,538 - Test: [  100/  195]    Loss 1.070045    Top1 71.656250    Top5 91.820312    
2021-11-16 00:48:21,049 - Test: [  110/  195]    Loss 1.072090    Top1 71.644176    Top5 91.803977    
2021-11-16 00:48:39,477 - Test: [  120/  195]    Loss 1.067994    Top1 71.673177    Top5 91.888021    
2021-11-16 00:48:57,900 - Test: [  130/  195]    Loss 1.065604    Top1 71.730769    Top5 91.911058    
2021-11-16 00:49:16,330 - Test: [  140/  195]    Loss 1.062946    Top1 71.849888    Top5 91.947545    
2021-11-16 00:49:34,691 - Test: [  150/  195]    Loss 1.063419    Top1 71.856771    Top5 91.955729    
2021-11-16 00:49:53,025 - Test: [  160/  195]    Loss 1.068029    Top1 71.809082    Top5 91.884766    
2021-11-16 00:50:11,478 - Test: [  170/  195]    Loss 1.072945    Top1 71.760110    Top5 91.810662    
2021-11-16 00:50:29,790 - Test: [  180/  195]    Loss 1.072817    Top1 71.740451    Top5 91.846788    
2021-11-16 00:50:48,145 - Test: [  190/  195]    Loss 1.069643    Top1 71.840049    Top5 91.852385    
2021-11-16 00:50:58,218 - ==> Top1: 71.856    Top5: 91.860    Loss: 1.068

2021-11-16 00:51:02,606 - --- test ---------------------
2021-11-16 00:51:02,607 - 50000 samples (256 per mini-batch)
2021-11-16 00:51:25,091 - Test: [   10/  195]    Loss 1.083132    Top1 71.757812    Top5 92.226562    
2021-11-16 00:51:43,467 - Test: [   20/  195]    Loss 1.109805    Top1 71.640625    Top5 91.582031    
2021-11-16 00:52:02,073 - Test: [   30/  195]    Loss 1.108301    Top1 71.210938    Top5 91.445312    
2021-11-16 00:52:20,704 - Test: [   40/  195]    Loss 1.100483    Top1 71.396484    Top5 91.474609    
2021-11-16 00:52:39,096 - Test: [   50/  195]    Loss 1.089111    Top1 71.601562    Top5 91.523438    
2021-11-16 00:52:57,648 - Test: [   60/  195]    Loss 1.083717    Top1 71.777344    Top5 91.601562    
2021-11-16 00:53:16,212 - Test: [   70/  195]    Loss 1.089194    Top1 71.679688    Top5 91.445312    
2021-11-16 00:53:34,625 - Test: [   80/  195]    Loss 1.082414    Top1 71.816406    Top5 91.557617    
2021-11-16 00:53:53,289 - Test: [   90/  195]    Loss 1.085987    Top1 71.623264    Top5 91.549479    
2021-11-16 00:54:11,966 - Test: [  100/  195]    Loss 1.086966    Top1 71.574219    Top5 91.566406    
2021-11-16 00:54:30,344 - Test: [  110/  195]    Loss 1.084293    Top1 71.576705    Top5 91.608665    
2021-11-16 00:54:49,025 - Test: [  120/  195]    Loss 1.087880    Top1 71.549479    Top5 91.578776    
2021-11-16 00:55:07,600 - Test: [  130/  195]    Loss 1.086819    Top1 71.550481    Top5 91.637620    
2021-11-16 00:55:26,044 - Test: [  140/  195]    Loss 1.089265    Top1 71.478795    Top5 91.604353    
2021-11-16 00:55:44,712 - Test: [  150/  195]    Loss 1.090316    Top1 71.432292    Top5 91.598958    
2021-11-16 00:56:02,999 - Test: [  160/  195]    Loss 1.088726    Top1 71.528320    Top5 91.606445    
2021-11-16 00:56:21,451 - Test: [  170/  195]    Loss 1.089409    Top1 71.509651    Top5 91.601562    
2021-11-16 00:56:39,968 - Test: [  180/  195]    Loss 1.087144    Top1 71.536458    Top5 91.601562    
2021-11-16 00:56:58,346 - Test: [  190/  195]    Loss 1.086639    Top1 71.539885    Top5 91.613898    
2021-11-16 00:57:08,387 - ==> Top1: 71.558    Top5: 91.622    Loss: 1.085

2021-11-16 00:57:12,726 - --- test ---------------------
2021-11-16 00:57:12,726 - 50000 samples (256 per mini-batch)
2021-11-16 00:57:33,913 - Test: [   10/  195]    Loss 1.023416    Top1 72.109375    Top5 91.992188    
2021-11-16 00:57:52,369 - Test: [   20/  195]    Loss 1.051385    Top1 71.875000    Top5 91.601562    
2021-11-16 00:58:10,816 - Test: [   30/  195]    Loss 1.038987    Top1 72.343750    Top5 91.914062    
2021-11-16 00:58:29,410 - Test: [   40/  195]    Loss 1.051976    Top1 72.207031    Top5 91.689453    
2021-11-16 00:58:47,956 - Test: [   50/  195]    Loss 1.054725    Top1 72.117188    Top5 91.656250    
2021-11-16 00:59:06,452 - Test: [   60/  195]    Loss 1.051381    Top1 72.226562    Top5 91.751302    
2021-11-16 00:59:24,729 - Test: [   70/  195]    Loss 1.057467    Top1 72.170759    Top5 91.757812    
2021-11-16 00:59:43,188 - Test: [   80/  195]    Loss 1.060907    Top1 72.016602    Top5 91.752930    
2021-11-16 01:00:01,597 - Test: [   90/  195]    Loss 1.062379    Top1 71.935764    Top5 91.744792    
2021-11-16 01:00:20,052 - Test: [  100/  195]    Loss 1.063195    Top1 71.910156    Top5 91.769531    
2021-11-16 01:00:38,560 - Test: [  110/  195]    Loss 1.065475    Top1 71.768466    Top5 91.789773    
2021-11-16 01:00:56,980 - Test: [  120/  195]    Loss 1.063159    Top1 71.845703    Top5 91.852214    
2021-11-16 01:01:15,333 - Test: [  130/  195]    Loss 1.064213    Top1 71.784856    Top5 91.859976    
2021-11-16 01:01:33,747 - Test: [  140/  195]    Loss 1.066127    Top1 71.685268    Top5 91.821987    
2021-11-16 01:01:52,173 - Test: [  150/  195]    Loss 1.068519    Top1 71.609375    Top5 91.815104    
2021-11-16 01:02:10,342 - Test: [  160/  195]    Loss 1.069546    Top1 71.694336    Top5 91.835938    
2021-11-16 01:02:28,593 - Test: [  170/  195]    Loss 1.069788    Top1 71.730239    Top5 91.840533    
2021-11-16 01:02:46,790 - Test: [  180/  195]    Loss 1.069607    Top1 71.773003    Top5 91.829427    
2021-11-16 01:03:05,109 - Test: [  190/  195]    Loss 1.069779    Top1 71.737253    Top5 91.846217    
2021-11-16 01:03:15,218 - ==> Top1: 71.700    Top5: 91.824    Loss: 1.072

2021-11-16 01:03:18,955 - --- test ---------------------
2021-11-16 01:03:18,956 - 50000 samples (256 per mini-batch)
2021-11-16 01:03:39,753 - Test: [   10/  195]    Loss 1.088413    Top1 72.304688    Top5 91.093750    
2021-11-16 01:03:57,920 - Test: [   20/  195]    Loss 1.074145    Top1 72.207031    Top5 91.523438    
2021-11-16 01:04:16,292 - Test: [   30/  195]    Loss 1.072232    Top1 72.291667    Top5 91.757812    
2021-11-16 01:04:34,487 - Test: [   40/  195]    Loss 1.078948    Top1 72.041016    Top5 91.640625    
2021-11-16 01:04:52,963 - Test: [   50/  195]    Loss 1.088373    Top1 71.804688    Top5 91.429688    
2021-11-16 01:05:11,265 - Test: [   60/  195]    Loss 1.082081    Top1 71.881510    Top5 91.601562    
2021-11-16 01:05:29,671 - Test: [   70/  195]    Loss 1.085799    Top1 71.757812    Top5 91.501116    
2021-11-16 01:05:47,888 - Test: [   80/  195]    Loss 1.086021    Top1 71.689453    Top5 91.625977    
2021-11-16 01:06:06,382 - Test: [   90/  195]    Loss 1.086144    Top1 71.736111    Top5 91.601562    
2021-11-16 01:06:24,853 - Test: [  100/  195]    Loss 1.083008    Top1 71.773438    Top5 91.632812    
2021-11-16 01:06:43,302 - Test: [  110/  195]    Loss 1.080961    Top1 71.789773    Top5 91.651278    
2021-11-16 01:07:01,601 - Test: [  120/  195]    Loss 1.081748    Top1 71.796875    Top5 91.722005    
2021-11-16 01:07:20,014 - Test: [  130/  195]    Loss 1.078901    Top1 71.859976    Top5 91.733774    
2021-11-16 01:07:38,305 - Test: [  140/  195]    Loss 1.074745    Top1 71.922433    Top5 91.791295    
2021-11-16 01:07:56,628 - Test: [  150/  195]    Loss 1.073629    Top1 71.890625    Top5 91.861979    
2021-11-16 01:08:14,890 - Test: [  160/  195]    Loss 1.072586    Top1 71.875000    Top5 91.875000    
2021-11-16 01:08:33,101 - Test: [  170/  195]    Loss 1.073177    Top1 71.838235    Top5 91.838235    
2021-11-16 01:08:51,377 - Test: [  180/  195]    Loss 1.073429    Top1 71.814236    Top5 91.803385    
2021-11-16 01:09:09,648 - Test: [  190/  195]    Loss 1.073601    Top1 71.813322    Top5 91.803043    
2021-11-16 01:09:19,696 - ==> Top1: 71.724    Top5: 91.786    Loss: 1.077

2021-11-16 01:09:23,257 - --- test ---------------------
2021-11-16 01:09:23,258 - 50000 samples (256 per mini-batch)
2021-11-16 01:09:43,772 - Test: [   10/  195]    Loss 1.028019    Top1 72.421875    Top5 92.695312    
2021-11-16 01:10:01,903 - Test: [   20/  195]    Loss 1.068605    Top1 71.464844    Top5 92.128906    
2021-11-16 01:10:20,221 - Test: [   30/  195]    Loss 1.069705    Top1 71.536458    Top5 92.070312    
2021-11-16 01:10:38,514 - Test: [   40/  195]    Loss 1.091143    Top1 71.455078    Top5 91.757812    
2021-11-16 01:10:56,876 - Test: [   50/  195]    Loss 1.087660    Top1 71.398438    Top5 91.781250    
2021-11-16 01:11:15,324 - Test: [   60/  195]    Loss 1.095508    Top1 71.126302    Top5 91.601562    
2021-11-16 01:11:33,424 - Test: [   70/  195]    Loss 1.086800    Top1 71.266741    Top5 91.702009    
2021-11-16 01:11:51,813 - Test: [   80/  195]    Loss 1.085407    Top1 71.162109    Top5 91.718750    
2021-11-16 01:12:10,164 - Test: [   90/  195]    Loss 1.085160    Top1 71.128472    Top5 91.662326    
2021-11-16 01:12:28,373 - Test: [  100/  195]    Loss 1.082227    Top1 71.238281    Top5 91.691406    
2021-11-16 01:12:46,847 - Test: [  110/  195]    Loss 1.083034    Top1 71.345881    Top5 91.672585    
2021-11-16 01:13:05,124 - Test: [  120/  195]    Loss 1.082577    Top1 71.298828    Top5 91.673177    
2021-11-16 01:13:23,365 - Test: [  130/  195]    Loss 1.078956    Top1 71.349159    Top5 91.733774    
2021-11-16 01:13:41,716 - Test: [  140/  195]    Loss 1.078759    Top1 71.356027    Top5 91.768973    
2021-11-16 01:13:59,985 - Test: [  150/  195]    Loss 1.079151    Top1 71.372396    Top5 91.791667    
2021-11-16 01:14:18,201 - Test: [  160/  195]    Loss 1.078366    Top1 71.450195    Top5 91.791992    
2021-11-16 01:14:36,333 - Test: [  170/  195]    Loss 1.080851    Top1 71.360294    Top5 91.762408    
2021-11-16 01:14:54,548 - Test: [  180/  195]    Loss 1.078819    Top1 71.427951    Top5 91.783854    
2021-11-16 01:15:12,859 - Test: [  190/  195]    Loss 1.082794    Top1 71.348684    Top5 91.780428    
2021-11-16 01:15:22,797 - ==> Top1: 71.410    Top5: 91.828    Loss: 1.079

2021-11-16 01:15:26,274 - --- test ---------------------
2021-11-16 01:15:26,275 - 50000 samples (256 per mini-batch)
2021-11-16 01:15:47,193 - Test: [   10/  195]    Loss 1.076400    Top1 70.351562    Top5 91.679688    
2021-11-16 01:16:05,566 - Test: [   20/  195]    Loss 1.072171    Top1 70.937500    Top5 91.640625    
2021-11-16 01:16:23,738 - Test: [   30/  195]    Loss 1.087170    Top1 70.729167    Top5 91.419271    
2021-11-16 01:16:41,890 - Test: [   40/  195]    Loss 1.089294    Top1 70.830078    Top5 91.552734    
2021-11-16 01:17:00,148 - Test: [   50/  195]    Loss 1.079231    Top1 71.281250    Top5 91.695312    
2021-11-16 01:17:18,609 - Test: [   60/  195]    Loss 1.073009    Top1 71.588542    Top5 91.757812    
2021-11-16 01:17:36,871 - Test: [   70/  195]    Loss 1.077115    Top1 71.568080    Top5 91.819196    
2021-11-16 01:17:55,236 - Test: [   80/  195]    Loss 1.073765    Top1 71.567383    Top5 91.782227    
2021-11-16 01:18:13,531 - Test: [   90/  195]    Loss 1.080881    Top1 71.436632    Top5 91.718750    
2021-11-16 01:18:31,680 - Test: [  100/  195]    Loss 1.076103    Top1 71.531250    Top5 91.792969    
2021-11-16 01:18:49,829 - Test: [  110/  195]    Loss 1.075739    Top1 71.523438    Top5 91.789773    
2021-11-16 01:19:08,028 - Test: [  120/  195]    Loss 1.078190    Top1 71.503906    Top5 91.803385    
2021-11-16 01:19:26,248 - Test: [  130/  195]    Loss 1.078007    Top1 71.451322    Top5 91.808894    
2021-11-16 01:19:44,582 - Test: [  140/  195]    Loss 1.075842    Top1 71.492746    Top5 91.849888    
2021-11-16 01:20:02,922 - Test: [  150/  195]    Loss 1.072360    Top1 71.526042    Top5 91.895833    
2021-11-16 01:20:21,142 - Test: [  160/  195]    Loss 1.071307    Top1 71.569824    Top5 91.909180    
2021-11-16 01:20:39,465 - Test: [  170/  195]    Loss 1.071987    Top1 71.587776    Top5 91.891085    
2021-11-16 01:20:57,554 - Test: [  180/  195]    Loss 1.071335    Top1 71.610243    Top5 91.890191    
2021-11-16 01:21:15,889 - Test: [  190/  195]    Loss 1.072833    Top1 71.605674    Top5 91.862664    
2021-11-16 01:21:25,719 - ==> Top1: 71.704    Top5: 91.884    Loss: 1.070

2021-11-16 01:21:29,053 - --- test ---------------------
2021-11-16 01:21:29,054 - 50000 samples (256 per mini-batch)
2021-11-16 01:21:50,744 - Test: [   10/  195]    Loss 1.108878    Top1 70.781250    Top5 91.367188    
2021-11-16 01:22:09,060 - Test: [   20/  195]    Loss 1.095801    Top1 71.308594    Top5 91.445312    
2021-11-16 01:22:27,213 - Test: [   30/  195]    Loss 1.086423    Top1 71.523438    Top5 91.653646    
2021-11-16 01:22:45,514 - Test: [   40/  195]    Loss 1.089643    Top1 71.523438    Top5 91.806641    
2021-11-16 01:23:03,684 - Test: [   50/  195]    Loss 1.091858    Top1 71.429688    Top5 91.757812    
2021-11-16 01:23:22,249 - Test: [   60/  195]    Loss 1.082419    Top1 71.783854    Top5 91.848958    
2021-11-16 01:23:40,431 - Test: [   70/  195]    Loss 1.085410    Top1 71.780134    Top5 91.696429    
2021-11-16 01:23:58,746 - Test: [   80/  195]    Loss 1.077331    Top1 71.899414    Top5 91.762695    
2021-11-16 01:24:16,956 - Test: [   90/  195]    Loss 1.073128    Top1 72.009549    Top5 91.757812    
2021-11-16 01:24:35,343 - Test: [  100/  195]    Loss 1.068845    Top1 72.082031    Top5 91.808594    
2021-11-16 01:24:53,545 - Test: [  110/  195]    Loss 1.069325    Top1 72.151989    Top5 91.768466    
2021-11-16 01:25:11,726 - Test: [  120/  195]    Loss 1.065825    Top1 72.151693    Top5 91.832682    
2021-11-16 01:25:30,137 - Test: [  130/  195]    Loss 1.072380    Top1 71.980168    Top5 91.775841    
2021-11-16 01:25:48,488 - Test: [  140/  195]    Loss 1.076771    Top1 71.955915    Top5 91.732701    
2021-11-16 01:26:06,688 - Test: [  150/  195]    Loss 1.079517    Top1 71.916667    Top5 91.666667    
2021-11-16 01:26:25,083 - Test: [  160/  195]    Loss 1.080029    Top1 71.887207    Top5 91.667480    
2021-11-16 01:26:43,400 - Test: [  170/  195]    Loss 1.080627    Top1 71.799173    Top5 91.688879    
2021-11-16 01:27:01,886 - Test: [  180/  195]    Loss 1.080465    Top1 71.816406    Top5 91.675347    
2021-11-16 01:27:20,100 - Test: [  190/  195]    Loss 1.077517    Top1 71.848273    Top5 91.710526    
2021-11-16 01:27:29,909 - ==> Top1: 71.806    Top5: 91.712    Loss: 1.078

2021-11-16 01:27:33,366 - --- test ---------------------
2021-11-16 01:27:33,366 - 50000 samples (256 per mini-batch)
2021-11-16 01:27:53,753 - Test: [   10/  195]    Loss 1.082752    Top1 71.835938    Top5 92.226562    
2021-11-16 01:28:11,957 - Test: [   20/  195]    Loss 1.062807    Top1 72.285156    Top5 92.343750    
2021-11-16 01:28:30,414 - Test: [   30/  195]    Loss 1.073241    Top1 71.888021    Top5 91.809896    
2021-11-16 01:28:48,588 - Test: [   40/  195]    Loss 1.065468    Top1 71.943359    Top5 92.050781    
2021-11-16 01:29:06,788 - Test: [   50/  195]    Loss 1.067058    Top1 71.742188    Top5 91.906250    
2021-11-16 01:29:25,104 - Test: [   60/  195]    Loss 1.074668    Top1 71.686198    Top5 91.829427    
2021-11-16 01:29:43,329 - Test: [   70/  195]    Loss 1.071165    Top1 71.802455    Top5 91.847098    
2021-11-16 01:30:01,572 - Test: [   80/  195]    Loss 1.074896    Top1 71.757812    Top5 91.816406    
2021-11-16 01:30:19,788 - Test: [   90/  195]    Loss 1.076586    Top1 71.731771    Top5 91.770833    
2021-11-16 01:30:38,095 - Test: [  100/  195]    Loss 1.074338    Top1 71.691406    Top5 91.792969    
2021-11-16 01:30:56,636 - Test: [  110/  195]    Loss 1.073693    Top1 71.605114    Top5 91.782670    
2021-11-16 01:31:14,984 - Test: [  120/  195]    Loss 1.070919    Top1 71.611328    Top5 91.803385    
2021-11-16 01:31:33,240 - Test: [  130/  195]    Loss 1.071828    Top1 71.592548    Top5 91.832933    
2021-11-16 01:31:51,656 - Test: [  140/  195]    Loss 1.068742    Top1 71.674107    Top5 91.872210    
2021-11-16 01:32:10,128 - Test: [  150/  195]    Loss 1.070555    Top1 71.627604    Top5 91.789062    
2021-11-16 01:32:28,408 - Test: [  160/  195]    Loss 1.071914    Top1 71.550293    Top5 91.811523    
2021-11-16 01:32:46,584 - Test: [  170/  195]    Loss 1.071311    Top1 71.601562    Top5 91.808364    
2021-11-16 01:33:04,832 - Test: [  180/  195]    Loss 1.070975    Top1 71.655816    Top5 91.796875    
2021-11-16 01:33:23,042 - Test: [  190/  195]    Loss 1.071043    Top1 71.628289    Top5 91.833882    
2021-11-16 01:33:32,977 - ==> Top1: 71.642    Top5: 91.806    Loss: 1.073

2021-11-16 01:33:37,335 - --- test ---------------------
2021-11-16 01:33:37,336 - 50000 samples (256 per mini-batch)
2021-11-16 01:33:59,529 - Test: [   10/  195]    Loss 1.034324    Top1 72.226562    Top5 92.265625    
2021-11-16 01:34:17,794 - Test: [   20/  195]    Loss 1.045283    Top1 72.187500    Top5 92.089844    
2021-11-16 01:34:36,012 - Test: [   30/  195]    Loss 1.068321    Top1 71.679688    Top5 91.875000    
2021-11-16 01:34:54,414 - Test: [   40/  195]    Loss 1.071803    Top1 71.591797    Top5 91.738281    
2021-11-16 01:35:12,819 - Test: [   50/  195]    Loss 1.060602    Top1 71.796875    Top5 91.953125    
2021-11-16 01:35:31,105 - Test: [   60/  195]    Loss 1.063789    Top1 71.855469    Top5 91.933594    
2021-11-16 01:35:49,331 - Test: [   70/  195]    Loss 1.061670    Top1 71.886161    Top5 92.059152    
2021-11-16 01:36:07,547 - Test: [   80/  195]    Loss 1.057393    Top1 71.992188    Top5 92.187500    
2021-11-16 01:36:25,812 - Test: [   90/  195]    Loss 1.055992    Top1 71.961806    Top5 92.174479    
2021-11-16 01:36:44,196 - Test: [  100/  195]    Loss 1.052218    Top1 72.023438    Top5 92.203125    
2021-11-16 01:37:02,540 - Test: [  110/  195]    Loss 1.050956    Top1 72.098722    Top5 92.180398    
2021-11-16 01:37:20,909 - Test: [  120/  195]    Loss 1.051360    Top1 72.073568    Top5 92.180990    
2021-11-16 01:37:39,142 - Test: [  130/  195]    Loss 1.053991    Top1 72.034255    Top5 92.178486    
2021-11-16 01:37:57,497 - Test: [  140/  195]    Loss 1.055465    Top1 71.975446    Top5 92.187500    
2021-11-16 01:38:15,892 - Test: [  150/  195]    Loss 1.056832    Top1 71.911458    Top5 92.174479    
2021-11-16 01:38:34,197 - Test: [  160/  195]    Loss 1.058873    Top1 71.879883    Top5 92.121582    
2021-11-16 01:38:52,401 - Test: [  170/  195]    Loss 1.059440    Top1 71.838235    Top5 92.113971    
2021-11-16 01:39:10,600 - Test: [  180/  195]    Loss 1.056596    Top1 71.961806    Top5 92.183160    
2021-11-16 01:39:29,104 - Test: [  190/  195]    Loss 1.056088    Top1 71.963405    Top5 92.181332    
2021-11-16 01:39:38,961 - ==> Top1: 71.904    Top5: 92.124    Loss: 1.058

2021-11-16 01:39:42,861 - --- test ---------------------
2021-11-16 01:39:42,862 - 50000 samples (256 per mini-batch)
2021-11-16 01:40:04,406 - Test: [   10/  195]    Loss 1.064095    Top1 71.210938    Top5 92.187500    
2021-11-16 01:40:22,633 - Test: [   20/  195]    Loss 1.037536    Top1 72.070312    Top5 92.109375    
2021-11-16 01:40:40,918 - Test: [   30/  195]    Loss 1.048948    Top1 71.966146    Top5 92.044271    
2021-11-16 01:40:59,155 - Test: [   40/  195]    Loss 1.062425    Top1 71.689453    Top5 91.826172    
2021-11-16 01:41:17,517 - Test: [   50/  195]    Loss 1.070441    Top1 71.851562    Top5 91.726562    
2021-11-16 01:41:35,861 - Test: [   60/  195]    Loss 1.069525    Top1 71.946615    Top5 91.673177    
2021-11-16 01:41:54,016 - Test: [   70/  195]    Loss 1.074131    Top1 71.919643    Top5 91.623884    
2021-11-16 01:42:12,289 - Test: [   80/  195]    Loss 1.070116    Top1 71.987305    Top5 91.621094    
2021-11-16 01:42:30,677 - Test: [   90/  195]    Loss 1.070211    Top1 72.009549    Top5 91.597222    
2021-11-16 01:42:49,138 - Test: [  100/  195]    Loss 1.068028    Top1 71.968750    Top5 91.597656    
2021-11-16 01:43:07,616 - Test: [  110/  195]    Loss 1.074419    Top1 71.846591    Top5 91.548295    
2021-11-16 01:43:25,882 - Test: [  120/  195]    Loss 1.078241    Top1 71.822917    Top5 91.503906    
2021-11-16 01:43:44,300 - Test: [  130/  195]    Loss 1.074960    Top1 71.739784    Top5 91.559495    
2021-11-16 01:44:02,479 - Test: [  140/  195]    Loss 1.070775    Top1 71.808036    Top5 91.621094    
2021-11-16 01:44:20,826 - Test: [  150/  195]    Loss 1.072213    Top1 71.765625    Top5 91.658854    
2021-11-16 01:44:39,000 - Test: [  160/  195]    Loss 1.072677    Top1 71.757812    Top5 91.672363    
2021-11-16 01:44:57,173 - Test: [  170/  195]    Loss 1.072936    Top1 71.677390    Top5 91.702665    
2021-11-16 01:45:15,473 - Test: [  180/  195]    Loss 1.069449    Top1 71.775174    Top5 91.792535    
2021-11-16 01:45:33,718 - Test: [  190/  195]    Loss 1.066559    Top1 71.805099    Top5 91.823602    
2021-11-16 01:45:43,646 - ==> Top1: 71.794    Top5: 91.818    Loss: 1.068

2021-11-16 01:45:47,783 - --- test ---------------------
2021-11-16 01:45:47,783 - 50000 samples (256 per mini-batch)
2021-11-16 01:46:09,585 - Test: [   10/  195]    Loss 1.024882    Top1 72.773438    Top5 92.265625    
2021-11-16 01:46:28,119 - Test: [   20/  195]    Loss 1.027076    Top1 72.871094    Top5 92.265625    
2021-11-16 01:46:46,396 - Test: [   30/  195]    Loss 1.070988    Top1 71.992188    Top5 91.914062    
2021-11-16 01:47:04,620 - Test: [   40/  195]    Loss 1.075422    Top1 71.601562    Top5 92.021484    
2021-11-16 01:47:23,017 - Test: [   50/  195]    Loss 1.070964    Top1 71.695313    Top5 92.046875    
2021-11-16 01:47:41,379 - Test: [   60/  195]    Loss 1.066174    Top1 71.777344    Top5 91.972656    
2021-11-16 01:47:59,605 - Test: [   70/  195]    Loss 1.059206    Top1 71.875000    Top5 92.064732    
2021-11-16 01:48:17,980 - Test: [   80/  195]    Loss 1.062225    Top1 71.806641    Top5 92.065430    
2021-11-16 01:48:36,410 - Test: [   90/  195]    Loss 1.057492    Top1 71.879340    Top5 92.105035    
2021-11-16 01:48:54,653 - Test: [  100/  195]    Loss 1.059432    Top1 71.804688    Top5 92.074219    
2021-11-16 01:49:12,955 - Test: [  110/  195]    Loss 1.061628    Top1 71.843040    Top5 92.024148    
2021-11-16 01:49:31,208 - Test: [  120/  195]    Loss 1.064279    Top1 71.705729    Top5 92.031250    
2021-11-16 01:49:49,550 - Test: [  130/  195]    Loss 1.063856    Top1 71.754808    Top5 92.010216    
2021-11-16 01:50:07,862 - Test: [  140/  195]    Loss 1.065517    Top1 71.749442    Top5 92.003348    
2021-11-16 01:50:26,183 - Test: [  150/  195]    Loss 1.069006    Top1 71.695313    Top5 91.945312    
2021-11-16 01:50:44,351 - Test: [  160/  195]    Loss 1.065637    Top1 71.738281    Top5 91.965332    
2021-11-16 01:51:02,821 - Test: [  170/  195]    Loss 1.065291    Top1 71.700368    Top5 91.978401    
2021-11-16 01:51:20,990 - Test: [  180/  195]    Loss 1.063291    Top1 71.723090    Top5 91.996528    
2021-11-16 01:51:39,151 - Test: [  190/  195]    Loss 1.062247    Top1 71.763980    Top5 92.008635    
2021-11-16 01:51:49,057 - ==> Top1: 71.756    Top5: 92.022    Loss: 1.060

2021-11-16 01:51:53,047 - --- test ---------------------
2021-11-16 01:51:53,047 - 50000 samples (256 per mini-batch)
2021-11-16 01:52:14,192 - Test: [   10/  195]    Loss 1.126080    Top1 71.171875    Top5 91.367188    
2021-11-16 01:52:32,564 - Test: [   20/  195]    Loss 1.116469    Top1 71.132812    Top5 91.503906    
2021-11-16 01:52:50,919 - Test: [   30/  195]    Loss 1.096911    Top1 71.627604    Top5 91.484375    
2021-11-16 01:53:09,197 - Test: [   40/  195]    Loss 1.087835    Top1 71.464844    Top5 91.552734    
2021-11-16 01:53:27,447 - Test: [   50/  195]    Loss 1.077677    Top1 71.812500    Top5 91.703125    
2021-11-16 01:53:45,707 - Test: [   60/  195]    Loss 1.068960    Top1 72.076823    Top5 91.783854    
2021-11-16 01:54:04,108 - Test: [   70/  195]    Loss 1.074052    Top1 72.059152    Top5 91.713170    
2021-11-16 01:54:22,570 - Test: [   80/  195]    Loss 1.070260    Top1 72.036133    Top5 91.743164    
2021-11-16 01:54:40,857 - Test: [   90/  195]    Loss 1.060585    Top1 72.187500    Top5 91.835938    
2021-11-16 01:54:59,287 - Test: [  100/  195]    Loss 1.055887    Top1 72.339844    Top5 91.976562    
2021-11-16 01:55:17,718 - Test: [  110/  195]    Loss 1.057855    Top1 72.169744    Top5 91.960227    
2021-11-16 01:55:36,160 - Test: [  120/  195]    Loss 1.056894    Top1 72.190755    Top5 91.936849    
2021-11-16 01:55:54,328 - Test: [  130/  195]    Loss 1.055496    Top1 72.247596    Top5 91.944111    
2021-11-16 01:56:12,671 - Test: [  140/  195]    Loss 1.057001    Top1 72.198661    Top5 91.914062    
2021-11-16 01:56:30,907 - Test: [  150/  195]    Loss 1.057107    Top1 72.260417    Top5 91.908854    
2021-11-16 01:56:49,112 - Test: [  160/  195]    Loss 1.052916    Top1 72.338867    Top5 91.943359    
2021-11-16 01:57:07,347 - Test: [  170/  195]    Loss 1.056260    Top1 72.224265    Top5 91.904871    
2021-11-16 01:57:25,574 - Test: [  180/  195]    Loss 1.055793    Top1 72.265625    Top5 91.903212    
2021-11-16 01:57:43,743 - Test: [  190/  195]    Loss 1.060759    Top1 72.148438    Top5 91.868832    
2021-11-16 01:57:53,791 - ==> Top1: 72.208    Top5: 91.890    Loss: 1.056

2021-11-16 01:57:57,620 - --- test ---------------------
2021-11-16 01:57:57,620 - 50000 samples (256 per mini-batch)
2021-11-16 01:58:18,499 - Test: [   10/  195]    Loss 1.141670    Top1 69.414062    Top5 90.546875    
2021-11-16 01:58:36,812 - Test: [   20/  195]    Loss 1.095106    Top1 71.132812    Top5 91.230469    
2021-11-16 01:58:55,104 - Test: [   30/  195]    Loss 1.084256    Top1 71.406250    Top5 91.380208    
2021-11-16 01:59:13,327 - Test: [   40/  195]    Loss 1.081737    Top1 71.552734    Top5 91.445312    
2021-11-16 01:59:31,581 - Test: [   50/  195]    Loss 1.081865    Top1 71.679688    Top5 91.515625    
2021-11-16 01:59:49,853 - Test: [   60/  195]    Loss 1.085887    Top1 71.582031    Top5 91.451823    
2021-11-16 02:00:08,399 - Test: [   70/  195]    Loss 1.080474    Top1 71.685268    Top5 91.618304    
2021-11-16 02:00:26,800 - Test: [   80/  195]    Loss 1.076635    Top1 71.831055    Top5 91.665039    
2021-11-16 02:00:45,020 - Test: [   90/  195]    Loss 1.077350    Top1 71.801215    Top5 91.688368    
2021-11-16 02:01:03,521 - Test: [  100/  195]    Loss 1.074196    Top1 71.882812    Top5 91.703125    
2021-11-16 02:01:21,837 - Test: [  110/  195]    Loss 1.072541    Top1 71.928267    Top5 91.729403    
2021-11-16 02:01:40,039 - Test: [  120/  195]    Loss 1.075020    Top1 71.868490    Top5 91.708984    
2021-11-16 02:01:58,501 - Test: [  130/  195]    Loss 1.078384    Top1 71.805889    Top5 91.667668    
2021-11-16 02:02:16,814 - Test: [  140/  195]    Loss 1.075336    Top1 71.844308    Top5 91.707589    
2021-11-16 02:02:35,086 - Test: [  150/  195]    Loss 1.076285    Top1 71.815104    Top5 91.705729    
2021-11-16 02:02:53,396 - Test: [  160/  195]    Loss 1.074608    Top1 71.816406    Top5 91.745605    
2021-11-16 02:03:11,508 - Test: [  170/  195]    Loss 1.071492    Top1 71.865809    Top5 91.767004    
2021-11-16 02:03:29,712 - Test: [  180/  195]    Loss 1.068322    Top1 71.931424    Top5 91.840278    
2021-11-16 02:03:47,986 - Test: [  190/  195]    Loss 1.068704    Top1 71.949013    Top5 91.852385    
2021-11-16 02:03:57,896 - ==> Top1: 71.954    Top5: 91.818    Loss: 1.069

2021-11-16 02:04:01,812 - --- test ---------------------
2021-11-16 02:04:01,812 - 50000 samples (256 per mini-batch)
2021-11-16 02:04:23,161 - Test: [   10/  195]    Loss 1.061091    Top1 72.343750    Top5 92.304688    
2021-11-16 02:04:41,549 - Test: [   20/  195]    Loss 1.104002    Top1 71.347656    Top5 91.464844    
2021-11-16 02:04:59,934 - Test: [   30/  195]    Loss 1.095689    Top1 71.718750    Top5 91.510417    
2021-11-16 02:05:18,036 - Test: [   40/  195]    Loss 1.098080    Top1 71.416016    Top5 91.542969    
2021-11-16 02:05:36,377 - Test: [   50/  195]    Loss 1.086063    Top1 71.867188    Top5 91.632812    
2021-11-16 02:05:54,634 - Test: [   60/  195]    Loss 1.090353    Top1 71.738281    Top5 91.575521    
2021-11-16 02:06:13,149 - Test: [   70/  195]    Loss 1.090194    Top1 71.796875    Top5 91.590402    
2021-11-16 02:06:31,293 - Test: [   80/  195]    Loss 1.088054    Top1 71.801758    Top5 91.591797    
2021-11-16 02:06:49,533 - Test: [   90/  195]    Loss 1.080250    Top1 71.762153    Top5 91.753472    
2021-11-16 02:07:07,788 - Test: [  100/  195]    Loss 1.079241    Top1 71.707031    Top5 91.792969    
2021-11-16 02:07:26,096 - Test: [  110/  195]    Loss 1.077416    Top1 71.633523    Top5 91.867898    
2021-11-16 02:07:44,401 - Test: [  120/  195]    Loss 1.076787    Top1 71.562500    Top5 91.861979    
2021-11-16 02:08:02,879 - Test: [  130/  195]    Loss 1.073740    Top1 71.616587    Top5 91.881010    
2021-11-16 02:08:21,037 - Test: [  140/  195]    Loss 1.079150    Top1 71.556920    Top5 91.805246    
2021-11-16 02:08:39,431 - Test: [  150/  195]    Loss 1.079239    Top1 71.567708    Top5 91.815104    
2021-11-16 02:08:57,596 - Test: [  160/  195]    Loss 1.077511    Top1 71.572266    Top5 91.777344    
2021-11-16 02:09:15,719 - Test: [  170/  195]    Loss 1.074563    Top1 71.610754    Top5 91.796875    
2021-11-16 02:09:33,906 - Test: [  180/  195]    Loss 1.072860    Top1 71.684028    Top5 91.816406    
2021-11-16 02:09:52,216 - Test: [  190/  195]    Loss 1.077009    Top1 71.550164    Top5 91.796875    
2021-11-16 02:10:02,146 - ==> Top1: 71.590    Top5: 91.788    Loss: 1.076

2021-11-16 02:10:05,967 - --- test ---------------------
2021-11-16 02:10:05,968 - 50000 samples (256 per mini-batch)
2021-11-16 02:10:26,913 - Test: [   10/  195]    Loss 1.048002    Top1 71.484375    Top5 92.187500    
2021-11-16 02:10:45,065 - Test: [   20/  195]    Loss 1.089046    Top1 71.269531    Top5 91.484375    
2021-11-16 02:11:03,241 - Test: [   30/  195]    Loss 1.089071    Top1 71.250000    Top5 91.523438    
2021-11-16 02:11:21,777 - Test: [   40/  195]    Loss 1.072422    Top1 71.660156    Top5 91.582031    
2021-11-16 02:11:40,012 - Test: [   50/  195]    Loss 1.071398    Top1 71.679688    Top5 91.648438    
2021-11-16 02:11:58,338 - Test: [   60/  195]    Loss 1.076155    Top1 71.529948    Top5 91.562500    
2021-11-16 02:12:16,738 - Test: [   70/  195]    Loss 1.078214    Top1 71.568080    Top5 91.556920    
2021-11-16 02:12:35,056 - Test: [   80/  195]    Loss 1.081426    Top1 71.572266    Top5 91.552734    
2021-11-16 02:12:53,254 - Test: [   90/  195]    Loss 1.074317    Top1 71.809896    Top5 91.666667    
2021-11-16 02:13:11,559 - Test: [  100/  195]    Loss 1.075593    Top1 71.710938    Top5 91.640625    
2021-11-16 02:13:29,804 - Test: [  110/  195]    Loss 1.076302    Top1 71.718750    Top5 91.622869    
2021-11-16 02:13:48,080 - Test: [  120/  195]    Loss 1.073492    Top1 71.764323    Top5 91.653646    
2021-11-16 02:14:06,382 - Test: [  130/  195]    Loss 1.072388    Top1 71.769832    Top5 91.631611    
2021-11-16 02:14:24,724 - Test: [  140/  195]    Loss 1.072591    Top1 71.791295    Top5 91.646205    
2021-11-16 02:14:43,031 - Test: [  150/  195]    Loss 1.072207    Top1 71.833333    Top5 91.666667    
2021-11-16 02:15:01,229 - Test: [  160/  195]    Loss 1.071522    Top1 71.860352    Top5 91.694336    
2021-11-16 02:15:19,319 - Test: [  170/  195]    Loss 1.071857    Top1 71.852022    Top5 91.691176    
2021-11-16 02:15:37,423 - Test: [  180/  195]    Loss 1.071048    Top1 71.903212    Top5 91.692708    
2021-11-16 02:15:55,708 - Test: [  190/  195]    Loss 1.072404    Top1 71.840049    Top5 91.704359    
2021-11-16 02:16:05,544 - ==> Top1: 71.876    Top5: 91.728    Loss: 1.071

2021-11-16 02:16:09,114 - --- test ---------------------
2021-11-16 02:16:09,115 - 50000 samples (256 per mini-batch)
2021-11-16 02:16:30,085 - Test: [   10/  195]    Loss 1.111455    Top1 70.664062    Top5 91.640625    
2021-11-16 02:16:48,123 - Test: [   20/  195]    Loss 1.126558    Top1 70.644531    Top5 91.152344    
2021-11-16 02:17:06,429 - Test: [   30/  195]    Loss 1.107668    Top1 71.341146    Top5 91.236979    
2021-11-16 02:17:24,727 - Test: [   40/  195]    Loss 1.090388    Top1 71.552734    Top5 91.455078    
2021-11-16 02:17:42,974 - Test: [   50/  195]    Loss 1.083532    Top1 71.609375    Top5 91.492188    
2021-11-16 02:18:01,212 - Test: [   60/  195]    Loss 1.091716    Top1 71.562500    Top5 91.458333    
2021-11-16 02:18:19,594 - Test: [   70/  195]    Loss 1.088555    Top1 71.612723    Top5 91.484375    
2021-11-16 02:18:37,938 - Test: [   80/  195]    Loss 1.083711    Top1 71.616211    Top5 91.489258    
2021-11-16 02:18:56,285 - Test: [   90/  195]    Loss 1.089123    Top1 71.445312    Top5 91.484375    
2021-11-16 02:19:14,577 - Test: [  100/  195]    Loss 1.086671    Top1 71.402344    Top5 91.542969    
2021-11-16 02:19:32,774 - Test: [  110/  195]    Loss 1.088725    Top1 71.363636    Top5 91.544744    
2021-11-16 02:19:51,007 - Test: [  120/  195]    Loss 1.083805    Top1 71.399740    Top5 91.643880    
2021-11-16 02:20:09,536 - Test: [  130/  195]    Loss 1.080458    Top1 71.433293    Top5 91.721755    
2021-11-16 02:20:28,040 - Test: [  140/  195]    Loss 1.079529    Top1 71.372768    Top5 91.763393    
2021-11-16 02:20:46,421 - Test: [  150/  195]    Loss 1.078067    Top1 71.445312    Top5 91.752604    
2021-11-16 02:21:04,494 - Test: [  160/  195]    Loss 1.074818    Top1 71.530762    Top5 91.777344    
2021-11-16 02:21:22,660 - Test: [  170/  195]    Loss 1.073719    Top1 71.551011    Top5 91.803768    
2021-11-16 02:21:40,820 - Test: [  180/  195]    Loss 1.074844    Top1 71.497396    Top5 91.781684    
2021-11-16 02:21:58,975 - Test: [  190/  195]    Loss 1.074638    Top1 71.490543    Top5 91.751645    
2021-11-16 02:22:08,867 - ==> Top1: 71.468    Top5: 91.774    Loss: 1.074

2021-11-16 02:22:12,188 - --- test ---------------------
2021-11-16 02:22:12,189 - 50000 samples (256 per mini-batch)
2021-11-16 02:22:33,008 - Test: [   10/  195]    Loss 1.070584    Top1 71.054688    Top5 91.914062    
2021-11-16 02:22:51,319 - Test: [   20/  195]    Loss 1.055125    Top1 71.464844    Top5 91.953125    
2021-11-16 02:23:09,494 - Test: [   30/  195]    Loss 1.066893    Top1 71.276042    Top5 91.888021    
2021-11-16 02:23:27,744 - Test: [   40/  195]    Loss 1.077033    Top1 71.259766    Top5 91.865234    
2021-11-16 02:23:45,987 - Test: [   50/  195]    Loss 1.069614    Top1 71.609375    Top5 91.968750    
2021-11-16 02:24:04,374 - Test: [   60/  195]    Loss 1.068972    Top1 71.640625    Top5 92.024740    
2021-11-16 02:24:22,566 - Test: [   70/  195]    Loss 1.070549    Top1 71.623884    Top5 91.919643    
2021-11-16 02:24:40,960 - Test: [   80/  195]    Loss 1.065526    Top1 71.782227    Top5 91.899414    
2021-11-16 02:24:59,216 - Test: [   90/  195]    Loss 1.064259    Top1 71.801215    Top5 91.940104    
2021-11-16 02:25:17,358 - Test: [  100/  195]    Loss 1.060491    Top1 71.980469    Top5 92.015625    
2021-11-16 02:25:35,549 - Test: [  110/  195]    Loss 1.059508    Top1 71.995739    Top5 92.020597    
2021-11-16 02:25:53,876 - Test: [  120/  195]    Loss 1.056692    Top1 71.998698    Top5 92.050781    
2021-11-16 02:26:12,067 - Test: [  130/  195]    Loss 1.058086    Top1 71.941106    Top5 92.058293    
2021-11-16 02:26:30,301 - Test: [  140/  195]    Loss 1.055778    Top1 72.022879    Top5 92.070312    
2021-11-16 02:26:48,513 - Test: [  150/  195]    Loss 1.062866    Top1 71.843750    Top5 91.984375    
2021-11-16 02:27:06,649 - Test: [  160/  195]    Loss 1.064013    Top1 71.828613    Top5 91.945801    
2021-11-16 02:27:24,817 - Test: [  170/  195]    Loss 1.062837    Top1 71.886489    Top5 91.971507    
2021-11-16 02:27:43,047 - Test: [  180/  195]    Loss 1.066040    Top1 71.875000    Top5 91.927083    
2021-11-16 02:28:01,226 - Test: [  190/  195]    Loss 1.064786    Top1 71.870888    Top5 91.938734    
2021-11-16 02:28:11,080 - ==> Top1: 71.918    Top5: 91.960    Loss: 1.063

2021-11-16 02:28:14,372 - --- test ---------------------
2021-11-16 02:28:14,372 - 50000 samples (256 per mini-batch)
2021-11-16 02:28:36,072 - Test: [   10/  195]    Loss 1.043762    Top1 70.859375    Top5 92.695312    
2021-11-16 02:28:54,261 - Test: [   20/  195]    Loss 1.052446    Top1 71.464844    Top5 92.070312    
2021-11-16 02:29:12,609 - Test: [   30/  195]    Loss 1.054723    Top1 71.757812    Top5 92.044271    
2021-11-16 02:29:30,801 - Test: [   40/  195]    Loss 1.059831    Top1 71.660156    Top5 92.001953    
2021-11-16 02:29:49,037 - Test: [   50/  195]    Loss 1.057525    Top1 71.726562    Top5 92.070312    
2021-11-16 02:30:07,192 - Test: [   60/  195]    Loss 1.066703    Top1 71.614583    Top5 91.920573    
2021-11-16 02:30:25,495 - Test: [   70/  195]    Loss 1.068875    Top1 71.612723    Top5 91.858259    
2021-11-16 02:30:43,732 - Test: [   80/  195]    Loss 1.066643    Top1 71.743164    Top5 91.933594    
2021-11-16 02:31:01,967 - Test: [   90/  195]    Loss 1.065381    Top1 71.944444    Top5 91.931424    
2021-11-16 02:31:20,355 - Test: [  100/  195]    Loss 1.063531    Top1 71.976562    Top5 92.000000    
2021-11-16 02:31:38,641 - Test: [  110/  195]    Loss 1.059250    Top1 72.027699    Top5 92.084517    
2021-11-16 02:31:57,038 - Test: [  120/  195]    Loss 1.055821    Top1 72.115885    Top5 92.102865    
2021-11-16 02:32:15,177 - Test: [  130/  195]    Loss 1.057116    Top1 72.124399    Top5 92.091346    
2021-11-16 02:32:33,486 - Test: [  140/  195]    Loss 1.057201    Top1 72.092634    Top5 92.089844    
2021-11-16 02:32:51,691 - Test: [  150/  195]    Loss 1.062045    Top1 72.028646    Top5 92.005208    
2021-11-16 02:33:10,091 - Test: [  160/  195]    Loss 1.058068    Top1 72.102051    Top5 92.036133    
2021-11-16 02:33:28,284 - Test: [  170/  195]    Loss 1.059321    Top1 72.015165    Top5 92.033548    
2021-11-16 02:33:46,384 - Test: [  180/  195]    Loss 1.060076    Top1 71.990017    Top5 92.024740    
2021-11-16 02:34:04,450 - Test: [  190/  195]    Loss 1.061131    Top1 71.946957    Top5 92.000411    
2021-11-16 02:34:14,313 - ==> Top1: 71.964    Top5: 91.994    Loss: 1.059

2021-11-16 02:34:18,102 - --- test ---------------------
2021-11-16 02:34:18,102 - 50000 samples (256 per mini-batch)
2021-11-16 02:34:39,790 - Test: [   10/  195]    Loss 1.087855    Top1 71.484375    Top5 91.250000    
2021-11-16 02:34:57,939 - Test: [   20/  195]    Loss 1.033984    Top1 72.363281    Top5 91.562500    
2021-11-16 02:35:16,461 - Test: [   30/  195]    Loss 1.058971    Top1 71.861979    Top5 91.497396    
2021-11-16 02:35:34,798 - Test: [   40/  195]    Loss 1.050904    Top1 72.011719    Top5 91.542969    
2021-11-16 02:35:52,961 - Test: [   50/  195]    Loss 1.037452    Top1 72.304688    Top5 91.914062    
2021-11-16 02:36:11,180 - Test: [   60/  195]    Loss 1.042414    Top1 72.213542    Top5 91.881510    
2021-11-16 02:36:29,478 - Test: [   70/  195]    Loss 1.054599    Top1 72.042411    Top5 91.752232    
2021-11-16 02:36:47,778 - Test: [   80/  195]    Loss 1.053018    Top1 72.060547    Top5 91.879883    
2021-11-16 02:37:06,032 - Test: [   90/  195]    Loss 1.051180    Top1 72.196181    Top5 91.888021    
2021-11-16 02:37:24,412 - Test: [  100/  195]    Loss 1.051717    Top1 72.152344    Top5 91.859375    
2021-11-16 02:37:42,593 - Test: [  110/  195]    Loss 1.054497    Top1 72.102273    Top5 91.757812    
2021-11-16 02:38:00,871 - Test: [  120/  195]    Loss 1.054863    Top1 72.070312    Top5 91.793620    
2021-11-16 02:38:19,129 - Test: [  130/  195]    Loss 1.059337    Top1 71.971154    Top5 91.748798    
2021-11-16 02:38:37,410 - Test: [  140/  195]    Loss 1.057705    Top1 72.028460    Top5 91.863839    
2021-11-16 02:38:55,569 - Test: [  150/  195]    Loss 1.057061    Top1 72.033854    Top5 91.901042    
2021-11-16 02:39:13,801 - Test: [  160/  195]    Loss 1.055336    Top1 72.023926    Top5 91.965332    
2021-11-16 02:39:32,124 - Test: [  170/  195]    Loss 1.056499    Top1 71.989890    Top5 91.976103    
2021-11-16 02:39:50,174 - Test: [  180/  195]    Loss 1.058387    Top1 71.963976    Top5 91.948785    
2021-11-16 02:40:08,256 - Test: [  190/  195]    Loss 1.059759    Top1 71.835938    Top5 91.988076    
2021-11-16 02:40:18,141 - ==> Top1: 71.800    Top5: 91.976    Loss: 1.061

2021-11-16 02:40:21,586 - --- test ---------------------
2021-11-16 02:40:21,587 - 50000 samples (256 per mini-batch)
2021-11-16 02:40:42,414 - Test: [   10/  195]    Loss 1.030656    Top1 72.265625    Top5 92.265625    
2021-11-16 02:41:00,601 - Test: [   20/  195]    Loss 1.042552    Top1 71.777344    Top5 92.265625    
2021-11-16 02:41:18,669 - Test: [   30/  195]    Loss 1.049043    Top1 71.692708    Top5 92.291667    
2021-11-16 02:41:37,150 - Test: [   40/  195]    Loss 1.059450    Top1 71.757812    Top5 91.933594    
2021-11-16 02:41:55,499 - Test: [   50/  195]    Loss 1.060880    Top1 71.835938    Top5 91.882812    
2021-11-16 02:42:13,719 - Test: [   60/  195]    Loss 1.053505    Top1 71.855469    Top5 91.985677    
2021-11-16 02:42:31,957 - Test: [   70/  195]    Loss 1.056698    Top1 71.780134    Top5 91.880580    
2021-11-16 02:42:50,109 - Test: [   80/  195]    Loss 1.063145    Top1 71.870117    Top5 91.884766    
2021-11-16 02:43:08,393 - Test: [   90/  195]    Loss 1.063426    Top1 71.875000    Top5 91.853299    
2021-11-16 02:43:26,634 - Test: [  100/  195]    Loss 1.065262    Top1 71.820312    Top5 91.871094    
2021-11-16 02:43:44,982 - Test: [  110/  195]    Loss 1.062305    Top1 71.935369    Top5 91.882102    
2021-11-16 02:44:03,205 - Test: [  120/  195]    Loss 1.060926    Top1 71.992188    Top5 91.901042    
2021-11-16 02:44:21,394 - Test: [  130/  195]    Loss 1.065942    Top1 71.871995    Top5 91.820913    
2021-11-16 02:44:39,656 - Test: [  140/  195]    Loss 1.062813    Top1 71.886161    Top5 91.902902    
2021-11-16 02:44:58,051 - Test: [  150/  195]    Loss 1.066032    Top1 71.830729    Top5 91.872396    
2021-11-16 02:45:16,164 - Test: [  160/  195]    Loss 1.068636    Top1 71.762695    Top5 91.882324    
2021-11-16 02:45:34,256 - Test: [  170/  195]    Loss 1.068737    Top1 71.787684    Top5 91.833640    
2021-11-16 02:45:52,404 - Test: [  180/  195]    Loss 1.074908    Top1 71.710069    Top5 91.775174    
2021-11-16 02:46:10,638 - Test: [  190/  195]    Loss 1.075982    Top1 71.673520    Top5 91.757812    
2021-11-16 02:46:20,540 - ==> Top1: 71.704    Top5: 91.790    Loss: 1.073

2021-11-16 02:46:23,847 - --- test ---------------------
2021-11-16 02:46:23,848 - 50000 samples (256 per mini-batch)
2021-11-16 02:46:44,671 - Test: [   10/  195]    Loss 1.349553    Top1 67.187500    Top5 88.359375    
2021-11-16 02:47:02,935 - Test: [   20/  195]    Loss 1.388053    Top1 66.230469    Top5 87.675781    
2021-11-16 02:47:21,116 - Test: [   30/  195]    Loss 1.341525    Top1 66.940104    Top5 88.125000    
2021-11-16 02:47:39,201 - Test: [   40/  195]    Loss 1.344419    Top1 66.914062    Top5 88.105469    
2021-11-16 02:47:57,421 - Test: [   50/  195]    Loss 1.343754    Top1 66.945312    Top5 88.195312    
2021-11-16 02:48:15,611 - Test: [   60/  195]    Loss 1.344094    Top1 66.875000    Top5 88.177083    
2021-11-16 02:48:33,904 - Test: [   70/  195]    Loss 1.334338    Top1 66.875000    Top5 88.286830    
2021-11-16 02:48:52,424 - Test: [   80/  195]    Loss 1.327811    Top1 67.011719    Top5 88.344727    
2021-11-16 02:49:10,785 - Test: [   90/  195]    Loss 1.329446    Top1 67.039931    Top5 88.372396    
2021-11-16 02:49:28,929 - Test: [  100/  195]    Loss 1.333652    Top1 66.996094    Top5 88.343750    
2021-11-16 02:49:47,130 - Test: [  110/  195]    Loss 1.330339    Top1 66.931818    Top5 88.462358    
2021-11-16 02:50:05,318 - Test: [  120/  195]    Loss 1.326808    Top1 67.011719    Top5 88.466797    
2021-11-16 02:50:23,548 - Test: [  130/  195]    Loss 1.329252    Top1 67.037260    Top5 88.425481    
2021-11-16 02:50:41,774 - Test: [  140/  195]    Loss 1.330167    Top1 67.039621    Top5 88.434710    
2021-11-16 02:51:00,201 - Test: [  150/  195]    Loss 1.332601    Top1 66.968750    Top5 88.385417    
2021-11-16 02:51:18,430 - Test: [  160/  195]    Loss 1.330987    Top1 66.994629    Top5 88.395996    
2021-11-16 02:51:36,528 - Test: [  170/  195]    Loss 1.327643    Top1 67.058824    Top5 88.446691    
2021-11-16 02:51:54,681 - Test: [  180/  195]    Loss 1.327729    Top1 67.139757    Top5 88.435330    
2021-11-16 02:52:12,980 - Test: [  190/  195]    Loss 1.325296    Top1 67.210115    Top5 88.456003    
2021-11-16 02:52:22,829 - ==> Top1: 67.158    Top5: 88.440    Loss: 1.327

2021-11-16 02:52:26,592 - --- test ---------------------
2021-11-16 02:52:26,593 - 50000 samples (256 per mini-batch)
2021-11-16 02:52:47,761 - Test: [   10/  195]    Loss 1.307307    Top1 68.554688    Top5 88.593750    
2021-11-16 02:53:05,809 - Test: [   20/  195]    Loss 1.324190    Top1 68.105469    Top5 88.437500    
2021-11-16 02:53:24,201 - Test: [   30/  195]    Loss 1.352716    Top1 67.057292    Top5 88.020833    
2021-11-16 02:53:42,441 - Test: [   40/  195]    Loss 1.347021    Top1 67.148438    Top5 88.115234    
2021-11-16 02:54:00,854 - Test: [   50/  195]    Loss 1.340573    Top1 67.023438    Top5 88.242188    
2021-11-16 02:54:19,279 - Test: [   60/  195]    Loss 1.335818    Top1 66.953125    Top5 88.352865    
2021-11-16 02:54:37,441 - Test: [   70/  195]    Loss 1.330376    Top1 67.154018    Top5 88.459821    
2021-11-16 02:54:55,896 - Test: [   80/  195]    Loss 1.329510    Top1 67.163086    Top5 88.505859    
2021-11-16 02:55:14,152 - Test: [   90/  195]    Loss 1.336173    Top1 66.979167    Top5 88.385417    
2021-11-16 02:55:32,320 - Test: [  100/  195]    Loss 1.347558    Top1 66.734375    Top5 88.191406    
2021-11-16 02:55:50,530 - Test: [  110/  195]    Loss 1.350877    Top1 66.697443    Top5 88.128551    
2021-11-16 02:56:08,852 - Test: [  120/  195]    Loss 1.352137    Top1 66.656901    Top5 88.131510    
2021-11-16 02:56:26,994 - Test: [  130/  195]    Loss 1.347662    Top1 66.670673    Top5 88.254207    
2021-11-16 02:56:45,424 - Test: [  140/  195]    Loss 1.351317    Top1 66.637835    Top5 88.183594    
2021-11-16 02:57:03,660 - Test: [  150/  195]    Loss 1.352051    Top1 66.671875    Top5 88.130208    
2021-11-16 02:57:21,791 - Test: [  160/  195]    Loss 1.353348    Top1 66.696777    Top5 88.090820    
2021-11-16 02:57:40,176 - Test: [  170/  195]    Loss 1.354862    Top1 66.681985    Top5 88.079044    
2021-11-16 02:57:58,405 - Test: [  180/  195]    Loss 1.353275    Top1 66.712240    Top5 88.098958    
2021-11-16 02:58:16,383 - Test: [  190/  195]    Loss 1.353553    Top1 66.751645    Top5 88.067434    
2021-11-16 02:58:26,440 - ==> Top1: 66.780    Top5: 88.118    Loss: 1.351

2021-11-16 02:58:30,059 - --- test ---------------------
2021-11-16 02:58:30,059 - 50000 samples (256 per mini-batch)
2021-11-16 02:58:51,069 - Test: [   10/  195]    Loss 1.373002    Top1 66.445312    Top5 88.125000    
2021-11-16 02:59:09,313 - Test: [   20/  195]    Loss 1.394569    Top1 65.722656    Top5 87.578125    
2021-11-16 02:59:27,433 - Test: [   30/  195]    Loss 1.397638    Top1 65.664062    Top5 87.486979    
2021-11-16 02:59:45,644 - Test: [   40/  195]    Loss 1.394554    Top1 65.742188    Top5 87.382812    
2021-11-16 03:00:03,977 - Test: [   50/  195]    Loss 1.387609    Top1 65.812500    Top5 87.453125    
2021-11-16 03:00:22,130 - Test: [   60/  195]    Loss 1.393817    Top1 65.638021    Top5 87.376302    
2021-11-16 03:00:40,636 - Test: [   70/  195]    Loss 1.407065    Top1 65.396205    Top5 87.131696    
2021-11-16 03:00:58,857 - Test: [   80/  195]    Loss 1.416151    Top1 65.195312    Top5 87.065430    
2021-11-16 03:01:17,029 - Test: [   90/  195]    Loss 1.410895    Top1 65.286458    Top5 87.213542    
2021-11-16 03:01:35,316 - Test: [  100/  195]    Loss 1.405723    Top1 65.292969    Top5 87.183594    
2021-11-16 03:01:53,612 - Test: [  110/  195]    Loss 1.405327    Top1 65.316051    Top5 87.130682    
2021-11-16 03:02:11,784 - Test: [  120/  195]    Loss 1.407273    Top1 65.312500    Top5 87.112630    
2021-11-16 03:02:29,978 - Test: [  130/  195]    Loss 1.406400    Top1 65.318510    Top5 87.124399    
2021-11-16 03:02:48,085 - Test: [  140/  195]    Loss 1.406238    Top1 65.348772    Top5 87.140067    
2021-11-16 03:03:06,249 - Test: [  150/  195]    Loss 1.410369    Top1 65.335938    Top5 87.098958    
2021-11-16 03:03:24,314 - Test: [  160/  195]    Loss 1.411933    Top1 65.332031    Top5 87.089844    
2021-11-16 03:03:42,570 - Test: [  170/  195]    Loss 1.410689    Top1 65.388327    Top5 87.148438    
2021-11-16 03:04:00,648 - Test: [  180/  195]    Loss 1.411889    Top1 65.342882    Top5 87.113715    
2021-11-16 03:04:18,865 - Test: [  190/  195]    Loss 1.412860    Top1 65.331003    Top5 87.088816    
2021-11-16 03:04:28,660 - ==> Top1: 65.292    Top5: 87.098    Loss: 1.413

2021-11-16 03:04:32,623 - --- test ---------------------
2021-11-16 03:04:32,624 - 50000 samples (256 per mini-batch)
2021-11-16 03:04:53,484 - Test: [   10/  195]    Loss 1.425921    Top1 65.039062    Top5 87.031250    
2021-11-16 03:05:11,679 - Test: [   20/  195]    Loss 1.398646    Top1 65.136719    Top5 87.441406    
2021-11-16 03:05:29,827 - Test: [   30/  195]    Loss 1.413102    Top1 65.195312    Top5 87.187500    
2021-11-16 03:05:48,024 - Test: [   40/  195]    Loss 1.393580    Top1 65.751953    Top5 87.285156    
2021-11-16 03:06:06,173 - Test: [   50/  195]    Loss 1.397682    Top1 65.578125    Top5 87.359375    
2021-11-16 03:06:24,484 - Test: [   60/  195]    Loss 1.395284    Top1 65.638021    Top5 87.460938    
2021-11-16 03:06:42,688 - Test: [   70/  195]    Loss 1.396212    Top1 65.652902    Top5 87.416295    
2021-11-16 03:07:01,038 - Test: [   80/  195]    Loss 1.398124    Top1 65.571289    Top5 87.421875    
2021-11-16 03:07:19,197 - Test: [   90/  195]    Loss 1.391701    Top1 65.646701    Top5 87.491319    
2021-11-16 03:07:37,487 - Test: [  100/  195]    Loss 1.392470    Top1 65.746094    Top5 87.367188    
2021-11-16 03:07:55,648 - Test: [  110/  195]    Loss 1.399166    Top1 65.582386    Top5 87.254972    
2021-11-16 03:08:13,910 - Test: [  120/  195]    Loss 1.401738    Top1 65.550130    Top5 87.262370    
2021-11-16 03:08:32,321 - Test: [  130/  195]    Loss 1.401883    Top1 65.537861    Top5 87.286659    
2021-11-16 03:08:50,745 - Test: [  140/  195]    Loss 1.399961    Top1 65.616629    Top5 87.318638    
2021-11-16 03:09:09,041 - Test: [  150/  195]    Loss 1.399372    Top1 65.575521    Top5 87.341146    
2021-11-16 03:09:27,308 - Test: [  160/  195]    Loss 1.398193    Top1 65.544434    Top5 87.385254    
2021-11-16 03:09:45,539 - Test: [  170/  195]    Loss 1.398147    Top1 65.585938    Top5 87.380515    
2021-11-16 03:10:03,712 - Test: [  180/  195]    Loss 1.398348    Top1 65.546875    Top5 87.371962    
2021-11-16 03:10:21,928 - Test: [  190/  195]    Loss 1.399645    Top1 65.493421    Top5 87.356086    
2021-11-16 03:10:31,991 - ==> Top1: 65.520    Top5: 87.376    Loss: 1.398

2021-11-16 03:10:36,292 - --- test ---------------------
2021-11-16 03:10:36,293 - 50000 samples (256 per mini-batch)
2021-11-16 03:10:58,223 - Test: [   10/  195]    Loss 1.544158    Top1 63.320312    Top5 85.234375    
2021-11-16 03:11:16,342 - Test: [   20/  195]    Loss 1.534605    Top1 63.417969    Top5 85.078125    
2021-11-16 03:11:34,773 - Test: [   30/  195]    Loss 1.542267    Top1 63.046875    Top5 85.052083    
2021-11-16 03:11:52,938 - Test: [   40/  195]    Loss 1.537858    Top1 62.753906    Top5 85.234375    
2021-11-16 03:12:11,473 - Test: [   50/  195]    Loss 1.543311    Top1 62.632812    Top5 85.273438    
2021-11-16 03:12:29,663 - Test: [   60/  195]    Loss 1.544050    Top1 62.643229    Top5 85.299479    
2021-11-16 03:12:47,824 - Test: [   70/  195]    Loss 1.543584    Top1 62.656250    Top5 85.290179    
2021-11-16 03:13:06,260 - Test: [   80/  195]    Loss 1.547175    Top1 62.431641    Top5 85.273438    
2021-11-16 03:13:24,764 - Test: [   90/  195]    Loss 1.550988    Top1 62.339410    Top5 85.282118    
2021-11-16 03:13:42,919 - Test: [  100/  195]    Loss 1.562195    Top1 62.312500    Top5 85.179688    
2021-11-16 03:14:01,235 - Test: [  110/  195]    Loss 1.565245    Top1 62.315341    Top5 85.191761    
2021-11-16 03:14:19,437 - Test: [  120/  195]    Loss 1.568585    Top1 62.347005    Top5 85.061849    
2021-11-16 03:14:37,925 - Test: [  130/  195]    Loss 1.568288    Top1 62.373798    Top5 85.063101    
2021-11-16 03:14:56,182 - Test: [  140/  195]    Loss 1.567012    Top1 62.413504    Top5 85.047433    
2021-11-16 03:15:14,388 - Test: [  150/  195]    Loss 1.567447    Top1 62.447917    Top5 85.088542    
2021-11-16 03:15:32,444 - Test: [  160/  195]    Loss 1.565621    Top1 62.500000    Top5 85.136719    
2021-11-16 03:15:50,615 - Test: [  170/  195]    Loss 1.566595    Top1 62.529871    Top5 85.089614    
2021-11-16 03:16:08,761 - Test: [  180/  195]    Loss 1.568144    Top1 62.545573    Top5 85.071615    
2021-11-16 03:16:27,132 - Test: [  190/  195]    Loss 1.569899    Top1 62.553454    Top5 85.084293    
2021-11-16 03:16:37,088 - ==> Top1: 62.520    Top5: 85.030    Loss: 1.573

2021-11-16 03:16:41,239 - --- test ---------------------
2021-11-16 03:16:41,240 - 50000 samples (256 per mini-batch)
2021-11-16 03:17:02,603 - Test: [   10/  195]    Loss 1.246217    Top1 68.437500    Top5 89.492188    
2021-11-16 03:17:20,606 - Test: [   20/  195]    Loss 1.280435    Top1 68.144531    Top5 89.003906    
2021-11-16 03:17:38,946 - Test: [   30/  195]    Loss 1.277424    Top1 67.773438    Top5 89.257812    
2021-11-16 03:17:57,285 - Test: [   40/  195]    Loss 1.289135    Top1 67.646484    Top5 89.189453    
2021-11-16 03:18:15,516 - Test: [   50/  195]    Loss 1.288047    Top1 67.703125    Top5 89.179688    
2021-11-16 03:18:33,628 - Test: [   60/  195]    Loss 1.291123    Top1 67.597656    Top5 89.075521    
2021-11-16 03:18:52,025 - Test: [   70/  195]    Loss 1.290685    Top1 67.578125    Top5 89.068080    
2021-11-16 03:19:10,368 - Test: [   80/  195]    Loss 1.295794    Top1 67.348633    Top5 88.989258    
2021-11-16 03:19:28,645 - Test: [   90/  195]    Loss 1.302878    Top1 67.100694    Top5 88.906250    
2021-11-16 03:19:47,158 - Test: [  100/  195]    Loss 1.307738    Top1 67.117188    Top5 88.812500    
2021-11-16 03:20:05,244 - Test: [  110/  195]    Loss 1.306813    Top1 67.180398    Top5 88.821023    
2021-11-16 03:20:23,335 - Test: [  120/  195]    Loss 1.310890    Top1 67.141927    Top5 88.717448    
2021-11-16 03:20:41,533 - Test: [  130/  195]    Loss 1.310883    Top1 67.046274    Top5 88.707933    
2021-11-16 03:20:59,808 - Test: [  140/  195]    Loss 1.313771    Top1 66.958705    Top5 88.674665    
2021-11-16 03:21:17,907 - Test: [  150/  195]    Loss 1.314841    Top1 66.989583    Top5 88.653646    
2021-11-16 03:21:36,011 - Test: [  160/  195]    Loss 1.318879    Top1 66.945801    Top5 88.623047    
2021-11-16 03:21:54,233 - Test: [  170/  195]    Loss 1.319756    Top1 66.976103    Top5 88.586857    
2021-11-16 03:22:12,320 - Test: [  180/  195]    Loss 1.315654    Top1 67.120226    Top5 88.615451    
2021-11-16 03:22:30,299 - Test: [  190/  195]    Loss 1.315073    Top1 67.131990    Top5 88.589638    
2021-11-16 03:22:40,366 - ==> Top1: 67.172    Top5: 88.594    Loss: 1.314

2021-11-16 03:22:44,045 - --- test ---------------------
2021-11-16 03:22:44,045 - 50000 samples (256 per mini-batch)
2021-11-16 03:23:05,293 - Test: [   10/  195]    Loss 1.331816    Top1 67.070312    Top5 88.984375    
2021-11-16 03:23:23,342 - Test: [   20/  195]    Loss 1.328578    Top1 67.382812    Top5 88.867188    
2021-11-16 03:23:41,580 - Test: [   30/  195]    Loss 1.305460    Top1 68.125000    Top5 88.971354    
2021-11-16 03:23:59,865 - Test: [   40/  195]    Loss 1.317224    Top1 67.714844    Top5 88.671875    
2021-11-16 03:24:18,129 - Test: [   50/  195]    Loss 1.330727    Top1 67.578125    Top5 88.390625    
2021-11-16 03:24:36,359 - Test: [   60/  195]    Loss 1.322207    Top1 67.656250    Top5 88.548177    
2021-11-16 03:24:54,712 - Test: [   70/  195]    Loss 1.325280    Top1 67.310268    Top5 88.515625    
2021-11-16 03:25:13,038 - Test: [   80/  195]    Loss 1.323780    Top1 67.250977    Top5 88.549805    
2021-11-16 03:25:31,094 - Test: [   90/  195]    Loss 1.330182    Top1 67.209201    Top5 88.446181    
2021-11-16 03:25:49,175 - Test: [  100/  195]    Loss 1.337066    Top1 67.101562    Top5 88.328125    
2021-11-16 03:26:07,345 - Test: [  110/  195]    Loss 1.332484    Top1 67.148438    Top5 88.412642    
2021-11-16 03:26:25,524 - Test: [  120/  195]    Loss 1.338543    Top1 67.041016    Top5 88.307292    
2021-11-16 03:26:43,767 - Test: [  130/  195]    Loss 1.338377    Top1 66.968149    Top5 88.338341    
2021-11-16 03:27:01,885 - Test: [  140/  195]    Loss 1.338577    Top1 66.992188    Top5 88.351004    
2021-11-16 03:27:20,036 - Test: [  150/  195]    Loss 1.338127    Top1 66.986979    Top5 88.375000    
2021-11-16 03:27:38,355 - Test: [  160/  195]    Loss 1.339725    Top1 66.940918    Top5 88.298340    
2021-11-16 03:27:56,392 - Test: [  170/  195]    Loss 1.338998    Top1 66.914062    Top5 88.322610    
2021-11-16 03:28:14,387 - Test: [  180/  195]    Loss 1.342107    Top1 66.907552    Top5 88.322483    
2021-11-16 03:28:32,399 - Test: [  190/  195]    Loss 1.342805    Top1 66.870888    Top5 88.322368    
2021-11-16 03:28:42,361 - ==> Top1: 66.910    Top5: 88.338    Loss: 1.341

2021-11-16 03:28:45,734 - --- test ---------------------
2021-11-16 03:28:45,735 - 50000 samples (256 per mini-batch)
2021-11-16 03:29:06,388 - Test: [   10/  195]    Loss 1.376388    Top1 66.562500    Top5 87.851562    
2021-11-16 03:29:24,517 - Test: [   20/  195]    Loss 1.346624    Top1 66.953125    Top5 88.261719    
2021-11-16 03:29:42,739 - Test: [   30/  195]    Loss 1.357009    Top1 66.992188    Top5 87.864583    
2021-11-16 03:30:00,770 - Test: [   40/  195]    Loss 1.351676    Top1 67.089844    Top5 87.910156    
2021-11-16 03:30:18,916 - Test: [   50/  195]    Loss 1.352336    Top1 66.968750    Top5 87.937500    
2021-11-16 03:30:37,249 - Test: [   60/  195]    Loss 1.355160    Top1 66.959635    Top5 87.832031    
2021-11-16 03:30:55,416 - Test: [   70/  195]    Loss 1.346012    Top1 67.075893    Top5 87.924107    
2021-11-16 03:31:13,492 - Test: [   80/  195]    Loss 1.344677    Top1 67.045898    Top5 87.978516    
2021-11-16 03:31:31,688 - Test: [   90/  195]    Loss 1.337809    Top1 67.135417    Top5 88.133681    
2021-11-16 03:31:49,893 - Test: [  100/  195]    Loss 1.337535    Top1 67.105469    Top5 88.207031    
2021-11-16 03:32:08,017 - Test: [  110/  195]    Loss 1.338698    Top1 67.109375    Top5 88.167614    
2021-11-16 03:32:26,147 - Test: [  120/  195]    Loss 1.335681    Top1 67.177734    Top5 88.180339    
2021-11-16 03:32:44,424 - Test: [  130/  195]    Loss 1.337177    Top1 67.103365    Top5 88.158053    
2021-11-16 03:33:02,491 - Test: [  140/  195]    Loss 1.340640    Top1 67.017299    Top5 88.155692    
2021-11-16 03:33:20,852 - Test: [  150/  195]    Loss 1.343337    Top1 67.010417    Top5 88.143229    
2021-11-16 03:33:38,988 - Test: [  160/  195]    Loss 1.340970    Top1 67.009277    Top5 88.183594    
2021-11-16 03:33:56,979 - Test: [  170/  195]    Loss 1.343185    Top1 66.941636    Top5 88.143382    
2021-11-16 03:34:15,197 - Test: [  180/  195]    Loss 1.343248    Top1 66.914062    Top5 88.166233    
2021-11-16 03:34:33,275 - Test: [  190/  195]    Loss 1.346098    Top1 66.893503    Top5 88.143503    
2021-11-16 03:34:43,033 - ==> Top1: 66.846    Top5: 88.128    Loss: 1.347

2021-11-16 03:34:46,259 - --- test ---------------------
2021-11-16 03:34:46,259 - 50000 samples (256 per mini-batch)
2021-11-16 03:35:07,401 - Test: [   10/  195]    Loss 1.360027    Top1 67.578125    Top5 87.304688    
2021-11-16 03:35:25,570 - Test: [   20/  195]    Loss 1.357014    Top1 67.304688    Top5 87.812500    
2021-11-16 03:35:43,734 - Test: [   30/  195]    Loss 1.361630    Top1 66.848958    Top5 87.799479    
2021-11-16 03:36:01,812 - Test: [   40/  195]    Loss 1.365553    Top1 66.816406    Top5 87.705078    
2021-11-16 03:36:20,004 - Test: [   50/  195]    Loss 1.370823    Top1 66.625000    Top5 87.648438    
2021-11-16 03:36:38,068 - Test: [   60/  195]    Loss 1.357840    Top1 66.861979    Top5 87.877604    
2021-11-16 03:36:56,177 - Test: [   70/  195]    Loss 1.352347    Top1 67.020089    Top5 87.963170    
2021-11-16 03:37:14,297 - Test: [   80/  195]    Loss 1.349503    Top1 67.036133    Top5 88.007812    
2021-11-16 03:37:32,512 - Test: [   90/  195]    Loss 1.350732    Top1 66.983507    Top5 87.973090    
2021-11-16 03:37:50,518 - Test: [  100/  195]    Loss 1.358744    Top1 66.894531    Top5 87.855469    
2021-11-16 03:38:08,813 - Test: [  110/  195]    Loss 1.363169    Top1 66.782670    Top5 87.791193    
2021-11-16 03:38:27,127 - Test: [  120/  195]    Loss 1.365014    Top1 66.757812    Top5 87.721354    
2021-11-16 03:38:45,212 - Test: [  130/  195]    Loss 1.364651    Top1 66.748798    Top5 87.713341    
2021-11-16 03:39:03,432 - Test: [  140/  195]    Loss 1.361075    Top1 66.771763    Top5 87.820871    
2021-11-16 03:39:21,620 - Test: [  150/  195]    Loss 1.359641    Top1 66.773438    Top5 87.859375    
2021-11-16 03:39:39,765 - Test: [  160/  195]    Loss 1.358418    Top1 66.748047    Top5 87.868652    
2021-11-16 03:39:58,109 - Test: [  170/  195]    Loss 1.361500    Top1 66.730239    Top5 87.775735    
2021-11-16 03:40:16,187 - Test: [  180/  195]    Loss 1.362896    Top1 66.714410    Top5 87.760417    
2021-11-16 03:40:34,216 - Test: [  190/  195]    Loss 1.365410    Top1 66.640625    Top5 87.738487    
2021-11-16 03:40:43,940 - ==> Top1: 66.596    Top5: 87.684    Loss: 1.368

2021-11-16 03:40:47,289 - --- test ---------------------
2021-11-16 03:40:47,290 - 50000 samples (256 per mini-batch)
2021-11-16 03:41:08,076 - Test: [   10/  195]    Loss 1.394390    Top1 65.781250    Top5 87.539062    
2021-11-16 03:41:26,156 - Test: [   20/  195]    Loss 1.385402    Top1 65.703125    Top5 87.363281    
2021-11-16 03:41:44,324 - Test: [   30/  195]    Loss 1.383431    Top1 65.442708    Top5 87.486979    
2021-11-16 03:42:02,376 - Test: [   40/  195]    Loss 1.394504    Top1 65.156250    Top5 87.373047    
2021-11-16 03:42:20,628 - Test: [   50/  195]    Loss 1.390664    Top1 65.359375    Top5 87.382812    
2021-11-16 03:42:38,828 - Test: [   60/  195]    Loss 1.404818    Top1 65.325521    Top5 87.096354    
2021-11-16 03:42:57,003 - Test: [   70/  195]    Loss 1.404627    Top1 65.507812    Top5 87.137277    
2021-11-16 03:43:15,177 - Test: [   80/  195]    Loss 1.412554    Top1 65.317383    Top5 87.001953    
2021-11-16 03:43:33,661 - Test: [   90/  195]    Loss 1.414599    Top1 65.316840    Top5 86.961806    
2021-11-16 03:43:51,823 - Test: [  100/  195]    Loss 1.416325    Top1 65.398438    Top5 86.968750    
2021-11-16 03:44:09,944 - Test: [  110/  195]    Loss 1.421598    Top1 65.245028    Top5 86.928267    
2021-11-16 03:44:28,021 - Test: [  120/  195]    Loss 1.418595    Top1 65.403646    Top5 86.956380    
2021-11-16 03:44:46,508 - Test: [  130/  195]    Loss 1.421614    Top1 65.315505    Top5 86.944111    
2021-11-16 03:45:04,628 - Test: [  140/  195]    Loss 1.421330    Top1 65.304129    Top5 86.964286    
2021-11-16 03:45:22,684 - Test: [  150/  195]    Loss 1.420290    Top1 65.239583    Top5 87.028646    
2021-11-16 03:45:40,793 - Test: [  160/  195]    Loss 1.420647    Top1 65.209961    Top5 87.028809    
2021-11-16 03:45:59,096 - Test: [  170/  195]    Loss 1.417616    Top1 65.278033    Top5 87.095588    
2021-11-16 03:46:17,040 - Test: [  180/  195]    Loss 1.418372    Top1 65.260417    Top5 87.076823    
2021-11-16 03:46:35,075 - Test: [  190/  195]    Loss 1.421717    Top1 65.195312    Top5 87.047697    
2021-11-16 03:46:44,952 - ==> Top1: 65.188    Top5: 87.060    Loss: 1.422

2021-11-16 03:46:48,491 - --- test ---------------------
2021-11-16 03:46:48,491 - 50000 samples (256 per mini-batch)
2021-11-16 03:47:10,369 - Test: [   10/  195]    Loss 1.360127    Top1 66.406250    Top5 88.281250    
2021-11-16 03:47:28,426 - Test: [   20/  195]    Loss 1.362779    Top1 66.406250    Top5 88.164062    
2021-11-16 03:47:46,458 - Test: [   30/  195]    Loss 1.353370    Top1 66.640625    Top5 88.216146    
2021-11-16 03:48:04,775 - Test: [   40/  195]    Loss 1.353129    Top1 66.806641    Top5 88.134766    
2021-11-16 03:48:23,134 - Test: [   50/  195]    Loss 1.351130    Top1 66.679688    Top5 88.101562    
2021-11-16 03:48:41,483 - Test: [   60/  195]    Loss 1.352988    Top1 66.764323    Top5 87.994792    
2021-11-16 03:48:59,703 - Test: [   70/  195]    Loss 1.354311    Top1 66.674107    Top5 88.080357    
2021-11-16 03:49:17,720 - Test: [   80/  195]    Loss 1.361051    Top1 66.611328    Top5 88.017578    
2021-11-16 03:49:35,867 - Test: [   90/  195]    Loss 1.372662    Top1 66.393229    Top5 87.786458    
2021-11-16 03:49:54,357 - Test: [  100/  195]    Loss 1.374175    Top1 66.445312    Top5 87.738281    
2021-11-16 03:50:12,419 - Test: [  110/  195]    Loss 1.368650    Top1 66.558949    Top5 87.808949    
2021-11-16 03:50:30,506 - Test: [  120/  195]    Loss 1.373950    Top1 66.429036    Top5 87.747396    
2021-11-16 03:50:48,821 - Test: [  130/  195]    Loss 1.372688    Top1 66.448317    Top5 87.803486    
2021-11-16 03:51:06,979 - Test: [  140/  195]    Loss 1.369939    Top1 66.464844    Top5 87.818080    
2021-11-16 03:51:25,060 - Test: [  150/  195]    Loss 1.369141    Top1 66.479167    Top5 87.841146    
2021-11-16 03:51:43,101 - Test: [  160/  195]    Loss 1.372020    Top1 66.467285    Top5 87.800293    
2021-11-16 03:52:01,254 - Test: [  170/  195]    Loss 1.370834    Top1 66.461397    Top5 87.819393    
2021-11-16 03:52:19,263 - Test: [  180/  195]    Loss 1.374491    Top1 66.417101    Top5 87.747396    
2021-11-16 03:52:37,396 - Test: [  190/  195]    Loss 1.372835    Top1 66.451480    Top5 87.785773    
2021-11-16 03:52:47,208 - ==> Top1: 66.414    Top5: 87.788    Loss: 1.373

2021-11-16 03:52:50,821 - --- test ---------------------
2021-11-16 03:52:50,822 - 50000 samples (256 per mini-batch)
2021-11-16 03:53:12,041 - Test: [   10/  195]    Loss 1.428247    Top1 65.781250    Top5 87.500000    
2021-11-16 03:53:30,233 - Test: [   20/  195]    Loss 1.435152    Top1 65.917969    Top5 87.265625    
2021-11-16 03:53:48,601 - Test: [   30/  195]    Loss 1.426670    Top1 65.729167    Top5 87.278646    
2021-11-16 03:54:06,817 - Test: [   40/  195]    Loss 1.409325    Top1 65.869141    Top5 87.480469    
2021-11-16 03:54:25,252 - Test: [   50/  195]    Loss 1.415285    Top1 65.835938    Top5 87.468750    
2021-11-16 03:54:43,418 - Test: [   60/  195]    Loss 1.409670    Top1 65.957031    Top5 87.473958    
2021-11-16 03:55:01,600 - Test: [   70/  195]    Loss 1.410179    Top1 65.954241    Top5 87.444196    
2021-11-16 03:55:19,788 - Test: [   80/  195]    Loss 1.412287    Top1 65.961914    Top5 87.373047    
2021-11-16 03:55:37,839 - Test: [   90/  195]    Loss 1.414820    Top1 65.868056    Top5 87.309028    
2021-11-16 03:55:56,244 - Test: [  100/  195]    Loss 1.410430    Top1 65.890625    Top5 87.343750    
2021-11-16 03:56:14,314 - Test: [  110/  195]    Loss 1.413168    Top1 65.806108    Top5 87.283381    
2021-11-16 03:56:32,556 - Test: [  120/  195]    Loss 1.414723    Top1 65.787760    Top5 87.275391    
2021-11-16 03:56:50,851 - Test: [  130/  195]    Loss 1.413985    Top1 65.844351    Top5 87.271635    
2021-11-16 03:57:09,020 - Test: [  140/  195]    Loss 1.414464    Top1 65.803571    Top5 87.248884    
2021-11-16 03:57:27,149 - Test: [  150/  195]    Loss 1.418404    Top1 65.750000    Top5 87.236979    
2021-11-16 03:57:45,223 - Test: [  160/  195]    Loss 1.421967    Top1 65.612793    Top5 87.141113    
2021-11-16 03:58:03,129 - Test: [  170/  195]    Loss 1.422748    Top1 65.574449    Top5 87.120864    
2021-11-16 03:58:21,137 - Test: [  180/  195]    Loss 1.422631    Top1 65.609809    Top5 87.122396    
2021-11-16 03:58:39,329 - Test: [  190/  195]    Loss 1.425030    Top1 65.573602    Top5 87.074424    
2021-11-16 03:58:49,099 - ==> Top1: 65.544    Top5: 87.058    Loss: 1.428

2021-11-16 03:58:52,875 - --- test ---------------------
2021-11-16 03:58:52,876 - 50000 samples (256 per mini-batch)
2021-11-16 03:59:14,080 - Test: [   10/  195]    Loss 1.402225    Top1 65.351562    Top5 87.851562    
2021-11-16 03:59:32,346 - Test: [   20/  195]    Loss 1.392965    Top1 65.566406    Top5 87.851562    
2021-11-16 03:59:50,282 - Test: [   30/  195]    Loss 1.390031    Top1 65.546875    Top5 87.760417    
2021-11-16 04:00:08,587 - Test: [   40/  195]    Loss 1.372616    Top1 65.703125    Top5 87.978516    
2021-11-16 04:00:26,768 - Test: [   50/  195]    Loss 1.376589    Top1 65.820312    Top5 87.921875    
2021-11-16 04:00:45,004 - Test: [   60/  195]    Loss 1.376582    Top1 65.787760    Top5 87.890625    
2021-11-16 04:01:03,116 - Test: [   70/  195]    Loss 1.384156    Top1 65.680804    Top5 87.818080    
2021-11-16 04:01:21,378 - Test: [   80/  195]    Loss 1.379620    Top1 65.883789    Top5 87.827148    
2021-11-16 04:01:39,662 - Test: [   90/  195]    Loss 1.380240    Top1 65.872396    Top5 87.825521    
2021-11-16 04:01:57,992 - Test: [  100/  195]    Loss 1.383892    Top1 65.765625    Top5 87.714844    
2021-11-16 04:02:16,167 - Test: [  110/  195]    Loss 1.389298    Top1 65.550426    Top5 87.649148    
2021-11-16 04:02:34,467 - Test: [  120/  195]    Loss 1.385423    Top1 65.631510    Top5 87.643229    
2021-11-16 04:02:52,621 - Test: [  130/  195]    Loss 1.387113    Top1 65.739183    Top5 87.584135    
2021-11-16 04:03:10,675 - Test: [  140/  195]    Loss 1.385822    Top1 65.719866    Top5 87.636719    
2021-11-16 04:03:28,807 - Test: [  150/  195]    Loss 1.389162    Top1 65.651042    Top5 87.638021    
2021-11-16 04:03:46,795 - Test: [  160/  195]    Loss 1.387329    Top1 65.729980    Top5 87.629395    
2021-11-16 04:04:04,836 - Test: [  170/  195]    Loss 1.385108    Top1 65.801930    Top5 87.647059    
2021-11-16 04:04:23,001 - Test: [  180/  195]    Loss 1.386070    Top1 65.761719    Top5 87.606337    
2021-11-16 04:04:41,033 - Test: [  190/  195]    Loss 1.384236    Top1 65.768914    Top5 87.631579    
2021-11-16 04:04:50,867 - ==> Top1: 65.756    Top5: 87.630    Loss: 1.384

2021-11-16 04:04:54,699 - --- test ---------------------
2021-11-16 04:04:54,699 - 50000 samples (256 per mini-batch)
2021-11-16 04:05:15,425 - Test: [   10/  195]    Loss 1.343688    Top1 66.679688    Top5 89.023438    
2021-11-16 04:05:33,483 - Test: [   20/  195]    Loss 1.334258    Top1 67.402344    Top5 88.632812    
2021-11-16 04:05:51,565 - Test: [   30/  195]    Loss 1.332263    Top1 67.395833    Top5 88.554688    
2021-11-16 04:06:09,826 - Test: [   40/  195]    Loss 1.320546    Top1 67.421875    Top5 88.574219    
2021-11-16 04:06:27,903 - Test: [   50/  195]    Loss 1.321839    Top1 67.234375    Top5 88.539062    
2021-11-16 04:06:46,115 - Test: [   60/  195]    Loss 1.330269    Top1 67.024740    Top5 88.339844    
2021-11-16 04:07:04,356 - Test: [   70/  195]    Loss 1.327767    Top1 67.092634    Top5 88.376116    
2021-11-16 04:07:22,416 - Test: [   80/  195]    Loss 1.321065    Top1 67.285156    Top5 88.461914    
2021-11-16 04:07:40,670 - Test: [   90/  195]    Loss 1.319377    Top1 67.356771    Top5 88.528646    
2021-11-16 04:07:58,815 - Test: [  100/  195]    Loss 1.313543    Top1 67.429688    Top5 88.632812    
2021-11-16 04:08:17,158 - Test: [  110/  195]    Loss 1.316843    Top1 67.311790    Top5 88.615057    
2021-11-16 04:08:35,354 - Test: [  120/  195]    Loss 1.320544    Top1 67.226562    Top5 88.570964    
2021-11-16 04:08:53,435 - Test: [  130/  195]    Loss 1.318768    Top1 67.202524    Top5 88.626803    
2021-11-16 04:09:11,573 - Test: [  140/  195]    Loss 1.314642    Top1 67.181920    Top5 88.669085    
2021-11-16 04:09:29,696 - Test: [  150/  195]    Loss 1.318074    Top1 67.093750    Top5 88.604167    
2021-11-16 04:09:47,853 - Test: [  160/  195]    Loss 1.313450    Top1 67.214355    Top5 88.635254    
2021-11-16 04:10:05,997 - Test: [  170/  195]    Loss 1.319712    Top1 67.097886    Top5 88.547794    
2021-11-16 04:10:23,966 - Test: [  180/  195]    Loss 1.317700    Top1 67.135417    Top5 88.559028    
2021-11-16 04:10:42,172 - Test: [  190/  195]    Loss 1.317804    Top1 67.142270    Top5 88.552632    
2021-11-16 04:10:51,985 - ==> Top1: 67.130    Top5: 88.582    Loss: 1.317

2021-11-16 04:10:55,845 - --- test ---------------------
2021-11-16 04:10:55,846 - 50000 samples (256 per mini-batch)
2021-11-16 04:11:17,013 - Test: [   10/  195]    Loss 1.316265    Top1 67.773438    Top5 88.320312    
2021-11-16 04:11:35,091 - Test: [   20/  195]    Loss 1.347099    Top1 66.679688    Top5 88.144531    
2021-11-16 04:11:53,198 - Test: [   30/  195]    Loss 1.354322    Top1 66.653646    Top5 88.125000    
2021-11-16 04:12:11,344 - Test: [   40/  195]    Loss 1.355850    Top1 66.660156    Top5 88.232422    
2021-11-16 04:12:29,564 - Test: [   50/  195]    Loss 1.359362    Top1 66.421875    Top5 88.148438    
2021-11-16 04:12:47,761 - Test: [   60/  195]    Loss 1.352612    Top1 66.647135    Top5 88.235677    
2021-11-16 04:13:05,872 - Test: [   70/  195]    Loss 1.351942    Top1 66.780134    Top5 88.214286    
2021-11-16 04:13:24,109 - Test: [   80/  195]    Loss 1.352312    Top1 66.801758    Top5 88.090820    
2021-11-16 04:13:42,173 - Test: [   90/  195]    Loss 1.356397    Top1 66.688368    Top5 88.007812    
2021-11-16 04:14:00,270 - Test: [  100/  195]    Loss 1.353715    Top1 66.621094    Top5 88.082031    
2021-11-16 04:14:18,300 - Test: [  110/  195]    Loss 1.353782    Top1 66.697443    Top5 88.064631    
2021-11-16 04:14:36,596 - Test: [  120/  195]    Loss 1.358249    Top1 66.608073    Top5 87.968750    
2021-11-16 04:14:54,658 - Test: [  130/  195]    Loss 1.363147    Top1 66.538462    Top5 87.872596    
2021-11-16 04:15:12,809 - Test: [  140/  195]    Loss 1.357936    Top1 66.607143    Top5 87.918527    
2021-11-16 04:15:31,042 - Test: [  150/  195]    Loss 1.357783    Top1 66.622396    Top5 87.908854    
2021-11-16 04:15:49,141 - Test: [  160/  195]    Loss 1.358759    Top1 66.577148    Top5 87.871094    
2021-11-16 04:16:07,102 - Test: [  170/  195]    Loss 1.365318    Top1 66.431526    Top5 87.784926    
2021-11-16 04:16:25,163 - Test: [  180/  195]    Loss 1.364645    Top1 66.449653    Top5 87.842882    
2021-11-16 04:16:43,179 - Test: [  190/  195]    Loss 1.364188    Top1 66.441201    Top5 87.839227    
2021-11-16 04:16:53,086 - ==> Top1: 66.450    Top5: 87.832    Loss: 1.364

2021-11-16 04:16:56,926 - --- test ---------------------
2021-11-16 04:16:56,926 - 50000 samples (256 per mini-batch)
2021-11-16 04:17:17,536 - Test: [   10/  195]    Loss 1.537849    Top1 62.773437    Top5 85.117188    
2021-11-16 04:17:35,598 - Test: [   20/  195]    Loss 1.528017    Top1 62.871094    Top5 84.863281    
2021-11-16 04:17:53,787 - Test: [   30/  195]    Loss 1.519554    Top1 63.528646    Top5 84.973958    
2021-11-16 04:18:11,995 - Test: [   40/  195]    Loss 1.543430    Top1 62.861328    Top5 84.882812    
2021-11-16 04:18:30,285 - Test: [   50/  195]    Loss 1.547844    Top1 62.640625    Top5 85.140625    
2021-11-16 04:18:48,416 - Test: [   60/  195]    Loss 1.562620    Top1 62.233073    Top5 84.980469    
2021-11-16 04:19:06,803 - Test: [   70/  195]    Loss 1.564404    Top1 62.209821    Top5 84.988839    
2021-11-16 04:19:25,053 - Test: [   80/  195]    Loss 1.561096    Top1 62.128906    Top5 85.053711    
2021-11-16 04:19:43,296 - Test: [   90/  195]    Loss 1.562262    Top1 62.126736    Top5 84.973958    
2021-11-16 04:20:01,457 - Test: [  100/  195]    Loss 1.569752    Top1 62.101563    Top5 84.878906    
2021-11-16 04:20:19,871 - Test: [  110/  195]    Loss 1.566573    Top1 62.187500    Top5 84.882812    
2021-11-16 04:20:37,844 - Test: [  120/  195]    Loss 1.573300    Top1 62.047526    Top5 84.866536    
2021-11-16 04:20:55,940 - Test: [  130/  195]    Loss 1.570545    Top1 62.040264    Top5 84.906851    
2021-11-16 04:21:14,118 - Test: [  140/  195]    Loss 1.567413    Top1 62.081473    Top5 84.944196    
2021-11-16 04:21:32,405 - Test: [  150/  195]    Loss 1.566989    Top1 62.130208    Top5 84.921875    
2021-11-16 04:21:50,390 - Test: [  160/  195]    Loss 1.565083    Top1 62.075195    Top5 84.946289    
2021-11-16 04:22:08,623 - Test: [  170/  195]    Loss 1.563362    Top1 62.169118    Top5 84.981618    
2021-11-16 04:22:26,780 - Test: [  180/  195]    Loss 1.566914    Top1 62.076823    Top5 84.930556    
2021-11-16 04:22:44,765 - Test: [  190/  195]    Loss 1.568255    Top1 62.008635    Top5 84.930099    
2021-11-16 04:22:54,798 - ==> Top1: 61.982    Top5: 84.926    Loss: 1.569

2021-11-16 04:22:58,416 - --- test ---------------------
2021-11-16 04:22:58,416 - 50000 samples (256 per mini-batch)
2021-11-16 04:23:18,951 - Test: [   10/  195]    Loss 1.337804    Top1 65.859375    Top5 89.101562    
2021-11-16 04:23:37,074 - Test: [   20/  195]    Loss 1.335546    Top1 66.289062    Top5 88.828125    
2021-11-16 04:23:55,122 - Test: [   30/  195]    Loss 1.340750    Top1 66.393229    Top5 88.671875    
2021-11-16 04:24:13,369 - Test: [   40/  195]    Loss 1.330642    Top1 66.591797    Top5 88.759766    
2021-11-16 04:24:31,589 - Test: [   50/  195]    Loss 1.319890    Top1 66.656250    Top5 88.992188    
2021-11-16 04:24:49,914 - Test: [   60/  195]    Loss 1.323749    Top1 66.731771    Top5 88.808594    
2021-11-16 04:25:08,134 - Test: [   70/  195]    Loss 1.326819    Top1 66.679688    Top5 88.710938    
2021-11-16 04:25:26,476 - Test: [   80/  195]    Loss 1.324869    Top1 66.704102    Top5 88.823242    
2021-11-16 04:25:44,765 - Test: [   90/  195]    Loss 1.319416    Top1 66.861979    Top5 88.849826    
2021-11-16 04:26:03,117 - Test: [  100/  195]    Loss 1.324162    Top1 66.843750    Top5 88.753906    
2021-11-16 04:26:21,425 - Test: [  110/  195]    Loss 1.318706    Top1 66.970881    Top5 88.785511    
2021-11-16 04:26:39,620 - Test: [  120/  195]    Loss 1.313821    Top1 67.063802    Top5 88.808594    
2021-11-16 04:26:57,796 - Test: [  130/  195]    Loss 1.311053    Top1 67.151442    Top5 88.816106    
2021-11-16 04:27:16,109 - Test: [  140/  195]    Loss 1.313550    Top1 67.159598    Top5 88.794643    
2021-11-16 04:27:34,313 - Test: [  150/  195]    Loss 1.311222    Top1 67.164062    Top5 88.809896    
2021-11-16 04:27:52,377 - Test: [  160/  195]    Loss 1.312807    Top1 67.138672    Top5 88.774414    
2021-11-16 04:28:10,470 - Test: [  170/  195]    Loss 1.312514    Top1 67.125460    Top5 88.759191    
2021-11-16 04:28:28,661 - Test: [  180/  195]    Loss 1.311760    Top1 67.141927    Top5 88.754340    
2021-11-16 04:28:46,660 - Test: [  190/  195]    Loss 1.312199    Top1 67.113487    Top5 88.754112    
2021-11-16 04:28:56,782 - ==> Top1: 67.078    Top5: 88.756    Loss: 1.316

2021-11-16 04:29:00,559 - --- test ---------------------
2021-11-16 04:29:00,559 - 50000 samples (256 per mini-batch)
2021-11-16 04:29:22,467 - Test: [   10/  195]    Loss 1.331222    Top1 67.578125    Top5 87.734375    
2021-11-16 04:29:40,523 - Test: [   20/  195]    Loss 1.334434    Top1 67.480469    Top5 87.812500    
2021-11-16 04:29:58,576 - Test: [   30/  195]    Loss 1.320062    Top1 67.851562    Top5 88.151042    
2021-11-16 04:30:16,961 - Test: [   40/  195]    Loss 1.307942    Top1 68.027344    Top5 88.134766    
2021-11-16 04:30:35,040 - Test: [   50/  195]    Loss 1.314766    Top1 67.882812    Top5 88.109375    
2021-11-16 04:30:53,243 - Test: [   60/  195]    Loss 1.316699    Top1 67.727865    Top5 88.066406    
2021-11-16 04:31:11,480 - Test: [   70/  195]    Loss 1.311780    Top1 67.773438    Top5 88.169643    
2021-11-16 04:31:29,689 - Test: [   80/  195]    Loss 1.308886    Top1 67.866211    Top5 88.208008    
2021-11-16 04:31:48,007 - Test: [   90/  195]    Loss 1.310978    Top1 67.743056    Top5 88.298611    
2021-11-16 04:32:06,131 - Test: [  100/  195]    Loss 1.315096    Top1 67.519531    Top5 88.292969    
2021-11-16 04:32:24,437 - Test: [  110/  195]    Loss 1.314693    Top1 67.574574    Top5 88.323864    
2021-11-16 04:32:42,599 - Test: [  120/  195]    Loss 1.310509    Top1 67.685547    Top5 88.427734    
2021-11-16 04:33:00,680 - Test: [  130/  195]    Loss 1.307304    Top1 67.725361    Top5 88.533654    
2021-11-16 04:33:18,740 - Test: [  140/  195]    Loss 1.306684    Top1 67.734375    Top5 88.599330    
2021-11-16 04:33:36,948 - Test: [  150/  195]    Loss 1.310023    Top1 67.648438    Top5 88.518229    
2021-11-16 04:33:55,043 - Test: [  160/  195]    Loss 1.312694    Top1 67.563477    Top5 88.486328    
2021-11-16 04:34:13,228 - Test: [  170/  195]    Loss 1.311258    Top1 67.587316    Top5 88.501838    
2021-11-16 04:34:31,415 - Test: [  180/  195]    Loss 1.313438    Top1 67.480469    Top5 88.480903    
2021-11-16 04:34:49,513 - Test: [  190/  195]    Loss 1.312014    Top1 67.514391    Top5 88.476562    
2021-11-16 04:34:59,351 - ==> Top1: 67.562    Top5: 88.522    Loss: 1.309

2021-11-16 04:35:03,375 - --- test ---------------------
2021-11-16 04:35:03,376 - 50000 samples (256 per mini-batch)
2021-11-16 04:35:25,450 - Test: [   10/  195]    Loss 1.333850    Top1 66.289062    Top5 88.046875    
2021-11-16 04:35:43,472 - Test: [   20/  195]    Loss 1.340606    Top1 66.289062    Top5 87.949219    
2021-11-16 04:36:01,810 - Test: [   30/  195]    Loss 1.321230    Top1 66.692708    Top5 88.046875    
2021-11-16 04:36:19,856 - Test: [   40/  195]    Loss 1.345317    Top1 66.054688    Top5 87.871094    
2021-11-16 04:36:38,026 - Test: [   50/  195]    Loss 1.348275    Top1 65.937500    Top5 87.937500    
2021-11-16 04:36:56,213 - Test: [   60/  195]    Loss 1.350771    Top1 66.119792    Top5 88.066406    
2021-11-16 04:37:14,609 - Test: [   70/  195]    Loss 1.354338    Top1 65.954241    Top5 88.091518    
2021-11-16 04:37:32,710 - Test: [   80/  195]    Loss 1.356807    Top1 66.059570    Top5 88.076172    
2021-11-16 04:37:50,982 - Test: [   90/  195]    Loss 1.352065    Top1 66.076389    Top5 88.129340    
2021-11-16 04:38:09,140 - Test: [  100/  195]    Loss 1.356110    Top1 66.042969    Top5 88.054688    
2021-11-16 04:38:27,356 - Test: [  110/  195]    Loss 1.356437    Top1 66.104403    Top5 88.014915    
2021-11-16 04:38:45,825 - Test: [  120/  195]    Loss 1.358957    Top1 66.038411    Top5 87.975260    
2021-11-16 04:39:03,896 - Test: [  130/  195]    Loss 1.356406    Top1 66.123798    Top5 88.022837    
2021-11-16 04:39:22,101 - Test: [  140/  195]    Loss 1.361937    Top1 66.015625    Top5 87.954799    
2021-11-16 04:39:40,285 - Test: [  150/  195]    Loss 1.363561    Top1 66.013021    Top5 87.945312    
2021-11-16 04:39:58,523 - Test: [  160/  195]    Loss 1.366630    Top1 65.935059    Top5 87.902832    
2021-11-16 04:40:16,972 - Test: [  170/  195]    Loss 1.366153    Top1 65.930607    Top5 87.936581    
2021-11-16 04:40:34,878 - Test: [  180/  195]    Loss 1.370558    Top1 65.846354    Top5 87.877604    
2021-11-16 04:40:52,968 - Test: [  190/  195]    Loss 1.368610    Top1 65.927220    Top5 87.913240    
2021-11-16 04:41:02,994 - ==> Top1: 65.966    Top5: 87.926    Loss: 1.369

2021-11-16 04:41:07,149 - --- test ---------------------
2021-11-16 04:41:07,150 - 50000 samples (256 per mini-batch)
2021-11-16 04:41:29,070 - Test: [   10/  195]    Loss 1.388001    Top1 65.937500    Top5 87.773438    
2021-11-16 04:41:47,137 - Test: [   20/  195]    Loss 1.403814    Top1 65.253906    Top5 87.675781    
2021-11-16 04:42:05,488 - Test: [   30/  195]    Loss 1.429609    Top1 65.208333    Top5 87.330729    
2021-11-16 04:42:23,671 - Test: [   40/  195]    Loss 1.429851    Top1 65.292969    Top5 87.509766    
2021-11-16 04:42:41,875 - Test: [   50/  195]    Loss 1.438646    Top1 65.218750    Top5 87.398438    
2021-11-16 04:43:00,339 - Test: [   60/  195]    Loss 1.452662    Top1 64.889323    Top5 87.109375    
2021-11-16 04:43:18,584 - Test: [   70/  195]    Loss 1.457326    Top1 64.849330    Top5 87.087054    
2021-11-16 04:43:36,757 - Test: [   80/  195]    Loss 1.449569    Top1 64.916992    Top5 87.045898    
2021-11-16 04:43:54,983 - Test: [   90/  195]    Loss 1.444000    Top1 64.969618    Top5 87.144097    
2021-11-16 04:44:13,057 - Test: [  100/  195]    Loss 1.441615    Top1 65.160156    Top5 87.152344    
2021-11-16 04:44:31,364 - Test: [  110/  195]    Loss 1.441092    Top1 65.181108    Top5 87.098722    
2021-11-16 04:44:49,507 - Test: [  120/  195]    Loss 1.439106    Top1 65.244141    Top5 87.102865    
2021-11-16 04:45:07,534 - Test: [  130/  195]    Loss 1.443720    Top1 65.159255    Top5 87.016226    
2021-11-16 04:45:25,793 - Test: [  140/  195]    Loss 1.444488    Top1 65.161830    Top5 87.022879    
2021-11-16 04:45:43,942 - Test: [  150/  195]    Loss 1.442632    Top1 65.221354    Top5 87.020833    
2021-11-16 04:46:02,036 - Test: [  160/  195]    Loss 1.445134    Top1 65.178223    Top5 86.977539    
2021-11-16 04:46:20,201 - Test: [  170/  195]    Loss 1.445276    Top1 65.195312    Top5 86.937040    
2021-11-16 04:46:38,226 - Test: [  180/  195]    Loss 1.445255    Top1 65.132378    Top5 86.931424    
2021-11-16 04:46:56,541 - Test: [  190/  195]    Loss 1.444016    Top1 65.131579    Top5 86.942845    
2021-11-16 04:47:06,289 - ==> Top1: 65.158    Top5: 86.950    Loss: 1.441

2021-11-16 04:47:10,316 - --- test ---------------------
2021-11-16 04:47:10,317 - 50000 samples (256 per mini-batch)
2021-11-16 04:47:31,569 - Test: [   10/  195]    Loss 3.107897    Top1 39.335937    Top5 64.687500    
2021-11-16 04:47:49,729 - Test: [   20/  195]    Loss 3.049100    Top1 41.074219    Top5 65.722656    
2021-11-16 04:48:07,801 - Test: [   30/  195]    Loss 3.043547    Top1 41.679687    Top5 65.585938    
2021-11-16 04:48:25,981 - Test: [   40/  195]    Loss 3.040538    Top1 41.611328    Top5 66.015625    
2021-11-16 04:48:44,249 - Test: [   50/  195]    Loss 3.040930    Top1 41.742188    Top5 66.132812    
2021-11-16 04:49:02,397 - Test: [   60/  195]    Loss 3.040506    Top1 41.783854    Top5 66.197917    
2021-11-16 04:49:20,752 - Test: [   70/  195]    Loss 3.030388    Top1 42.176339    Top5 66.445312    
2021-11-16 04:49:38,850 - Test: [   80/  195]    Loss 3.031637    Top1 42.167969    Top5 66.611328    
2021-11-16 04:49:56,958 - Test: [   90/  195]    Loss 3.024445    Top1 42.191840    Top5 66.657986    
2021-11-16 04:50:15,140 - Test: [  100/  195]    Loss 3.023190    Top1 42.203125    Top5 66.761719    
2021-11-16 04:50:33,475 - Test: [  110/  195]    Loss 3.023567    Top1 42.194602    Top5 66.775568    
2021-11-16 04:50:51,653 - Test: [  120/  195]    Loss 3.027953    Top1 42.086589    Top5 66.689453    
2021-11-16 04:51:09,657 - Test: [  130/  195]    Loss 3.027330    Top1 42.037260    Top5 66.658654    
2021-11-16 04:51:27,838 - Test: [  140/  195]    Loss 3.025471    Top1 42.034040    Top5 66.766183    
2021-11-16 04:51:46,247 - Test: [  150/  195]    Loss 3.025736    Top1 42.046875    Top5 66.731771    
2021-11-16 04:52:04,320 - Test: [  160/  195]    Loss 3.018900    Top1 42.211914    Top5 66.848145    
2021-11-16 04:52:22,414 - Test: [  170/  195]    Loss 3.020125    Top1 42.182904    Top5 66.914062    
2021-11-16 04:52:40,597 - Test: [  180/  195]    Loss 3.019897    Top1 42.200521    Top5 66.901042    
2021-11-16 04:52:58,781 - Test: [  190/  195]    Loss 3.014946    Top1 42.345806    Top5 66.979852    
2021-11-16 04:53:08,829 - ==> Top1: 42.322    Top5: 67.006    Loss: 3.014

2021-11-16 04:53:12,821 - --- test ---------------------
2021-11-16 04:53:12,821 - 50000 samples (256 per mini-batch)
2021-11-16 04:53:34,765 - Test: [   10/  195]    Loss 3.699799    Top1 31.718750    Top5 54.492188    
2021-11-16 04:53:52,648 - Test: [   20/  195]    Loss 3.732172    Top1 31.171875    Top5 54.375000    
2021-11-16 04:54:10,712 - Test: [   30/  195]    Loss 3.734212    Top1 31.471354    Top5 54.153646    
2021-11-16 04:54:28,807 - Test: [   40/  195]    Loss 3.717807    Top1 31.650391    Top5 54.677734    
2021-11-16 04:54:46,840 - Test: [   50/  195]    Loss 3.693422    Top1 32.164062    Top5 55.367188    
2021-11-16 04:55:04,908 - Test: [   60/  195]    Loss 3.686459    Top1 32.246094    Top5 55.533854    
2021-11-16 04:55:23,191 - Test: [   70/  195]    Loss 3.688995    Top1 32.271205    Top5 55.379464    
2021-11-16 04:55:41,403 - Test: [   80/  195]    Loss 3.696245    Top1 32.226562    Top5 55.205078    
2021-11-16 04:55:59,420 - Test: [   90/  195]    Loss 3.702217    Top1 32.165799    Top5 55.086806    
2021-11-16 04:56:17,472 - Test: [  100/  195]    Loss 3.696314    Top1 32.269531    Top5 55.289063    
2021-11-16 04:56:35,681 - Test: [  110/  195]    Loss 3.697954    Top1 32.226562    Top5 55.337358    
2021-11-16 04:56:53,757 - Test: [  120/  195]    Loss 3.701978    Top1 32.145182    Top5 55.361328    
2021-11-16 04:57:12,004 - Test: [  130/  195]    Loss 3.705903    Top1 32.061298    Top5 55.306490    
2021-11-16 04:57:30,240 - Test: [  140/  195]    Loss 3.707649    Top1 32.053571    Top5 55.292969    
2021-11-16 04:57:48,205 - Test: [  150/  195]    Loss 3.707588    Top1 32.065104    Top5 55.296875    
2021-11-16 04:58:06,240 - Test: [  160/  195]    Loss 3.705556    Top1 32.084961    Top5 55.319824    
2021-11-16 04:58:24,319 - Test: [  170/  195]    Loss 3.708283    Top1 32.054228    Top5 55.353860    
2021-11-16 04:58:42,484 - Test: [  180/  195]    Loss 3.710628    Top1 32.105035    Top5 55.427517    
2021-11-16 04:59:00,600 - Test: [  190/  195]    Loss 3.708038    Top1 32.105263    Top5 55.468750    
2021-11-16 04:59:10,440 - ==> Top1: 32.098    Top5: 55.502    Loss: 3.709

2021-11-16 04:59:13,695 - --- test ---------------------
2021-11-16 04:59:13,695 - 50000 samples (256 per mini-batch)
2021-11-16 04:59:35,638 - Test: [   10/  195]    Loss 3.686576    Top1 33.125000    Top5 56.718750    
2021-11-16 04:59:53,617 - Test: [   20/  195]    Loss 3.679578    Top1 33.164062    Top5 57.128906    
2021-11-16 05:00:11,772 - Test: [   30/  195]    Loss 3.677742    Top1 33.059896    Top5 57.304687    
2021-11-16 05:00:30,016 - Test: [   40/  195]    Loss 3.683175    Top1 33.300781    Top5 57.246094    
2021-11-16 05:00:48,126 - Test: [   50/  195]    Loss 3.688761    Top1 33.335938    Top5 57.070312    
2021-11-16 05:01:06,133 - Test: [   60/  195]    Loss 3.687589    Top1 33.313802    Top5 57.128906    
2021-11-16 05:01:24,305 - Test: [   70/  195]    Loss 3.690189    Top1 33.370536    Top5 57.131696    
2021-11-16 05:01:42,438 - Test: [   80/  195]    Loss 3.692746    Top1 33.178711    Top5 57.065430    
2021-11-16 05:02:00,740 - Test: [   90/  195]    Loss 3.701366    Top1 33.016493    Top5 56.896701    
2021-11-16 05:02:19,007 - Test: [  100/  195]    Loss 3.693147    Top1 33.230469    Top5 57.062500    
2021-11-16 05:02:37,184 - Test: [  110/  195]    Loss 3.687457    Top1 33.295455    Top5 57.155540    
2021-11-16 05:02:55,408 - Test: [  120/  195]    Loss 3.683228    Top1 33.421224    Top5 57.184245    
2021-11-16 05:03:13,536 - Test: [  130/  195]    Loss 3.683882    Top1 33.458534    Top5 57.109375    
2021-11-16 05:03:31,593 - Test: [  140/  195]    Loss 3.688724    Top1 33.426339    Top5 57.011719    
2021-11-16 05:03:49,794 - Test: [  150/  195]    Loss 3.688132    Top1 33.419271    Top5 57.044271    
2021-11-16 05:04:07,800 - Test: [  160/  195]    Loss 3.689074    Top1 33.393555    Top5 56.970215    
2021-11-16 05:04:25,993 - Test: [  170/  195]    Loss 3.690420    Top1 33.386949    Top5 56.987592    
2021-11-16 05:04:44,157 - Test: [  180/  195]    Loss 3.692581    Top1 33.372396    Top5 56.931424    
2021-11-16 05:05:02,229 - Test: [  190/  195]    Loss 3.690722    Top1 33.441612    Top5 56.983964    
2021-11-16 05:05:12,113 - ==> Top1: 33.482    Top5: 56.990    Loss: 3.690

2021-11-16 05:05:15,599 - --- test ---------------------
2021-11-16 05:05:15,600 - 50000 samples (256 per mini-batch)
2021-11-16 05:05:36,734 - Test: [   10/  195]    Loss 3.788505    Top1 30.351562    Top5 54.023438    
2021-11-16 05:05:54,869 - Test: [   20/  195]    Loss 3.798524    Top1 30.214844    Top5 53.906250    
2021-11-16 05:06:12,956 - Test: [   30/  195]    Loss 3.821059    Top1 30.494792    Top5 53.411458    
2021-11-16 05:06:31,117 - Test: [   40/  195]    Loss 3.796781    Top1 30.820313    Top5 53.896484    
2021-11-16 05:06:49,320 - Test: [   50/  195]    Loss 3.793830    Top1 30.835938    Top5 53.898438    
2021-11-16 05:07:07,341 - Test: [   60/  195]    Loss 3.796908    Top1 30.735677    Top5 54.082031    
2021-11-16 05:07:25,389 - Test: [   70/  195]    Loss 3.796577    Top1 30.853795    Top5 54.168527    
2021-11-16 05:07:43,548 - Test: [   80/  195]    Loss 3.795304    Top1 30.830078    Top5 54.228516    
2021-11-16 05:08:01,772 - Test: [   90/  195]    Loss 3.798870    Top1 30.724826    Top5 54.210069    
2021-11-16 05:08:19,948 - Test: [  100/  195]    Loss 3.795150    Top1 30.703125    Top5 54.273438    
2021-11-16 05:08:38,117 - Test: [  110/  195]    Loss 3.797444    Top1 30.706676    Top5 54.247159    
2021-11-16 05:08:56,409 - Test: [  120/  195]    Loss 3.804868    Top1 30.569661    Top5 54.088542    
2021-11-16 05:09:14,569 - Test: [  130/  195]    Loss 3.800859    Top1 30.691106    Top5 54.125601    
2021-11-16 05:09:32,784 - Test: [  140/  195]    Loss 3.806470    Top1 30.566406    Top5 54.009487    
2021-11-16 05:09:50,891 - Test: [  150/  195]    Loss 3.802828    Top1 30.705729    Top5 54.096354    
2021-11-16 05:10:08,757 - Test: [  160/  195]    Loss 3.807949    Top1 30.690918    Top5 53.977051    
2021-11-16 05:10:26,748 - Test: [  170/  195]    Loss 3.812423    Top1 30.576746    Top5 53.880974    
2021-11-16 05:10:44,801 - Test: [  180/  195]    Loss 3.811592    Top1 30.564236    Top5 53.927951    
2021-11-16 05:11:02,757 - Test: [  190/  195]    Loss 3.811012    Top1 30.559211    Top5 53.957648    
2021-11-16 05:11:12,701 - ==> Top1: 30.532    Top5: 53.932    Loss: 3.812

2021-11-16 05:11:16,270 - --- test ---------------------
2021-11-16 05:11:16,271 - 50000 samples (256 per mini-batch)
2021-11-16 05:11:38,417 - Test: [   10/  195]    Loss 3.596806    Top1 33.476562    Top5 57.187500    
2021-11-16 05:11:56,545 - Test: [   20/  195]    Loss 3.615166    Top1 33.417969    Top5 56.992188    
2021-11-16 05:12:14,637 - Test: [   30/  195]    Loss 3.601713    Top1 33.645833    Top5 57.174479    
2021-11-16 05:12:32,712 - Test: [   40/  195]    Loss 3.597574    Top1 33.320313    Top5 57.197266    
2021-11-16 05:12:50,730 - Test: [   50/  195]    Loss 3.599876    Top1 33.234375    Top5 57.164062    
2021-11-16 05:13:09,049 - Test: [   60/  195]    Loss 3.595594    Top1 33.313802    Top5 57.532552    
2021-11-16 05:13:27,129 - Test: [   70/  195]    Loss 3.598492    Top1 33.247768    Top5 57.472098    
2021-11-16 05:13:45,276 - Test: [   80/  195]    Loss 3.595122    Top1 33.359375    Top5 57.539063    
2021-11-16 05:14:03,536 - Test: [   90/  195]    Loss 3.589312    Top1 33.515625    Top5 57.578125    
2021-11-16 05:14:21,652 - Test: [  100/  195]    Loss 3.581232    Top1 33.718750    Top5 57.781250    
2021-11-16 05:14:39,639 - Test: [  110/  195]    Loss 3.579077    Top1 33.742898    Top5 57.759233    
2021-11-16 05:14:57,909 - Test: [  120/  195]    Loss 3.578122    Top1 33.694661    Top5 57.714844    
2021-11-16 05:15:16,071 - Test: [  130/  195]    Loss 3.576125    Top1 33.780048    Top5 57.755409    
2021-11-16 05:15:34,229 - Test: [  140/  195]    Loss 3.576842    Top1 33.744420    Top5 57.787388    
2021-11-16 05:15:52,595 - Test: [  150/  195]    Loss 3.573610    Top1 33.763021    Top5 57.828125    
2021-11-16 05:16:10,569 - Test: [  160/  195]    Loss 3.575498    Top1 33.801270    Top5 57.780762    
2021-11-16 05:16:28,669 - Test: [  170/  195]    Loss 3.576149    Top1 33.798254    Top5 57.755055    
2021-11-16 05:16:46,705 - Test: [  180/  195]    Loss 3.572548    Top1 33.888889    Top5 57.836372    
2021-11-16 05:17:04,704 - Test: [  190/  195]    Loss 3.574333    Top1 33.865132    Top5 57.833059    
2021-11-16 05:17:14,607 - ==> Top1: 33.844    Top5: 57.756    Loss: 3.576

2021-11-16 05:17:18,164 - --- test ---------------------
2021-11-16 05:17:18,164 - 50000 samples (256 per mini-batch)
2021-11-16 05:17:38,976 - Test: [   10/  195]    Loss 3.680942    Top1 33.945312    Top5 57.304687    
2021-11-16 05:17:56,954 - Test: [   20/  195]    Loss 3.659014    Top1 33.496094    Top5 57.246094    
2021-11-16 05:18:14,922 - Test: [   30/  195]    Loss 3.667254    Top1 33.281250    Top5 56.992188    
2021-11-16 05:18:33,101 - Test: [   40/  195]    Loss 3.658888    Top1 33.457031    Top5 56.816406    
2021-11-16 05:18:51,142 - Test: [   50/  195]    Loss 3.652814    Top1 33.406250    Top5 56.804688    
2021-11-16 05:19:09,307 - Test: [   60/  195]    Loss 3.651371    Top1 33.444010    Top5 56.875000    
2021-11-16 05:19:27,402 - Test: [   70/  195]    Loss 3.654329    Top1 33.392857    Top5 56.908482    
2021-11-16 05:19:45,554 - Test: [   80/  195]    Loss 3.647807    Top1 33.657227    Top5 57.114258    
2021-11-16 05:20:03,679 - Test: [   90/  195]    Loss 3.647435    Top1 33.615451    Top5 57.200521    
2021-11-16 05:20:21,732 - Test: [  100/  195]    Loss 3.650490    Top1 33.500000    Top5 56.992188    
2021-11-16 05:20:39,801 - Test: [  110/  195]    Loss 3.655338    Top1 33.458807    Top5 56.899858    
2021-11-16 05:20:57,893 - Test: [  120/  195]    Loss 3.652139    Top1 33.580729    Top5 56.969401    
2021-11-16 05:21:16,060 - Test: [  130/  195]    Loss 3.652463    Top1 33.509615    Top5 56.974159    
2021-11-16 05:21:34,270 - Test: [  140/  195]    Loss 3.650183    Top1 33.621652    Top5 56.953125    
2021-11-16 05:21:52,285 - Test: [  150/  195]    Loss 3.650051    Top1 33.554688    Top5 56.971354    
2021-11-16 05:22:10,168 - Test: [  160/  195]    Loss 3.648058    Top1 33.605957    Top5 56.970215    
2021-11-16 05:22:28,084 - Test: [  170/  195]    Loss 3.648596    Top1 33.566176    Top5 56.916360    
2021-11-16 05:22:46,012 - Test: [  180/  195]    Loss 3.653146    Top1 33.472222    Top5 56.833767    
2021-11-16 05:23:04,014 - Test: [  190/  195]    Loss 3.654026    Top1 33.476562    Top5 56.823602    
2021-11-16 05:23:13,784 - ==> Top1: 33.496    Top5: 56.804    Loss: 3.654

2021-11-16 05:23:16,965 - --- test ---------------------
2021-11-16 05:23:16,965 - 50000 samples (256 per mini-batch)
2021-11-16 05:23:37,563 - Test: [   10/  195]    Loss 3.621005    Top1 33.398438    Top5 56.640625    
2021-11-16 05:23:55,520 - Test: [   20/  195]    Loss 3.623743    Top1 33.652344    Top5 57.324219    
2021-11-16 05:24:13,614 - Test: [   30/  195]    Loss 3.593537    Top1 34.140625    Top5 57.903646    
2021-11-16 05:24:31,614 - Test: [   40/  195]    Loss 3.579407    Top1 34.580078    Top5 58.261719    
2021-11-16 05:24:49,517 - Test: [   50/  195]    Loss 3.574751    Top1 34.898438    Top5 58.367188    
2021-11-16 05:25:07,469 - Test: [   60/  195]    Loss 3.569972    Top1 35.058594    Top5 58.411458    
2021-11-16 05:25:25,409 - Test: [   70/  195]    Loss 3.561397    Top1 35.167411    Top5 58.638393    
2021-11-16 05:25:43,466 - Test: [   80/  195]    Loss 3.572637    Top1 35.004883    Top5 58.486328    
2021-11-16 05:26:01,580 - Test: [   90/  195]    Loss 3.580263    Top1 34.726562    Top5 58.502604    
2021-11-16 05:26:19,741 - Test: [  100/  195]    Loss 3.580947    Top1 34.652344    Top5 58.535156    
2021-11-16 05:26:37,880 - Test: [  110/  195]    Loss 3.576567    Top1 34.737216    Top5 58.636364    
2021-11-16 05:26:55,884 - Test: [  120/  195]    Loss 3.577533    Top1 34.843750    Top5 58.701172    
2021-11-16 05:27:13,980 - Test: [  130/  195]    Loss 3.580975    Top1 34.744591    Top5 58.680889    
2021-11-16 05:27:32,129 - Test: [  140/  195]    Loss 3.581932    Top1 34.807478    Top5 58.646763    
2021-11-16 05:27:50,152 - Test: [  150/  195]    Loss 3.580059    Top1 34.867188    Top5 58.687500    
2021-11-16 05:28:08,207 - Test: [  160/  195]    Loss 3.577085    Top1 34.980469    Top5 58.793945    
2021-11-16 05:28:26,141 - Test: [  170/  195]    Loss 3.578273    Top1 34.931066    Top5 58.818934    
2021-11-16 05:28:44,192 - Test: [  180/  195]    Loss 3.577966    Top1 34.926215    Top5 58.873698    
2021-11-16 05:29:02,392 - Test: [  190/  195]    Loss 3.578962    Top1 34.882813    Top5 58.863076    
2021-11-16 05:29:12,060 - ==> Top1: 34.890    Top5: 58.900    Loss: 3.577

2021-11-16 05:29:15,529 - --- test ---------------------
2021-11-16 05:29:15,529 - 50000 samples (256 per mini-batch)
2021-11-16 05:29:36,818 - Test: [   10/  195]    Loss 3.439475    Top1 36.796875    Top5 61.914062    
2021-11-16 05:29:54,730 - Test: [   20/  195]    Loss 3.484335    Top1 35.683594    Top5 60.585938    
2021-11-16 05:30:12,785 - Test: [   30/  195]    Loss 3.478411    Top1 35.898438    Top5 60.898438    
2021-11-16 05:30:30,711 - Test: [   40/  195]    Loss 3.491854    Top1 35.908203    Top5 60.566406    
2021-11-16 05:30:48,645 - Test: [   50/  195]    Loss 3.497455    Top1 35.984375    Top5 60.578125    
2021-11-16 05:31:06,932 - Test: [   60/  195]    Loss 3.500290    Top1 36.145833    Top5 60.462240    
2021-11-16 05:31:24,893 - Test: [   70/  195]    Loss 3.508565    Top1 35.982143    Top5 60.407366    
2021-11-16 05:31:42,974 - Test: [   80/  195]    Loss 3.505685    Top1 36.176758    Top5 60.507812    
2021-11-16 05:32:01,145 - Test: [   90/  195]    Loss 3.502608    Top1 36.236979    Top5 60.546875    
2021-11-16 05:32:19,293 - Test: [  100/  195]    Loss 3.497211    Top1 36.261719    Top5 60.578125    
2021-11-16 05:32:37,257 - Test: [  110/  195]    Loss 3.497375    Top1 36.171875    Top5 60.468750    
2021-11-16 05:32:55,134 - Test: [  120/  195]    Loss 3.493389    Top1 36.289062    Top5 60.527344    
2021-11-16 05:33:13,206 - Test: [  130/  195]    Loss 3.495622    Top1 36.216947    Top5 60.438702    
2021-11-16 05:33:31,255 - Test: [  140/  195]    Loss 3.492421    Top1 36.269531    Top5 60.521763    
2021-11-16 05:33:49,272 - Test: [  150/  195]    Loss 3.493223    Top1 36.200521    Top5 60.520833    
2021-11-16 05:34:07,170 - Test: [  160/  195]    Loss 3.493716    Top1 36.103516    Top5 60.510254    
2021-11-16 05:34:25,319 - Test: [  170/  195]    Loss 3.489656    Top1 36.116728    Top5 60.625000    
2021-11-16 05:34:43,176 - Test: [  180/  195]    Loss 3.491536    Top1 36.091580    Top5 60.577257    
2021-11-16 05:35:01,109 - Test: [  190/  195]    Loss 3.489125    Top1 36.116365    Top5 60.598273    
2021-11-16 05:35:11,009 - ==> Top1: 36.172    Top5: 60.674    Loss: 3.487

2021-11-16 05:35:14,348 - --- test ---------------------
2021-11-16 05:35:14,348 - 50000 samples (256 per mini-batch)
2021-11-16 05:35:35,500 - Test: [   10/  195]    Loss 3.347581    Top1 38.906250    Top5 63.554687    
2021-11-16 05:35:53,316 - Test: [   20/  195]    Loss 3.337579    Top1 39.023438    Top5 63.242188    
2021-11-16 05:36:11,202 - Test: [   30/  195]    Loss 3.315935    Top1 39.348958    Top5 63.867188    
2021-11-16 05:36:29,277 - Test: [   40/  195]    Loss 3.304707    Top1 39.248047    Top5 64.062500    
2021-11-16 05:36:47,388 - Test: [   50/  195]    Loss 3.301644    Top1 39.234375    Top5 64.093750    
2021-11-16 05:37:05,422 - Test: [   60/  195]    Loss 3.295170    Top1 39.375000    Top5 64.049479    
2021-11-16 05:37:23,516 - Test: [   70/  195]    Loss 3.297450    Top1 39.319196    Top5 64.029018    
2021-11-16 05:37:41,608 - Test: [   80/  195]    Loss 3.298555    Top1 39.272461    Top5 64.028320    
2021-11-16 05:37:59,632 - Test: [   90/  195]    Loss 3.298141    Top1 39.201389    Top5 64.110243    
2021-11-16 05:38:17,671 - Test: [  100/  195]    Loss 3.300676    Top1 39.015625    Top5 64.097656    
2021-11-16 05:38:35,670 - Test: [  110/  195]    Loss 3.303967    Top1 38.934659    Top5 63.952415    
2021-11-16 05:38:53,773 - Test: [  120/  195]    Loss 3.303118    Top1 38.955078    Top5 63.981120    
2021-11-16 05:39:11,860 - Test: [  130/  195]    Loss 3.296118    Top1 39.089543    Top5 64.125601    
2021-11-16 05:39:29,897 - Test: [  140/  195]    Loss 3.295464    Top1 39.143415    Top5 64.090402    
2021-11-16 05:39:47,997 - Test: [  150/  195]    Loss 3.298691    Top1 39.106771    Top5 64.062500    
2021-11-16 05:40:06,020 - Test: [  160/  195]    Loss 3.298477    Top1 39.240723    Top5 64.072266    
2021-11-16 05:40:23,939 - Test: [  170/  195]    Loss 3.300588    Top1 39.255515    Top5 64.060202    
2021-11-16 05:40:41,928 - Test: [  180/  195]    Loss 3.300949    Top1 39.210069    Top5 64.010417    
2021-11-16 05:40:59,878 - Test: [  190/  195]    Loss 3.298193    Top1 39.317434    Top5 64.050164    
2021-11-16 05:41:09,774 - ==> Top1: 39.334    Top5: 64.056    Loss: 3.298

2021-11-16 05:41:13,174 - --- test ---------------------
2021-11-16 05:41:13,174 - 50000 samples (256 per mini-batch)
2021-11-16 05:41:34,164 - Test: [   10/  195]    Loss 3.436794    Top1 35.664063    Top5 60.664063    
2021-11-16 05:41:52,065 - Test: [   20/  195]    Loss 3.447874    Top1 35.898438    Top5 59.570312    
2021-11-16 05:42:10,144 - Test: [   30/  195]    Loss 3.461761    Top1 35.625000    Top5 59.036458    
2021-11-16 05:42:28,411 - Test: [   40/  195]    Loss 3.466262    Top1 35.761719    Top5 59.052734    
2021-11-16 05:42:46,515 - Test: [   50/  195]    Loss 3.468466    Top1 35.851562    Top5 59.078125    
2021-11-16 05:43:04,621 - Test: [   60/  195]    Loss 3.472773    Top1 35.696615    Top5 58.867187    
2021-11-16 05:43:22,884 - Test: [   70/  195]    Loss 3.468519    Top1 35.658482    Top5 59.056920    
2021-11-16 05:43:41,045 - Test: [   80/  195]    Loss 3.467793    Top1 35.664063    Top5 59.038086    
2021-11-16 05:43:59,024 - Test: [   90/  195]    Loss 3.455848    Top1 35.863715    Top5 59.318576    
2021-11-16 05:44:17,088 - Test: [  100/  195]    Loss 3.451184    Top1 36.031250    Top5 59.425781    
2021-11-16 05:44:35,356 - Test: [  110/  195]    Loss 3.451828    Top1 35.994318    Top5 59.485085    
2021-11-16 05:44:53,373 - Test: [  120/  195]    Loss 3.451033    Top1 35.960286    Top5 59.524740    
2021-11-16 05:45:11,540 - Test: [  130/  195]    Loss 3.451822    Top1 36.000601    Top5 59.591346    
2021-11-16 05:45:29,620 - Test: [  140/  195]    Loss 3.454156    Top1 35.965402    Top5 59.617746    
2021-11-16 05:45:47,797 - Test: [  150/  195]    Loss 3.452789    Top1 36.000000    Top5 59.671875    
2021-11-16 05:46:05,889 - Test: [  160/  195]    Loss 3.454532    Top1 35.898438    Top5 59.609375    
2021-11-16 05:46:23,819 - Test: [  170/  195]    Loss 3.454031    Top1 35.958180    Top5 59.634651    
2021-11-16 05:46:41,853 - Test: [  180/  195]    Loss 3.453544    Top1 36.011285    Top5 59.620226    
2021-11-16 05:46:59,753 - Test: [  190/  195]    Loss 3.456102    Top1 35.941612    Top5 59.518914    
2021-11-16 05:47:09,694 - ==> Top1: 35.960    Top5: 59.556    Loss: 3.455

2021-11-16 05:47:13,246 - --- test ---------------------
2021-11-16 05:47:13,246 - 50000 samples (256 per mini-batch)
2021-11-16 05:47:34,057 - Test: [   10/  195]    Loss 3.497682    Top1 33.984375    Top5 58.710938    
2021-11-16 05:47:51,906 - Test: [   20/  195]    Loss 3.449032    Top1 35.097656    Top5 59.511719    
2021-11-16 05:48:09,960 - Test: [   30/  195]    Loss 3.396630    Top1 35.950521    Top5 60.559896    
2021-11-16 05:48:28,013 - Test: [   40/  195]    Loss 3.395066    Top1 36.250000    Top5 60.673828    
2021-11-16 05:48:46,251 - Test: [   50/  195]    Loss 3.390354    Top1 36.523438    Top5 60.546875    
2021-11-16 05:49:04,133 - Test: [   60/  195]    Loss 3.379649    Top1 36.529948    Top5 60.742188    
2021-11-16 05:49:22,172 - Test: [   70/  195]    Loss 3.382592    Top1 36.462054    Top5 60.686384    
2021-11-16 05:49:40,263 - Test: [   80/  195]    Loss 3.381163    Top1 36.445313    Top5 60.781250    
2021-11-16 05:49:58,265 - Test: [   90/  195]    Loss 3.385678    Top1 36.406250    Top5 60.698785    
2021-11-16 05:50:16,325 - Test: [  100/  195]    Loss 3.393491    Top1 36.203125    Top5 60.644531    
2021-11-16 05:50:34,403 - Test: [  110/  195]    Loss 3.390974    Top1 36.221591    Top5 60.600142    
2021-11-16 05:50:52,610 - Test: [  120/  195]    Loss 3.389693    Top1 36.236979    Top5 60.517578    
2021-11-16 05:51:10,597 - Test: [  130/  195]    Loss 3.390577    Top1 36.310096    Top5 60.462740    
2021-11-16 05:51:28,712 - Test: [  140/  195]    Loss 3.398878    Top1 36.127232    Top5 60.326451    
2021-11-16 05:51:46,661 - Test: [  150/  195]    Loss 3.398225    Top1 36.122396    Top5 60.312500    
2021-11-16 05:52:04,537 - Test: [  160/  195]    Loss 3.401133    Top1 36.032715    Top5 60.310059    
2021-11-16 05:52:22,569 - Test: [  170/  195]    Loss 3.400420    Top1 35.971967    Top5 60.319393    
2021-11-16 05:52:40,649 - Test: [  180/  195]    Loss 3.399256    Top1 35.989583    Top5 60.275608    
2021-11-16 05:52:58,741 - Test: [  190/  195]    Loss 3.402919    Top1 35.976562    Top5 60.234375    
2021-11-16 05:53:08,538 - ==> Top1: 35.962    Top5: 60.278    Loss: 3.403

2021-11-16 05:53:11,907 - --- test ---------------------
2021-11-16 05:53:11,907 - 50000 samples (256 per mini-batch)
2021-11-16 05:53:34,120 - Test: [   10/  195]    Loss 3.616502    Top1 33.007812    Top5 56.796875    
2021-11-16 05:53:51,937 - Test: [   20/  195]    Loss 3.646243    Top1 33.808594    Top5 56.289062    
2021-11-16 05:54:10,013 - Test: [   30/  195]    Loss 3.666887    Top1 33.033854    Top5 56.328125    
2021-11-16 05:54:28,190 - Test: [   40/  195]    Loss 3.663785    Top1 32.802734    Top5 56.269531    
2021-11-16 05:54:46,273 - Test: [   50/  195]    Loss 3.651480    Top1 33.164062    Top5 56.554688    
2021-11-16 05:55:04,564 - Test: [   60/  195]    Loss 3.654206    Top1 33.072917    Top5 56.367188    
2021-11-16 05:55:22,472 - Test: [   70/  195]    Loss 3.651236    Top1 33.281250    Top5 56.534598    
2021-11-16 05:55:40,776 - Test: [   80/  195]    Loss 3.647319    Top1 33.388672    Top5 56.606445    
2021-11-16 05:55:58,780 - Test: [   90/  195]    Loss 3.653221    Top1 33.038194    Top5 56.605903    
2021-11-16 05:56:17,017 - Test: [  100/  195]    Loss 3.653028    Top1 33.023438    Top5 56.480469    
2021-11-16 05:56:34,994 - Test: [  110/  195]    Loss 3.654002    Top1 32.958097    Top5 56.544744    
2021-11-16 05:56:52,974 - Test: [  120/  195]    Loss 3.658927    Top1 32.848307    Top5 56.442057    
2021-11-16 05:57:11,184 - Test: [  130/  195]    Loss 3.657078    Top1 32.893630    Top5 56.580529    
2021-11-16 05:57:29,348 - Test: [  140/  195]    Loss 3.656506    Top1 32.898996    Top5 56.576451    
2021-11-16 05:57:47,249 - Test: [  150/  195]    Loss 3.653485    Top1 33.005208    Top5 56.588542    
2021-11-16 05:58:05,236 - Test: [  160/  195]    Loss 3.652232    Top1 33.002930    Top5 56.652832    
2021-11-16 05:58:23,229 - Test: [  170/  195]    Loss 3.653166    Top1 33.005515    Top5 56.608456    
2021-11-16 05:58:41,108 - Test: [  180/  195]    Loss 3.651588    Top1 33.042535    Top5 56.666667    
2021-11-16 05:58:59,095 - Test: [  190/  195]    Loss 3.652566    Top1 32.991365    Top5 56.624178    
2021-11-16 05:59:08,891 - ==> Top1: 33.080    Top5: 56.682    Loss: 3.651

2021-11-16 05:59:12,272 - --- test ---------------------
2021-11-16 05:59:12,272 - 50000 samples (256 per mini-batch)
2021-11-16 05:59:34,092 - Test: [   10/  195]    Loss 4.016294    Top1 28.750000    Top5 51.054687    
2021-11-16 05:59:52,028 - Test: [   20/  195]    Loss 3.985347    Top1 29.531250    Top5 51.933594    
2021-11-16 06:00:09,927 - Test: [   30/  195]    Loss 3.987927    Top1 29.583333    Top5 51.796875    
2021-11-16 06:00:27,995 - Test: [   40/  195]    Loss 3.974525    Top1 29.843750    Top5 52.011719    
2021-11-16 06:00:45,962 - Test: [   50/  195]    Loss 3.972576    Top1 29.734375    Top5 52.132812    
2021-11-16 06:01:03,902 - Test: [   60/  195]    Loss 3.960786    Top1 29.856771    Top5 52.421875    
2021-11-16 06:01:21,948 - Test: [   70/  195]    Loss 3.948003    Top1 30.083705    Top5 52.734375    
2021-11-16 06:01:39,968 - Test: [   80/  195]    Loss 3.937509    Top1 30.292969    Top5 52.978516    
2021-11-16 06:01:58,036 - Test: [   90/  195]    Loss 3.934736    Top1 30.203993    Top5 52.990451    
2021-11-16 06:02:16,090 - Test: [  100/  195]    Loss 3.944675    Top1 30.027344    Top5 52.632812    
2021-11-16 06:02:34,212 - Test: [  110/  195]    Loss 3.944738    Top1 30.078125    Top5 52.727273    
2021-11-16 06:02:52,138 - Test: [  120/  195]    Loss 3.950061    Top1 30.032552    Top5 52.568359    
2021-11-16 06:03:10,173 - Test: [  130/  195]    Loss 3.951274    Top1 30.039063    Top5 52.590144    
2021-11-16 06:03:28,324 - Test: [  140/  195]    Loss 3.947271    Top1 30.133929    Top5 52.692522    
2021-11-16 06:03:46,281 - Test: [  150/  195]    Loss 3.944179    Top1 30.135417    Top5 52.705729    
2021-11-16 06:04:04,403 - Test: [  160/  195]    Loss 3.942314    Top1 30.136719    Top5 52.746582    
2021-11-16 06:04:22,217 - Test: [  170/  195]    Loss 3.941903    Top1 30.128676    Top5 52.805607    
2021-11-16 06:04:40,310 - Test: [  180/  195]    Loss 3.939530    Top1 30.138889    Top5 52.871094    
2021-11-16 06:04:58,100 - Test: [  190/  195]    Loss 3.940267    Top1 30.082237    Top5 52.847451    
2021-11-16 06:05:07,850 - ==> Top1: 30.038    Top5: 52.800    Loss: 3.943

2021-11-16 06:05:11,111 - --- test ---------------------
2021-11-16 06:05:11,112 - 50000 samples (256 per mini-batch)
2021-11-16 06:05:32,262 - Test: [   10/  195]    Loss 4.101725    Top1 28.125000    Top5 49.101562    
2021-11-16 06:05:50,225 - Test: [   20/  195]    Loss 4.116781    Top1 27.558594    Top5 49.511719    
2021-11-16 06:06:08,216 - Test: [   30/  195]    Loss 4.122312    Top1 27.278646    Top5 49.231771    
2021-11-16 06:06:26,452 - Test: [   40/  195]    Loss 4.136614    Top1 26.953125    Top5 48.652344    
2021-11-16 06:06:44,525 - Test: [   50/  195]    Loss 4.130898    Top1 26.914063    Top5 48.718750    
2021-11-16 06:07:02,436 - Test: [   60/  195]    Loss 4.132463    Top1 26.914063    Top5 48.684896    
2021-11-16 06:07:20,342 - Test: [   70/  195]    Loss 4.119454    Top1 27.036830    Top5 48.967634    
2021-11-16 06:07:38,464 - Test: [   80/  195]    Loss 4.120062    Top1 26.987305    Top5 49.038086    
2021-11-16 06:07:56,442 - Test: [   90/  195]    Loss 4.114958    Top1 27.135417    Top5 49.231771    
2021-11-16 06:08:14,452 - Test: [  100/  195]    Loss 4.114388    Top1 26.980469    Top5 49.281250    
2021-11-16 06:08:32,345 - Test: [  110/  195]    Loss 4.117816    Top1 26.867898    Top5 49.158381    
2021-11-16 06:08:50,428 - Test: [  120/  195]    Loss 4.120163    Top1 26.861979    Top5 49.134115    
2021-11-16 06:09:08,461 - Test: [  130/  195]    Loss 4.120336    Top1 26.971154    Top5 49.125601    
2021-11-16 06:09:26,556 - Test: [  140/  195]    Loss 4.121355    Top1 26.880580    Top5 49.079241    
2021-11-16 06:09:44,528 - Test: [  150/  195]    Loss 4.113317    Top1 26.997396    Top5 49.226563    
2021-11-16 06:10:02,414 - Test: [  160/  195]    Loss 4.109346    Top1 27.092285    Top5 49.365234    
2021-11-16 06:10:20,268 - Test: [  170/  195]    Loss 4.110682    Top1 27.125460    Top5 49.331342    
2021-11-16 06:10:38,318 - Test: [  180/  195]    Loss 4.114133    Top1 27.081163    Top5 49.251302    
2021-11-16 06:10:56,082 - Test: [  190/  195]    Loss 4.117370    Top1 27.002467    Top5 49.185855    
2021-11-16 06:11:05,776 - ==> Top1: 27.038    Top5: 49.258    Loss: 4.113

2021-11-16 06:11:09,212 - --- test ---------------------
2021-11-16 06:11:09,212 - 50000 samples (256 per mini-batch)
2021-11-16 06:11:31,412 - Test: [   10/  195]    Loss 3.605874    Top1 33.476562    Top5 56.562500    
2021-11-16 06:11:49,228 - Test: [   20/  195]    Loss 3.576892    Top1 34.511719    Top5 57.031250    
2021-11-16 06:12:07,262 - Test: [   30/  195]    Loss 3.566070    Top1 34.609375    Top5 57.070312    
2021-11-16 06:12:25,250 - Test: [   40/  195]    Loss 3.568006    Top1 34.199219    Top5 57.031250    
2021-11-16 06:12:43,358 - Test: [   50/  195]    Loss 3.578424    Top1 34.070312    Top5 56.843750    
2021-11-16 06:13:01,409 - Test: [   60/  195]    Loss 3.588023    Top1 33.763021    Top5 56.562500    
2021-11-16 06:13:19,395 - Test: [   70/  195]    Loss 3.573161    Top1 33.839286    Top5 56.947545    
2021-11-16 06:13:37,553 - Test: [   80/  195]    Loss 3.584790    Top1 33.535156    Top5 56.718750    
2021-11-16 06:13:55,473 - Test: [   90/  195]    Loss 3.582138    Top1 33.693576    Top5 56.857639    
2021-11-16 06:14:13,381 - Test: [  100/  195]    Loss 3.582990    Top1 33.597656    Top5 56.953125    
2021-11-16 06:14:31,475 - Test: [  110/  195]    Loss 3.591039    Top1 33.394886    Top5 56.718750    
2021-11-16 06:14:49,377 - Test: [  120/  195]    Loss 3.593727    Top1 33.271484    Top5 56.653646    
2021-11-16 06:15:07,393 - Test: [  130/  195]    Loss 3.594128    Top1 33.194111    Top5 56.637620    
2021-11-16 06:15:25,429 - Test: [  140/  195]    Loss 3.588145    Top1 33.256138    Top5 56.696429    
2021-11-16 06:15:43,355 - Test: [  150/  195]    Loss 3.584822    Top1 33.268229    Top5 56.783854    
2021-11-16 06:16:01,208 - Test: [  160/  195]    Loss 3.584761    Top1 33.291016    Top5 56.750488    
2021-11-16 06:16:19,203 - Test: [  170/  195]    Loss 3.582710    Top1 33.343290    Top5 56.789982    
2021-11-16 06:16:37,093 - Test: [  180/  195]    Loss 3.582776    Top1 33.365885    Top5 56.799045    
2021-11-16 06:16:54,857 - Test: [  190/  195]    Loss 3.583000    Top1 33.441612    Top5 56.768092    
2021-11-16 06:17:04,558 - ==> Top1: 33.456    Top5: 56.754    Loss: 3.583

2021-11-16 06:17:07,664 - --- test ---------------------
2021-11-16 06:17:07,664 - 50000 samples (256 per mini-batch)
2021-11-16 06:17:30,249 - Test: [   10/  195]    Loss 3.472459    Top1 35.312500    Top5 58.828125    
2021-11-16 06:17:48,033 - Test: [   20/  195]    Loss 3.472665    Top1 34.824219    Top5 58.671875    
2021-11-16 06:18:06,112 - Test: [   30/  195]    Loss 3.475620    Top1 34.453125    Top5 58.945312    
2021-11-16 06:18:23,995 - Test: [   40/  195]    Loss 3.452081    Top1 34.921875    Top5 59.365234    
2021-11-16 06:18:42,038 - Test: [   50/  195]    Loss 3.429164    Top1 35.234375    Top5 59.875000    
2021-11-16 06:18:59,952 - Test: [   60/  195]    Loss 3.433662    Top1 35.182292    Top5 59.667969    
2021-11-16 06:19:17,965 - Test: [   70/  195]    Loss 3.442072    Top1 34.977679    Top5 59.536830    
2021-11-16 06:19:35,992 - Test: [   80/  195]    Loss 3.441805    Top1 34.965820    Top5 59.584961    
2021-11-16 06:19:53,926 - Test: [   90/  195]    Loss 3.433399    Top1 35.043403    Top5 59.665799    
2021-11-16 06:20:12,053 - Test: [  100/  195]    Loss 3.443556    Top1 34.984375    Top5 59.433594    
2021-11-16 06:20:30,109 - Test: [  110/  195]    Loss 3.447843    Top1 34.989347    Top5 59.378551    
2021-11-16 06:20:48,101 - Test: [  120/  195]    Loss 3.449197    Top1 35.009766    Top5 59.410807    
2021-11-16 06:21:06,018 - Test: [  130/  195]    Loss 3.451236    Top1 34.993990    Top5 59.314904    
2021-11-16 06:21:24,039 - Test: [  140/  195]    Loss 3.454641    Top1 34.977679    Top5 59.218750    
2021-11-16 06:21:42,159 - Test: [  150/  195]    Loss 3.455982    Top1 35.000000    Top5 59.294271    
2021-11-16 06:22:00,041 - Test: [  160/  195]    Loss 3.458236    Top1 35.034180    Top5 59.257812    
2021-11-16 06:22:18,074 - Test: [  170/  195]    Loss 3.459563    Top1 35.011489    Top5 59.280790    
2021-11-16 06:22:35,847 - Test: [  180/  195]    Loss 3.456146    Top1 35.056424    Top5 59.301215    
2021-11-16 06:22:53,843 - Test: [  190/  195]    Loss 3.456589    Top1 35.094572    Top5 59.305099    
2021-11-16 06:23:03,572 - ==> Top1: 35.058    Top5: 59.258    Loss: 3.458

2021-11-16 06:23:06,978 - --- test ---------------------
2021-11-16 06:23:06,978 - 50000 samples (256 per mini-batch)
2021-11-16 06:23:29,341 - Test: [   10/  195]    Loss 4.521180    Top1 22.109375    Top5 41.835938    
2021-11-16 06:23:47,092 - Test: [   20/  195]    Loss 4.519020    Top1 21.777344    Top5 40.996094    
2021-11-16 06:24:05,004 - Test: [   30/  195]    Loss 4.506860    Top1 21.783854    Top5 41.354167    
2021-11-16 06:24:23,091 - Test: [   40/  195]    Loss 4.491749    Top1 21.728516    Top5 41.542969    
2021-11-16 06:24:41,041 - Test: [   50/  195]    Loss 4.495188    Top1 21.742188    Top5 41.554688    
2021-11-16 06:24:59,031 - Test: [   60/  195]    Loss 4.491479    Top1 21.751302    Top5 41.634115    
2021-11-16 06:25:16,979 - Test: [   70/  195]    Loss 4.506671    Top1 21.640625    Top5 41.411830    
2021-11-16 06:25:34,911 - Test: [   80/  195]    Loss 4.497390    Top1 21.718750    Top5 41.640625    
2021-11-16 06:25:52,997 - Test: [   90/  195]    Loss 4.488939    Top1 21.805556    Top5 41.892361    
2021-11-16 06:26:10,919 - Test: [  100/  195]    Loss 4.480123    Top1 21.863281    Top5 41.992188    
2021-11-16 06:26:29,153 - Test: [  110/  195]    Loss 4.482713    Top1 21.899858    Top5 41.974432    
2021-11-16 06:26:47,171 - Test: [  120/  195]    Loss 4.484627    Top1 21.914062    Top5 41.946615    
2021-11-16 06:27:05,132 - Test: [  130/  195]    Loss 4.486917    Top1 21.763822    Top5 41.835938    
2021-11-16 06:27:23,299 - Test: [  140/  195]    Loss 4.487559    Top1 21.690848    Top5 41.741071    
2021-11-16 06:27:41,233 - Test: [  150/  195]    Loss 4.487597    Top1 21.757812    Top5 41.755208    
2021-11-16 06:27:59,011 - Test: [  160/  195]    Loss 4.484597    Top1 21.787109    Top5 41.840820    
2021-11-16 06:28:16,837 - Test: [  170/  195]    Loss 4.484240    Top1 21.815257    Top5 41.801471    
2021-11-16 06:28:34,732 - Test: [  180/  195]    Loss 4.482090    Top1 21.818576    Top5 41.875000    
2021-11-16 06:28:52,672 - Test: [  190/  195]    Loss 4.483444    Top1 21.761924    Top5 41.805099    
2021-11-16 06:29:02,349 - ==> Top1: 21.822    Top5: 41.836    Loss: 4.480

2021-11-16 06:29:06,108 - --- test ---------------------
2021-11-16 06:29:06,108 - 50000 samples (256 per mini-batch)
2021-11-16 06:29:27,067 - Test: [   10/  195]    Loss 4.304884    Top1 23.828125    Top5 44.492188    
2021-11-16 06:29:44,930 - Test: [   20/  195]    Loss 4.280329    Top1 23.886719    Top5 44.921875    
2021-11-16 06:30:02,901 - Test: [   30/  195]    Loss 4.283703    Top1 23.736979    Top5 44.791667    
2021-11-16 06:30:21,046 - Test: [   40/  195]    Loss 4.288400    Top1 23.623047    Top5 44.414062    
2021-11-16 06:30:38,912 - Test: [   50/  195]    Loss 4.295401    Top1 23.664063    Top5 44.218750    
2021-11-16 06:30:56,837 - Test: [   60/  195]    Loss 4.299815    Top1 23.548177    Top5 44.329427    
2021-11-16 06:31:14,677 - Test: [   70/  195]    Loss 4.300877    Top1 23.616071    Top5 44.341518    
2021-11-16 06:31:32,832 - Test: [   80/  195]    Loss 4.300107    Top1 23.569336    Top5 44.296875    
2021-11-16 06:31:50,896 - Test: [   90/  195]    Loss 4.301250    Top1 23.537326    Top5 44.279514    
2021-11-16 06:32:08,760 - Test: [  100/  195]    Loss 4.301979    Top1 23.515625    Top5 44.152344    
2021-11-16 06:32:26,932 - Test: [  110/  195]    Loss 4.294216    Top1 23.639915    Top5 44.353693    
2021-11-16 06:32:44,829 - Test: [  120/  195]    Loss 4.299063    Top1 23.580729    Top5 44.296875    
2021-11-16 06:33:02,715 - Test: [  130/  195]    Loss 4.301873    Top1 23.569712    Top5 44.233774    
2021-11-16 06:33:20,854 - Test: [  140/  195]    Loss 4.298704    Top1 23.638393    Top5 44.305246    
2021-11-16 06:33:38,891 - Test: [  150/  195]    Loss 4.297126    Top1 23.679688    Top5 44.369792    
2021-11-16 06:33:56,766 - Test: [  160/  195]    Loss 4.299702    Top1 23.669434    Top5 44.316406    
2021-11-16 06:34:14,635 - Test: [  170/  195]    Loss 4.301540    Top1 23.602941    Top5 44.221048    
2021-11-16 06:34:32,623 - Test: [  180/  195]    Loss 4.301732    Top1 23.574219    Top5 44.240451    
2021-11-16 06:34:50,881 - Test: [  190/  195]    Loss 4.303756    Top1 23.486842    Top5 44.214638    
2021-11-16 06:35:00,525 - ==> Top1: 23.532    Top5: 44.284    Loss: 4.300

2021-11-16 06:35:04,148 - --- test ---------------------
2021-11-16 06:35:04,149 - 50000 samples (256 per mini-batch)
2021-11-16 06:35:26,571 - Test: [   10/  195]    Loss 3.824991    Top1 30.390625    Top5 52.539062    
2021-11-16 06:35:44,393 - Test: [   20/  195]    Loss 3.803016    Top1 30.898437    Top5 52.734375    
2021-11-16 06:36:02,307 - Test: [   30/  195]    Loss 3.827757    Top1 29.882812    Top5 52.265625    
2021-11-16 06:36:20,329 - Test: [   40/  195]    Loss 3.843721    Top1 29.980469    Top5 52.236328    
2021-11-16 06:36:38,420 - Test: [   50/  195]    Loss 3.840447    Top1 29.960937    Top5 52.375000    
2021-11-16 06:36:56,601 - Test: [   60/  195]    Loss 3.855171    Top1 29.837240    Top5 52.259115    
2021-11-16 06:37:14,551 - Test: [   70/  195]    Loss 3.859417    Top1 29.765625    Top5 52.126116    
2021-11-16 06:37:32,501 - Test: [   80/  195]    Loss 3.859877    Top1 29.843750    Top5 52.172852    
2021-11-16 06:37:50,684 - Test: [   90/  195]    Loss 3.850317    Top1 30.095486    Top5 52.326389    
2021-11-16 06:38:08,605 - Test: [  100/  195]    Loss 3.852388    Top1 29.968750    Top5 52.265625    
2021-11-16 06:38:26,711 - Test: [  110/  195]    Loss 3.846501    Top1 29.996449    Top5 52.343750    
2021-11-16 06:38:44,801 - Test: [  120/  195]    Loss 3.842485    Top1 30.009766    Top5 52.428385    
2021-11-16 06:39:02,728 - Test: [  130/  195]    Loss 3.845636    Top1 29.942909    Top5 52.442909    
2021-11-16 06:39:20,697 - Test: [  140/  195]    Loss 3.842119    Top1 29.955357    Top5 52.472098    
2021-11-16 06:39:38,807 - Test: [  150/  195]    Loss 3.840766    Top1 29.947917    Top5 52.466146    
2021-11-16 06:39:56,724 - Test: [  160/  195]    Loss 3.840887    Top1 29.960937    Top5 52.502441    
2021-11-16 06:40:14,581 - Test: [  170/  195]    Loss 3.843143    Top1 29.898897    Top5 52.442555    
2021-11-16 06:40:32,484 - Test: [  180/  195]    Loss 3.843910    Top1 29.884983    Top5 52.365451    
2021-11-16 06:40:50,597 - Test: [  190/  195]    Loss 3.842083    Top1 29.814967    Top5 52.421875    
2021-11-16 06:41:00,309 - ==> Top1: 29.800    Top5: 52.438    Loss: 3.843

2021-11-16 06:41:04,388 - --- test ---------------------
2021-11-16 06:41:04,388 - 50000 samples (256 per mini-batch)
2021-11-16 06:41:25,473 - Test: [   10/  195]    Loss 3.491605    Top1 35.625000    Top5 59.375000    
2021-11-16 06:41:43,551 - Test: [   20/  195]    Loss 3.470175    Top1 35.390625    Top5 59.355469    
2021-11-16 06:42:01,556 - Test: [   30/  195]    Loss 3.470059    Top1 35.429687    Top5 59.231771    
2021-11-16 06:42:19,547 - Test: [   40/  195]    Loss 3.474089    Top1 35.009766    Top5 59.287109    
2021-11-16 06:42:37,472 - Test: [   50/  195]    Loss 3.493735    Top1 34.664062    Top5 58.960938    
2021-11-16 06:42:55,561 - Test: [   60/  195]    Loss 3.482698    Top1 34.752604    Top5 59.023438    
2021-11-16 06:43:13,835 - Test: [   70/  195]    Loss 3.500174    Top1 34.503348    Top5 58.805804    
2021-11-16 06:43:31,794 - Test: [   80/  195]    Loss 3.503444    Top1 34.345703    Top5 58.691406    
2021-11-16 06:43:49,803 - Test: [   90/  195]    Loss 3.498244    Top1 34.457465    Top5 58.828125    
2021-11-16 06:44:07,880 - Test: [  100/  195]    Loss 3.495901    Top1 34.621094    Top5 58.843750    
2021-11-16 06:44:25,973 - Test: [  110/  195]    Loss 3.493233    Top1 34.644886    Top5 58.813920    
2021-11-16 06:44:44,241 - Test: [  120/  195]    Loss 3.495398    Top1 34.537760    Top5 58.759766    
2021-11-16 06:45:02,268 - Test: [  130/  195]    Loss 3.495982    Top1 34.549279    Top5 58.737981    
2021-11-16 06:45:20,243 - Test: [  140/  195]    Loss 3.491034    Top1 34.642857    Top5 58.761161    
2021-11-16 06:45:38,156 - Test: [  150/  195]    Loss 3.487636    Top1 34.736979    Top5 58.828125    
2021-11-16 06:45:56,177 - Test: [  160/  195]    Loss 3.483336    Top1 34.785156    Top5 58.872070    
2021-11-16 06:46:14,157 - Test: [  170/  195]    Loss 3.483310    Top1 34.832261    Top5 58.901654    
2021-11-16 06:46:32,179 - Test: [  180/  195]    Loss 3.485134    Top1 34.778646    Top5 58.851997    
2021-11-16 06:46:50,162 - Test: [  190/  195]    Loss 3.486345    Top1 34.767681    Top5 58.817845    
2021-11-16 06:47:00,019 - ==> Top1: 34.780    Top5: 58.832    Loss: 3.485

2021-11-16 06:47:04,141 - --- test ---------------------
2021-11-16 06:47:04,142 - 50000 samples (256 per mini-batch)
2021-11-16 06:47:26,945 - Test: [   10/  195]    Loss 6.971379    Top1 0.273437    Top5 1.367188    
2021-11-16 06:47:44,796 - Test: [   20/  195]    Loss 6.944857    Top1 0.507813    Top5 1.699219    
2021-11-16 06:48:02,902 - Test: [   30/  195]    Loss 6.942192    Top1 0.494792    Top5 1.731771    
2021-11-16 06:48:20,852 - Test: [   40/  195]    Loss 6.937152    Top1 0.498047    Top5 1.708984    
2021-11-16 06:48:38,775 - Test: [   50/  195]    Loss 6.931917    Top1 0.445312    Top5 1.695313    
2021-11-16 06:48:56,892 - Test: [   60/  195]    Loss 6.933726    Top1 0.475260    Top5 1.686198    
2021-11-16 06:49:14,784 - Test: [   70/  195]    Loss 6.933730    Top1 0.474330    Top5 1.679688    
2021-11-16 06:49:32,944 - Test: [   80/  195]    Loss 6.935940    Top1 0.449219    Top5 1.611328    
2021-11-16 06:49:51,020 - Test: [   90/  195]    Loss 6.937464    Top1 0.451389    Top5 1.636285    
2021-11-16 06:50:08,876 - Test: [  100/  195]    Loss 6.937414    Top1 0.449219    Top5 1.617187    
2021-11-16 06:50:26,833 - Test: [  110/  195]    Loss 6.938196    Top1 0.433239    Top5 1.615767    
2021-11-16 06:50:44,940 - Test: [  120/  195]    Loss 6.939980    Top1 0.413411    Top5 1.595052    
2021-11-16 06:51:02,899 - Test: [  130/  195]    Loss 6.941900    Top1 0.402644    Top5 1.592548    
2021-11-16 06:51:20,789 - Test: [  140/  195]    Loss 6.943617    Top1 0.390625    Top5 1.559710    
2021-11-16 06:51:38,681 - Test: [  150/  195]    Loss 6.942693    Top1 0.382812    Top5 1.541667    
2021-11-16 06:51:56,519 - Test: [  160/  195]    Loss 6.942754    Top1 0.380859    Top5 1.562500    
2021-11-16 06:52:14,392 - Test: [  170/  195]    Loss 6.942499    Top1 0.386029    Top5 1.585478    
2021-11-16 06:52:32,368 - Test: [  180/  195]    Loss 6.943440    Top1 0.384115    Top5 1.577691    
2021-11-16 06:52:50,370 - Test: [  190/  195]    Loss 6.943915    Top1 0.384457    Top5 1.558388    
2021-11-16 06:53:00,046 - ==> Top1: 0.384    Top5: 1.546    Loss: 6.945

2021-11-16 06:53:03,691 - --- test ---------------------
2021-11-16 06:53:03,692 - 50000 samples (256 per mini-batch)
2021-11-16 06:53:24,347 - Test: [   10/  195]    Loss 6.769368    Top1 0.781250    Top5 2.773437    
2021-11-16 06:53:42,176 - Test: [   20/  195]    Loss 6.758194    Top1 0.703125    Top5 2.617187    
2021-11-16 06:54:00,090 - Test: [   30/  195]    Loss 6.770491    Top1 0.664062    Top5 2.486979    
2021-11-16 06:54:17,940 - Test: [   40/  195]    Loss 6.774520    Top1 0.634766    Top5 2.333984    
2021-11-16 06:54:35,829 - Test: [   50/  195]    Loss 6.776153    Top1 0.640625    Top5 2.335937    
2021-11-16 06:54:53,860 - Test: [   60/  195]    Loss 6.776395    Top1 0.631510    Top5 2.382812    
2021-11-16 06:55:11,874 - Test: [   70/  195]    Loss 6.782146    Top1 0.580357    Top5 2.276786    
2021-11-16 06:55:29,736 - Test: [   80/  195]    Loss 6.781517    Top1 0.566406    Top5 2.265625    
2021-11-16 06:55:47,769 - Test: [   90/  195]    Loss 6.780794    Top1 0.577257    Top5 2.252604    
2021-11-16 06:56:05,718 - Test: [  100/  195]    Loss 6.781450    Top1 0.582031    Top5 2.253906    
2021-11-16 06:56:23,653 - Test: [  110/  195]    Loss 6.781355    Top1 0.585938    Top5 2.279830    
2021-11-16 06:56:41,615 - Test: [  120/  195]    Loss 6.781600    Top1 0.569661    Top5 2.265625    
2021-11-16 06:56:59,462 - Test: [  130/  195]    Loss 6.781137    Top1 0.549880    Top5 2.247596    
2021-11-16 06:57:17,466 - Test: [  140/  195]    Loss 6.779232    Top1 0.544085    Top5 2.273996    
2021-11-16 06:57:35,521 - Test: [  150/  195]    Loss 6.780718    Top1 0.531250    Top5 2.263021    
2021-11-16 06:57:53,363 - Test: [  160/  195]    Loss 6.780464    Top1 0.522461    Top5 2.260742    
2021-11-16 06:58:11,180 - Test: [  170/  195]    Loss 6.781331    Top1 0.517004    Top5 2.240349    
2021-11-16 06:58:29,129 - Test: [  180/  195]    Loss 6.781869    Top1 0.514323    Top5 2.213542    
2021-11-16 06:58:47,000 - Test: [  190/  195]    Loss 6.781789    Top1 0.530428    Top5 2.224507    
2021-11-16 06:58:56,680 - ==> Top1: 0.542    Top5: 2.240    Loss: 6.782

2021-11-16 06:59:00,278 - --- test ---------------------
2021-11-16 06:59:00,279 - 50000 samples (256 per mini-batch)
2021-11-16 06:59:22,706 - Test: [   10/  195]    Loss 6.943502    Top1 0.625000    Top5 1.757812    
2021-11-16 06:59:40,588 - Test: [   20/  195]    Loss 6.928453    Top1 0.429687    Top5 1.816406    
2021-11-16 06:59:58,467 - Test: [   30/  195]    Loss 6.933898    Top1 0.403646    Top5 1.796875    
2021-11-16 07:00:16,461 - Test: [   40/  195]    Loss 6.935831    Top1 0.400391    Top5 1.767578    
2021-11-16 07:00:34,469 - Test: [   50/  195]    Loss 6.936986    Top1 0.406250    Top5 1.718750    
2021-11-16 07:00:52,539 - Test: [   60/  195]    Loss 6.942073    Top1 0.384115    Top5 1.666667    
2021-11-16 07:01:10,401 - Test: [   70/  195]    Loss 6.944277    Top1 0.357143    Top5 1.612723    
2021-11-16 07:01:28,381 - Test: [   80/  195]    Loss 6.947787    Top1 0.346680    Top5 1.591797    
2021-11-16 07:01:46,424 - Test: [   90/  195]    Loss 6.946206    Top1 0.364583    Top5 1.618924    
2021-11-16 07:02:04,284 - Test: [  100/  195]    Loss 6.947867    Top1 0.351563    Top5 1.597656    
2021-11-16 07:02:22,422 - Test: [  110/  195]    Loss 6.947411    Top1 0.358665    Top5 1.619318    
2021-11-16 07:02:40,305 - Test: [  120/  195]    Loss 6.947423    Top1 0.367839    Top5 1.627604    
2021-11-16 07:02:58,375 - Test: [  130/  195]    Loss 6.948788    Top1 0.360577    Top5 1.631611    
2021-11-16 07:03:16,209 - Test: [  140/  195]    Loss 6.950195    Top1 0.359933    Top5 1.651786    
2021-11-16 07:03:34,179 - Test: [  150/  195]    Loss 6.951880    Top1 0.348958    Top5 1.643229    
2021-11-16 07:03:52,100 - Test: [  160/  195]    Loss 6.951717    Top1 0.356445    Top5 1.645508    
2021-11-16 07:04:10,006 - Test: [  170/  195]    Loss 6.952365    Top1 0.363051    Top5 1.654412    
2021-11-16 07:04:28,056 - Test: [  180/  195]    Loss 6.952978    Top1 0.358073    Top5 1.631944    
2021-11-16 07:04:45,969 - Test: [  190/  195]    Loss 6.952058    Top1 0.374178    Top5 1.632401    
2021-11-16 07:04:55,660 - ==> Top1: 0.372    Top5: 1.622    Loss: 6.952

2021-11-16 07:04:59,379 - --- test ---------------------
2021-11-16 07:04:59,379 - 50000 samples (256 per mini-batch)
2021-11-16 07:05:20,256 - Test: [   10/  195]    Loss 6.862884    Top1 0.312500    Top5 2.031250    
2021-11-16 07:05:38,017 - Test: [   20/  195]    Loss 6.846500    Top1 0.468750    Top5 2.500000    
2021-11-16 07:05:56,100 - Test: [   30/  195]    Loss 6.852726    Top1 0.390625    Top5 2.317708    
2021-11-16 07:06:13,975 - Test: [   40/  195]    Loss 6.845243    Top1 0.400391    Top5 2.353516    
2021-11-16 07:06:31,930 - Test: [   50/  195]    Loss 6.840650    Top1 0.398438    Top5 2.351563    
2021-11-16 07:06:49,948 - Test: [   60/  195]    Loss 6.842293    Top1 0.429687    Top5 2.356771    
2021-11-16 07:07:07,832 - Test: [   70/  195]    Loss 6.844699    Top1 0.407366    Top5 2.254464    
2021-11-16 07:07:25,746 - Test: [   80/  195]    Loss 6.845038    Top1 0.449219    Top5 2.319336    
2021-11-16 07:07:43,773 - Test: [   90/  195]    Loss 6.844236    Top1 0.438368    Top5 2.352431    
2021-11-16 07:08:01,719 - Test: [  100/  195]    Loss 6.844426    Top1 0.425781    Top5 2.371094    
2021-11-16 07:08:19,723 - Test: [  110/  195]    Loss 6.843543    Top1 0.436790    Top5 2.382812    
2021-11-16 07:08:37,814 - Test: [  120/  195]    Loss 6.842556    Top1 0.432943    Top5 2.369792    
2021-11-16 07:08:55,783 - Test: [  130/  195]    Loss 6.843199    Top1 0.414663    Top5 2.319712    
2021-11-16 07:09:13,942 - Test: [  140/  195]    Loss 6.844126    Top1 0.412946    Top5 2.310268    
2021-11-16 07:09:31,930 - Test: [  150/  195]    Loss 6.842926    Top1 0.419271    Top5 2.338542    
2021-11-16 07:09:49,832 - Test: [  160/  195]    Loss 6.843677    Top1 0.427246    Top5 2.353516    
2021-11-16 07:10:07,666 - Test: [  170/  195]    Loss 6.842639    Top1 0.427390    Top5 2.364430    
2021-11-16 07:10:25,736 - Test: [  180/  195]    Loss 6.840749    Top1 0.431858    Top5 2.358941    
2021-11-16 07:10:43,614 - Test: [  190/  195]    Loss 6.841403    Top1 0.425576    Top5 2.349918    
2021-11-16 07:10:53,380 - ==> Top1: 0.424    Top5: 2.356    Loss: 6.841

2021-11-16 07:10:57,065 - --- test ---------------------
2021-11-16 07:10:57,065 - 50000 samples (256 per mini-batch)
2021-11-16 07:11:18,335 - Test: [   10/  195]    Loss 6.768966    Top1 0.429687    Top5 2.460938    
2021-11-16 07:11:36,148 - Test: [   20/  195]    Loss 6.770007    Top1 0.507813    Top5 2.402344    
2021-11-16 07:11:53,975 - Test: [   30/  195]    Loss 6.772400    Top1 0.533854    Top5 2.395833    
2021-11-16 07:12:11,880 - Test: [   40/  195]    Loss 6.763430    Top1 0.566406    Top5 2.529297    
2021-11-16 07:12:30,106 - Test: [   50/  195]    Loss 6.761802    Top1 0.578125    Top5 2.523438    
2021-11-16 07:12:47,981 - Test: [   60/  195]    Loss 6.765664    Top1 0.585938    Top5 2.441406    
2021-11-16 07:13:06,000 - Test: [   70/  195]    Loss 6.764861    Top1 0.591518    Top5 2.427455    
2021-11-16 07:13:24,034 - Test: [   80/  195]    Loss 6.765067    Top1 0.600586    Top5 2.475586    
2021-11-16 07:13:42,087 - Test: [   90/  195]    Loss 6.766281    Top1 0.581597    Top5 2.378472    
2021-11-16 07:14:00,183 - Test: [  100/  195]    Loss 6.766405    Top1 0.597656    Top5 2.394531    
2021-11-16 07:14:18,058 - Test: [  110/  195]    Loss 6.767677    Top1 0.614347    Top5 2.425426    
2021-11-16 07:14:36,023 - Test: [  120/  195]    Loss 6.767534    Top1 0.621745    Top5 2.415365    
2021-11-16 07:14:54,053 - Test: [  130/  195]    Loss 6.768277    Top1 0.615986    Top5 2.436899    
2021-11-16 07:15:12,071 - Test: [  140/  195]    Loss 6.768704    Top1 0.611049    Top5 2.421875    
2021-11-16 07:15:30,159 - Test: [  150/  195]    Loss 6.768838    Top1 0.606771    Top5 2.416667    
2021-11-16 07:15:47,921 - Test: [  160/  195]    Loss 6.767919    Top1 0.625000    Top5 2.446289    
2021-11-16 07:16:05,983 - Test: [  170/  195]    Loss 6.768713    Top1 0.608915    Top5 2.426471    
2021-11-16 07:16:23,749 - Test: [  180/  195]    Loss 6.767270    Top1 0.616319    Top5 2.447917    
2021-11-16 07:16:41,648 - Test: [  190/  195]    Loss 6.766315    Top1 0.625000    Top5 2.440378    
2021-11-16 07:16:51,448 - ==> Top1: 0.620    Top5: 2.450    Loss: 6.767

2021-11-16 07:16:55,061 - --- test ---------------------
2021-11-16 07:16:55,061 - 50000 samples (256 per mini-batch)
2021-11-16 07:17:16,667 - Test: [   10/  195]    Loss 6.819150    Top1 0.546875    Top5 2.226562    
2021-11-16 07:17:34,443 - Test: [   20/  195]    Loss 6.820678    Top1 0.527344    Top5 2.265625    
2021-11-16 07:17:52,541 - Test: [   30/  195]    Loss 6.819200    Top1 0.546875    Top5 2.291667    
2021-11-16 07:18:10,383 - Test: [   40/  195]    Loss 6.821887    Top1 0.566406    Top5 2.324219    
2021-11-16 07:18:28,549 - Test: [   50/  195]    Loss 6.821822    Top1 0.570313    Top5 2.296875    
2021-11-16 07:18:46,384 - Test: [   60/  195]    Loss 6.821061    Top1 0.579427    Top5 2.304688    
2021-11-16 07:19:04,392 - Test: [   70/  195]    Loss 6.820776    Top1 0.602679    Top5 2.366071    
2021-11-16 07:19:22,432 - Test: [   80/  195]    Loss 6.820516    Top1 0.610352    Top5 2.397461    
2021-11-16 07:19:40,417 - Test: [   90/  195]    Loss 6.819683    Top1 0.611979    Top5 2.421875    
2021-11-16 07:19:58,485 - Test: [  100/  195]    Loss 6.818137    Top1 0.601562    Top5 2.425781    
2021-11-16 07:20:16,277 - Test: [  110/  195]    Loss 6.817381    Top1 0.625000    Top5 2.450284    
2021-11-16 07:20:34,236 - Test: [  120/  195]    Loss 6.817045    Top1 0.618490    Top5 2.425130    
2021-11-16 07:20:52,274 - Test: [  130/  195]    Loss 6.817131    Top1 0.621995    Top5 2.478966    
2021-11-16 07:21:10,237 - Test: [  140/  195]    Loss 6.816834    Top1 0.616629    Top5 2.488839    
2021-11-16 07:21:28,207 - Test: [  150/  195]    Loss 6.817371    Top1 0.617188    Top5 2.466146    
2021-11-16 07:21:46,150 - Test: [  160/  195]    Loss 6.817641    Top1 0.620117    Top5 2.492676    
2021-11-16 07:22:03,953 - Test: [  170/  195]    Loss 6.815945    Top1 0.618107    Top5 2.516085    
2021-11-16 07:22:21,834 - Test: [  180/  195]    Loss 6.817631    Top1 0.627170    Top5 2.500000    
2021-11-16 07:22:39,633 - Test: [  190/  195]    Loss 6.818456    Top1 0.637336    Top5 2.485609    
2021-11-16 07:22:49,313 - ==> Top1: 0.632    Top5: 2.490    Loss: 6.819

2021-11-16 07:22:52,867 - --- test ---------------------
2021-11-16 07:22:52,867 - 50000 samples (256 per mini-batch)
2021-11-16 07:23:14,513 - Test: [   10/  195]    Loss 6.623363    Top1 1.289063    Top5 5.078125    
2021-11-16 07:23:32,374 - Test: [   20/  195]    Loss 6.636868    Top1 1.191406    Top5 4.511719    
2021-11-16 07:23:50,284 - Test: [   30/  195]    Loss 6.639655    Top1 1.119792    Top5 4.505208    
2021-11-16 07:24:08,333 - Test: [   40/  195]    Loss 6.646755    Top1 1.035156    Top5 4.189453    
2021-11-16 07:24:26,299 - Test: [   50/  195]    Loss 6.644006    Top1 1.117188    Top5 4.156250    
2021-11-16 07:24:44,170 - Test: [   60/  195]    Loss 6.647100    Top1 1.106771    Top5 4.173177    
2021-11-16 07:25:02,249 - Test: [   70/  195]    Loss 6.646494    Top1 1.132813    Top5 4.224330    
2021-11-16 07:25:20,178 - Test: [   80/  195]    Loss 6.647448    Top1 1.157227    Top5 4.213867    
2021-11-16 07:25:38,259 - Test: [   90/  195]    Loss 6.649329    Top1 1.154514    Top5 4.231771    
2021-11-16 07:25:56,333 - Test: [  100/  195]    Loss 6.651440    Top1 1.144531    Top5 4.195313    
2021-11-16 07:26:14,097 - Test: [  110/  195]    Loss 6.649851    Top1 1.125710    Top5 4.229403    
2021-11-16 07:26:32,136 - Test: [  120/  195]    Loss 6.649053    Top1 1.155599    Top5 4.277344    
2021-11-16 07:26:50,159 - Test: [  130/  195]    Loss 6.650681    Top1 1.147837    Top5 4.278846    
2021-11-16 07:27:08,075 - Test: [  140/  195]    Loss 6.650437    Top1 1.121652    Top5 4.271763    
2021-11-16 07:27:25,977 - Test: [  150/  195]    Loss 6.649815    Top1 1.161458    Top5 4.304688    
2021-11-16 07:27:43,921 - Test: [  160/  195]    Loss 6.649458    Top1 1.176758    Top5 4.333496    
2021-11-16 07:28:01,841 - Test: [  170/  195]    Loss 6.649807    Top1 1.183364    Top5 4.331342    
2021-11-16 07:28:19,722 - Test: [  180/  195]    Loss 6.650376    Top1 1.189236    Top5 4.351128    
2021-11-16 07:28:37,811 - Test: [  190/  195]    Loss 6.650631    Top1 1.200658    Top5 4.383224    
2021-11-16 07:28:47,445 - ==> Top1: 1.204    Top5: 4.384    Loss: 6.650

2021-11-16 07:28:50,902 - --- test ---------------------
2021-11-16 07:28:50,903 - 50000 samples (256 per mini-batch)
2021-11-16 07:29:12,725 - Test: [   10/  195]    Loss 6.799496    Top1 0.507813    Top5 1.835937    
2021-11-16 07:29:30,548 - Test: [   20/  195]    Loss 6.778535    Top1 0.546875    Top5 2.226562    
2021-11-16 07:29:48,513 - Test: [   30/  195]    Loss 6.775078    Top1 0.598958    Top5 2.200521    
2021-11-16 07:30:06,336 - Test: [   40/  195]    Loss 6.769645    Top1 0.595703    Top5 2.304688    
2021-11-16 07:30:24,245 - Test: [   50/  195]    Loss 6.769567    Top1 0.585938    Top5 2.304688    
2021-11-16 07:30:42,416 - Test: [   60/  195]    Loss 6.768489    Top1 0.540365    Top5 2.272135    
2021-11-16 07:31:00,268 - Test: [   70/  195]    Loss 6.771111    Top1 0.535714    Top5 2.276786    
2021-11-16 07:31:18,264 - Test: [   80/  195]    Loss 6.771534    Top1 0.546875    Top5 2.270508    
2021-11-16 07:31:36,224 - Test: [   90/  195]    Loss 6.770355    Top1 0.538194    Top5 2.248264    
2021-11-16 07:31:54,141 - Test: [  100/  195]    Loss 6.772192    Top1 0.539062    Top5 2.218750    
2021-11-16 07:32:12,227 - Test: [  110/  195]    Loss 6.771438    Top1 0.539773    Top5 2.237216    
2021-11-16 07:32:30,252 - Test: [  120/  195]    Loss 6.771182    Top1 0.543620    Top5 2.226562    
2021-11-16 07:32:48,190 - Test: [  130/  195]    Loss 6.771095    Top1 0.582933    Top5 2.265625    
2021-11-16 07:33:06,330 - Test: [  140/  195]    Loss 6.771486    Top1 0.602679    Top5 2.285156    
2021-11-16 07:33:24,392 - Test: [  150/  195]    Loss 6.772020    Top1 0.601562    Top5 2.270833    
2021-11-16 07:33:42,188 - Test: [  160/  195]    Loss 6.772517    Top1 0.578613    Top5 2.255859    
2021-11-16 07:34:00,104 - Test: [  170/  195]    Loss 6.772124    Top1 0.565257    Top5 2.242647    
2021-11-16 07:34:18,008 - Test: [  180/  195]    Loss 6.773407    Top1 0.546875    Top5 2.204861    
2021-11-16 07:34:35,910 - Test: [  190/  195]    Loss 6.773152    Top1 0.550987    Top5 2.230674    
2021-11-16 07:34:45,575 - ==> Top1: 0.546    Top5: 2.214    Loss: 6.774

2021-11-16 07:34:49,166 - --- test ---------------------
2021-11-16 07:34:49,166 - 50000 samples (256 per mini-batch)
2021-11-16 07:35:11,191 - Test: [   10/  195]    Loss 6.743421    Top1 0.898438    Top5 3.164062    
2021-11-16 07:35:29,019 - Test: [   20/  195]    Loss 6.759600    Top1 0.976562    Top5 3.085938    
2021-11-16 07:35:46,858 - Test: [   30/  195]    Loss 6.772029    Top1 0.872396    Top5 3.085938    
2021-11-16 07:36:04,938 - Test: [   40/  195]    Loss 6.769836    Top1 0.908203    Top5 3.193359    
2021-11-16 07:36:22,855 - Test: [   50/  195]    Loss 6.768782    Top1 0.953125    Top5 3.171875    
2021-11-16 07:36:40,724 - Test: [   60/  195]    Loss 6.769888    Top1 0.917969    Top5 3.072917    
2021-11-16 07:36:58,680 - Test: [   70/  195]    Loss 6.766644    Top1 0.948661    Top5 3.085938    
2021-11-16 07:37:16,635 - Test: [   80/  195]    Loss 6.769896    Top1 0.976562    Top5 3.066406    
2021-11-16 07:37:34,621 - Test: [   90/  195]    Loss 6.770292    Top1 1.011285    Top5 3.120660    
2021-11-16 07:37:52,692 - Test: [  100/  195]    Loss 6.768655    Top1 0.992187    Top5 3.121094    
2021-11-16 07:38:10,592 - Test: [  110/  195]    Loss 6.771605    Top1 0.994318    Top5 3.110795    
2021-11-16 07:38:28,488 - Test: [  120/  195]    Loss 6.772221    Top1 0.986328    Top5 3.069661    
2021-11-16 07:38:46,528 - Test: [  130/  195]    Loss 6.772198    Top1 0.985577    Top5 3.052885    
2021-11-16 07:39:04,571 - Test: [  140/  195]    Loss 6.773277    Top1 0.982143    Top5 3.052455    
2021-11-16 07:39:22,493 - Test: [  150/  195]    Loss 6.772804    Top1 0.973958    Top5 3.041667    
2021-11-16 07:39:40,303 - Test: [  160/  195]    Loss 6.773873    Top1 0.939941    Top5 2.980957    
2021-11-16 07:39:58,227 - Test: [  170/  195]    Loss 6.773651    Top1 0.939798    Top5 2.954963    
2021-11-16 07:40:16,172 - Test: [  180/  195]    Loss 6.772667    Top1 0.939670    Top5 2.953559    
2021-11-16 07:40:33,978 - Test: [  190/  195]    Loss 6.772746    Top1 0.931332    Top5 2.946135    
2021-11-16 07:40:43,730 - ==> Top1: 0.928    Top5: 2.928    Loss: 6.773

2021-11-16 07:40:47,285 - --- test ---------------------
2021-11-16 07:40:47,285 - 50000 samples (256 per mini-batch)
2021-11-16 07:41:08,706 - Test: [   10/  195]    Loss 6.832101    Top1 0.468750    Top5 1.757812    
2021-11-16 07:41:26,460 - Test: [   20/  195]    Loss 6.831276    Top1 0.488281    Top5 1.875000    
2021-11-16 07:41:44,387 - Test: [   30/  195]    Loss 6.837412    Top1 0.468750    Top5 1.796875    
2021-11-16 07:42:02,301 - Test: [   40/  195]    Loss 6.836291    Top1 0.419922    Top5 1.679688    
2021-11-16 07:42:20,333 - Test: [   50/  195]    Loss 6.840943    Top1 0.398438    Top5 1.640625    
2021-11-16 07:42:38,351 - Test: [   60/  195]    Loss 6.839635    Top1 0.390625    Top5 1.699219    
2021-11-16 07:42:56,166 - Test: [   70/  195]    Loss 6.838464    Top1 0.390625    Top5 1.735491    
2021-11-16 07:43:14,146 - Test: [   80/  195]    Loss 6.843958    Top1 0.395508    Top5 1.704102    
2021-11-16 07:43:32,160 - Test: [   90/  195]    Loss 6.843828    Top1 0.407986    Top5 1.723090    
2021-11-16 07:43:50,032 - Test: [  100/  195]    Loss 6.844600    Top1 0.394531    Top5 1.730469    
2021-11-16 07:44:08,103 - Test: [  110/  195]    Loss 6.843987    Top1 0.404830    Top5 1.754261    
2021-11-16 07:44:25,973 - Test: [  120/  195]    Loss 6.843934    Top1 0.406901    Top5 1.751302    
2021-11-16 07:44:43,970 - Test: [  130/  195]    Loss 6.844918    Top1 0.423678    Top5 1.763822    
2021-11-16 07:45:01,951 - Test: [  140/  195]    Loss 6.844772    Top1 0.429687    Top5 1.794085    
2021-11-16 07:45:20,022 - Test: [  150/  195]    Loss 6.842955    Top1 0.450521    Top5 1.820312    
2021-11-16 07:45:37,814 - Test: [  160/  195]    Loss 6.842023    Top1 0.449219    Top5 1.828613    
2021-11-16 07:45:55,663 - Test: [  170/  195]    Loss 6.842318    Top1 0.452665    Top5 1.801471    
2021-11-16 07:46:13,454 - Test: [  180/  195]    Loss 6.840474    Top1 0.453559    Top5 1.838108    
2021-11-16 07:46:31,384 - Test: [  190/  195]    Loss 6.839871    Top1 0.460526    Top5 1.850329    
2021-11-16 07:46:41,116 - ==> Top1: 0.466    Top5: 1.862    Loss: 6.840

2021-11-16 07:46:44,850 - --- test ---------------------
2021-11-16 07:46:44,851 - 50000 samples (256 per mini-batch)
2021-11-16 07:47:07,049 - Test: [   10/  195]    Loss 6.853845    Top1 0.468750    Top5 1.875000    
2021-11-16 07:47:24,843 - Test: [   20/  195]    Loss 6.853040    Top1 0.351563    Top5 1.855469    
2021-11-16 07:47:42,711 - Test: [   30/  195]    Loss 6.853557    Top1 0.299479    Top5 1.783854    
2021-11-16 07:48:00,815 - Test: [   40/  195]    Loss 6.854584    Top1 0.292969    Top5 1.875000    
2021-11-16 07:48:18,797 - Test: [   50/  195]    Loss 6.857655    Top1 0.289063    Top5 1.812500    
2021-11-16 07:48:36,717 - Test: [   60/  195]    Loss 6.857145    Top1 0.279948    Top5 1.809896    
2021-11-16 07:48:54,645 - Test: [   70/  195]    Loss 6.859586    Top1 0.267857    Top5 1.802455    
2021-11-16 07:49:12,685 - Test: [   80/  195]    Loss 6.858645    Top1 0.249023    Top5 1.777344    
2021-11-16 07:49:30,556 - Test: [   90/  195]    Loss 6.859814    Top1 0.256076    Top5 1.762153    
2021-11-16 07:49:48,667 - Test: [  100/  195]    Loss 6.859893    Top1 0.246094    Top5 1.746094    
2021-11-16 07:50:06,562 - Test: [  110/  195]    Loss 6.858507    Top1 0.252131    Top5 1.743608    
2021-11-16 07:50:24,494 - Test: [  120/  195]    Loss 6.858899    Top1 0.250651    Top5 1.705729    
2021-11-16 07:50:42,652 - Test: [  130/  195]    Loss 6.858322    Top1 0.258413    Top5 1.721755    
2021-11-16 07:51:00,750 - Test: [  140/  195]    Loss 6.859188    Top1 0.253906    Top5 1.707589    
2021-11-16 07:51:18,633 - Test: [  150/  195]    Loss 6.860524    Top1 0.255208    Top5 1.708333    
2021-11-16 07:51:36,509 - Test: [  160/  195]    Loss 6.860717    Top1 0.251465    Top5 1.713867    
2021-11-16 07:51:54,361 - Test: [  170/  195]    Loss 6.861417    Top1 0.245864    Top5 1.721048    
2021-11-16 07:52:12,277 - Test: [  180/  195]    Loss 6.860681    Top1 0.249566    Top5 1.757812    
2021-11-16 07:52:30,303 - Test: [  190/  195]    Loss 6.861572    Top1 0.244655    Top5 1.739309    
2021-11-16 07:52:40,106 - ==> Top1: 0.244    Top5: 1.750    Loss: 6.861

2021-11-16 07:52:43,840 - --- test ---------------------
2021-11-16 07:52:43,840 - 50000 samples (256 per mini-batch)
2021-11-16 07:53:04,715 - Test: [   10/  195]    Loss 6.783903    Top1 0.429687    Top5 1.679688    
2021-11-16 07:53:22,577 - Test: [   20/  195]    Loss 6.780320    Top1 0.507813    Top5 1.894531    
2021-11-16 07:53:40,549 - Test: [   30/  195]    Loss 6.782989    Top1 0.507813    Top5 2.031250    
2021-11-16 07:53:58,756 - Test: [   40/  195]    Loss 6.778323    Top1 0.488281    Top5 2.070313    
2021-11-16 07:54:16,865 - Test: [   50/  195]    Loss 6.779912    Top1 0.476562    Top5 2.007812    
2021-11-16 07:54:34,842 - Test: [   60/  195]    Loss 6.780076    Top1 0.475260    Top5 1.985677    
2021-11-16 07:54:52,906 - Test: [   70/  195]    Loss 6.781018    Top1 0.491071    Top5 1.964286    
2021-11-16 07:55:10,957 - Test: [   80/  195]    Loss 6.779513    Top1 0.483398    Top5 1.992187    
2021-11-16 07:55:28,925 - Test: [   90/  195]    Loss 6.777876    Top1 0.490451    Top5 1.979167    
2021-11-16 07:55:46,821 - Test: [  100/  195]    Loss 6.779589    Top1 0.496094    Top5 1.957031    
2021-11-16 07:56:04,667 - Test: [  110/  195]    Loss 6.780485    Top1 0.493608    Top5 1.967330    
2021-11-16 07:56:22,737 - Test: [  120/  195]    Loss 6.776989    Top1 0.533854    Top5 2.057292    
2021-11-16 07:56:40,795 - Test: [  130/  195]    Loss 6.776559    Top1 0.549880    Top5 2.073317    
2021-11-16 07:56:58,754 - Test: [  140/  195]    Loss 6.775263    Top1 0.566406    Top5 2.098214    
2021-11-16 07:57:16,655 - Test: [  150/  195]    Loss 6.777057    Top1 0.562500    Top5 2.078125    
2021-11-16 07:57:34,521 - Test: [  160/  195]    Loss 6.777801    Top1 0.578613    Top5 2.084961    
2021-11-16 07:57:52,455 - Test: [  170/  195]    Loss 6.776807    Top1 0.579044    Top5 2.118566    
2021-11-16 07:58:10,279 - Test: [  180/  195]    Loss 6.777767    Top1 0.568576    Top5 2.118056    
2021-11-16 07:58:28,049 - Test: [  190/  195]    Loss 6.777794    Top1 0.569490    Top5 2.113487    
2021-11-16 07:58:37,890 - ==> Top1: 0.560    Top5: 2.106    Loss: 6.779

2021-11-16 07:58:41,566 - --- test ---------------------
2021-11-16 07:58:41,567 - 50000 samples (256 per mini-batch)
2021-11-16 07:59:02,491 - Test: [   10/  195]    Loss 6.799782    Top1 0.546875    Top5 3.164062    
2021-11-16 07:59:20,308 - Test: [   20/  195]    Loss 6.804023    Top1 0.468750    Top5 2.871094    
2021-11-16 07:59:38,326 - Test: [   30/  195]    Loss 6.811834    Top1 0.481771    Top5 2.864583    
2021-11-16 07:59:56,354 - Test: [   40/  195]    Loss 6.806941    Top1 0.595703    Top5 3.027344    
2021-11-16 08:00:14,334 - Test: [   50/  195]    Loss 6.808192    Top1 0.601562    Top5 2.945312    
2021-11-16 08:00:32,229 - Test: [   60/  195]    Loss 6.809146    Top1 0.592448    Top5 2.910156    
2021-11-16 08:00:50,173 - Test: [   70/  195]    Loss 6.808086    Top1 0.608259    Top5 2.912946    
2021-11-16 08:01:08,072 - Test: [   80/  195]    Loss 6.807145    Top1 0.644531    Top5 2.900391    
2021-11-16 08:01:25,903 - Test: [   90/  195]    Loss 6.807111    Top1 0.598958    Top5 2.821181    
2021-11-16 08:01:43,839 - Test: [  100/  195]    Loss 6.808073    Top1 0.597656    Top5 2.757813    
2021-11-16 08:02:01,989 - Test: [  110/  195]    Loss 6.807484    Top1 0.600142    Top5 2.745028    
2021-11-16 08:02:20,064 - Test: [  120/  195]    Loss 6.807038    Top1 0.589193    Top5 2.737630    
2021-11-16 08:02:37,934 - Test: [  130/  195]    Loss 6.807104    Top1 0.597957    Top5 2.770433    
2021-11-16 08:02:55,928 - Test: [  140/  195]    Loss 6.807307    Top1 0.602679    Top5 2.756696    
2021-11-16 08:03:13,855 - Test: [  150/  195]    Loss 6.806459    Top1 0.614583    Top5 2.752604    
2021-11-16 08:03:31,596 - Test: [  160/  195]    Loss 6.806149    Top1 0.615234    Top5 2.775879    
2021-11-16 08:03:49,423 - Test: [  170/  195]    Loss 6.807454    Top1 0.613511    Top5 2.761949    
2021-11-16 08:04:07,280 - Test: [  180/  195]    Loss 6.807577    Top1 0.607639    Top5 2.749566    
2021-11-16 08:04:25,075 - Test: [  190/  195]    Loss 6.806938    Top1 0.616776    Top5 2.765214    
2021-11-16 08:04:34,723 - ==> Top1: 0.620    Top5: 2.762    Loss: 6.807

2021-11-16 08:04:38,399 - --- test ---------------------
2021-11-16 08:04:38,399 - 50000 samples (256 per mini-batch)
2021-11-16 08:05:01,133 - Test: [   10/  195]    Loss 6.775533    Top1 0.937500    Top5 3.007812    
2021-11-16 08:05:18,975 - Test: [   20/  195]    Loss 6.776012    Top1 0.839844    Top5 3.027344    
2021-11-16 08:05:36,781 - Test: [   30/  195]    Loss 6.777978    Top1 0.781250    Top5 2.916667    
2021-11-16 08:05:54,813 - Test: [   40/  195]    Loss 6.788689    Top1 0.693359    Top5 2.568359    
2021-11-16 08:06:12,845 - Test: [   50/  195]    Loss 6.780384    Top1 0.718750    Top5 2.734375    
2021-11-16 08:06:30,673 - Test: [   60/  195]    Loss 6.781552    Top1 0.716146    Top5 2.753906    
2021-11-16 08:06:48,768 - Test: [   70/  195]    Loss 6.781042    Top1 0.719866    Top5 2.762277    
2021-11-16 08:07:06,733 - Test: [   80/  195]    Loss 6.780219    Top1 0.722656    Top5 2.763672    
2021-11-16 08:07:24,641 - Test: [   90/  195]    Loss 6.776758    Top1 0.703125    Top5 2.795139    
2021-11-16 08:07:42,496 - Test: [  100/  195]    Loss 6.776927    Top1 0.699219    Top5 2.789062    
2021-11-16 08:08:00,533 - Test: [  110/  195]    Loss 6.774698    Top1 0.692472    Top5 2.837358    
2021-11-16 08:08:18,396 - Test: [  120/  195]    Loss 6.775450    Top1 0.696615    Top5 2.799479    
2021-11-16 08:08:36,360 - Test: [  130/  195]    Loss 6.777731    Top1 0.694111    Top5 2.791466    
2021-11-16 08:08:54,306 - Test: [  140/  195]    Loss 6.778728    Top1 0.691964    Top5 2.770647    
2021-11-16 08:09:12,145 - Test: [  150/  195]    Loss 6.777950    Top1 0.705729    Top5 2.799479    
2021-11-16 08:09:30,105 - Test: [  160/  195]    Loss 6.779045    Top1 0.708008    Top5 2.788086    
2021-11-16 08:09:47,892 - Test: [  170/  195]    Loss 6.778788    Top1 0.703125    Top5 2.791820    
2021-11-16 08:10:05,848 - Test: [  180/  195]    Loss 6.778182    Top1 0.711806    Top5 2.784288    
2021-11-16 08:10:23,662 - Test: [  190/  195]    Loss 6.777391    Top1 0.725740    Top5 2.791941    
2021-11-16 08:10:33,406 - ==> Top1: 0.734    Top5: 2.798    Loss: 6.778

2021-11-16 08:10:37,508 - --- test ---------------------
2021-11-16 08:10:37,509 - 50000 samples (256 per mini-batch)
2021-11-16 08:10:59,730 - Test: [   10/  195]    Loss 6.752069    Top1 0.664062    Top5 2.617187    
2021-11-16 08:11:17,567 - Test: [   20/  195]    Loss 6.740704    Top1 0.605469    Top5 2.636719    
2021-11-16 08:11:35,560 - Test: [   30/  195]    Loss 6.741662    Top1 0.585938    Top5 2.565104    
2021-11-16 08:11:53,474 - Test: [   40/  195]    Loss 6.735876    Top1 0.664062    Top5 2.744141    
2021-11-16 08:12:11,398 - Test: [   50/  195]    Loss 6.733867    Top1 0.703125    Top5 2.703125    
2021-11-16 08:12:29,413 - Test: [   60/  195]    Loss 6.734590    Top1 0.690104    Top5 2.695313    
2021-11-16 08:12:47,440 - Test: [   70/  195]    Loss 6.734971    Top1 0.669643    Top5 2.639509    
2021-11-16 08:13:05,454 - Test: [   80/  195]    Loss 6.738776    Top1 0.668945    Top5 2.617187    
2021-11-16 08:13:23,351 - Test: [   90/  195]    Loss 6.738800    Top1 0.659722    Top5 2.608507    
2021-11-16 08:13:41,293 - Test: [  100/  195]    Loss 6.736561    Top1 0.644531    Top5 2.613281    
2021-11-16 08:13:59,240 - Test: [  110/  195]    Loss 6.738609    Top1 0.614347    Top5 2.578125    
2021-11-16 08:14:17,424 - Test: [  120/  195]    Loss 6.740602    Top1 0.618490    Top5 2.552083    
2021-11-16 08:14:35,441 - Test: [  130/  195]    Loss 6.739836    Top1 0.628005    Top5 2.572115    
2021-11-16 08:14:53,381 - Test: [  140/  195]    Loss 6.740775    Top1 0.633371    Top5 2.566964    
2021-11-16 08:15:11,225 - Test: [  150/  195]    Loss 6.741953    Top1 0.630208    Top5 2.567708    
2021-11-16 08:15:29,420 - Test: [  160/  195]    Loss 6.740937    Top1 0.642090    Top5 2.595215    
2021-11-16 08:15:47,315 - Test: [  170/  195]    Loss 6.740221    Top1 0.652574    Top5 2.619485    
2021-11-16 08:16:05,137 - Test: [  180/  195]    Loss 6.740495    Top1 0.651042    Top5 2.615017    
2021-11-16 08:16:23,117 - Test: [  190/  195]    Loss 6.739360    Top1 0.657895    Top5 2.619243    
2021-11-16 08:16:32,799 - ==> Top1: 0.676    Top5: 2.644    Loss: 6.739

2021-11-16 08:16:36,747 - --- test ---------------------
2021-11-16 08:16:36,748 - 50000 samples (256 per mini-batch)
2021-11-16 08:16:59,133 - Test: [   10/  195]    Loss 6.825887    Top1 1.015625    Top5 2.265625    
2021-11-16 08:17:16,973 - Test: [   20/  195]    Loss 6.826046    Top1 0.820312    Top5 2.128906    
2021-11-16 08:17:34,800 - Test: [   30/  195]    Loss 6.818453    Top1 0.742188    Top5 2.200521    
2021-11-16 08:17:52,784 - Test: [   40/  195]    Loss 6.822137    Top1 0.664062    Top5 2.041016    
2021-11-16 08:18:10,880 - Test: [   50/  195]    Loss 6.818998    Top1 0.640625    Top5 2.125000    
2021-11-16 08:18:28,745 - Test: [   60/  195]    Loss 6.820756    Top1 0.598958    Top5 1.972656    
2021-11-16 08:18:46,831 - Test: [   70/  195]    Loss 6.818400    Top1 0.641741    Top5 2.059152    
2021-11-16 08:19:04,771 - Test: [   80/  195]    Loss 6.817801    Top1 0.644531    Top5 2.084961    
2021-11-16 08:19:22,796 - Test: [   90/  195]    Loss 6.816835    Top1 0.646701    Top5 2.109375    
2021-11-16 08:19:40,766 - Test: [  100/  195]    Loss 6.817136    Top1 0.656250    Top5 2.167969    
2021-11-16 08:19:58,672 - Test: [  110/  195]    Loss 6.816858    Top1 0.653409    Top5 2.169744    
2021-11-16 08:20:16,570 - Test: [  120/  195]    Loss 6.816968    Top1 0.647786    Top5 2.171224    
2021-11-16 08:20:34,520 - Test: [  130/  195]    Loss 6.816842    Top1 0.631010    Top5 2.151442    
2021-11-16 08:20:52,538 - Test: [  140/  195]    Loss 6.815975    Top1 0.625000    Top5 2.142857    
2021-11-16 08:21:10,495 - Test: [  150/  195]    Loss 6.815575    Top1 0.627604    Top5 2.164062    
2021-11-16 08:21:28,417 - Test: [  160/  195]    Loss 6.816396    Top1 0.607910    Top5 2.148438    
2021-11-16 08:21:46,211 - Test: [  170/  195]    Loss 6.816224    Top1 0.599724    Top5 2.127757    
2021-11-16 08:22:04,116 - Test: [  180/  195]    Loss 6.815320    Top1 0.605469    Top5 2.150608    
2021-11-16 08:22:21,935 - Test: [  190/  195]    Loss 6.815904    Top1 0.608553    Top5 2.171053    
2021-11-16 08:22:31,753 - ==> Top1: 0.612    Top5: 2.178    Loss: 6.815

2021-11-16 08:22:35,412 - --- test ---------------------
2021-11-16 08:22:35,413 - 50000 samples (256 per mini-batch)
2021-11-16 08:22:56,485 - Test: [   10/  195]    Loss 6.812086    Top1 0.429687    Top5 2.148438    
2021-11-16 08:23:14,400 - Test: [   20/  195]    Loss 6.791539    Top1 0.546875    Top5 2.343750    
2021-11-16 08:23:32,211 - Test: [   30/  195]    Loss 6.788874    Top1 0.533854    Top5 2.317708    
2021-11-16 08:23:50,109 - Test: [   40/  195]    Loss 6.787351    Top1 0.517578    Top5 2.441406    
2021-11-16 08:24:08,308 - Test: [   50/  195]    Loss 6.782318    Top1 0.515625    Top5 2.460938    
2021-11-16 08:24:26,141 - Test: [   60/  195]    Loss 6.783395    Top1 0.514323    Top5 2.467448    
2021-11-16 08:24:43,974 - Test: [   70/  195]    Loss 6.783240    Top1 0.496652    Top5 2.444196    
2021-11-16 08:25:01,884 - Test: [   80/  195]    Loss 6.781792    Top1 0.537109    Top5 2.548828    
2021-11-16 08:25:19,918 - Test: [   90/  195]    Loss 6.779662    Top1 0.559896    Top5 2.573785    
2021-11-16 08:25:37,844 - Test: [  100/  195]    Loss 6.781634    Top1 0.574219    Top5 2.582031    
2021-11-16 08:25:55,930 - Test: [  110/  195]    Loss 6.780948    Top1 0.568182    Top5 2.588778    
2021-11-16 08:26:13,766 - Test: [  120/  195]    Loss 6.782421    Top1 0.572917    Top5 2.561849    
2021-11-16 08:26:31,773 - Test: [  130/  195]    Loss 6.782961    Top1 0.573918    Top5 2.545072    
2021-11-16 08:26:49,931 - Test: [  140/  195]    Loss 6.783643    Top1 0.580357    Top5 2.519531    
2021-11-16 08:27:07,908 - Test: [  150/  195]    Loss 6.784023    Top1 0.572917    Top5 2.507812    
2021-11-16 08:27:25,751 - Test: [  160/  195]    Loss 6.786147    Top1 0.566406    Top5 2.478027    
2021-11-16 08:27:43,942 - Test: [  170/  195]    Loss 6.787405    Top1 0.567555    Top5 2.467831    
2021-11-16 08:28:01,802 - Test: [  180/  195]    Loss 6.788121    Top1 0.581597    Top5 2.467448    
2021-11-16 08:28:19,765 - Test: [  190/  195]    Loss 6.787902    Top1 0.592105    Top5 2.462993    
2021-11-16 08:28:29,429 - ==> Top1: 0.594    Top5: 2.472    Loss: 6.788

2021-11-16 08:28:32,795 - --- test ---------------------
2021-11-16 08:28:32,796 - 50000 samples (256 per mini-batch)
2021-11-16 08:28:54,710 - Test: [   10/  195]    Loss 6.876656    Top1 0.390625    Top5 2.656250    
2021-11-16 08:29:12,539 - Test: [   20/  195]    Loss 6.861847    Top1 0.664062    Top5 2.988281    
2021-11-16 08:29:30,522 - Test: [   30/  195]    Loss 6.873801    Top1 0.677083    Top5 2.929688    
2021-11-16 08:29:48,563 - Test: [   40/  195]    Loss 6.872453    Top1 0.654297    Top5 2.988281    
2021-11-16 08:30:06,540 - Test: [   50/  195]    Loss 6.874306    Top1 0.679688    Top5 2.976563    
2021-11-16 08:30:24,588 - Test: [   60/  195]    Loss 6.873897    Top1 0.638021    Top5 2.910156    
2021-11-16 08:30:42,673 - Test: [   70/  195]    Loss 6.874510    Top1 0.636161    Top5 2.912946    
2021-11-16 08:31:00,916 - Test: [   80/  195]    Loss 6.877061    Top1 0.644531    Top5 2.924805    
2021-11-16 08:31:19,059 - Test: [   90/  195]    Loss 6.875552    Top1 0.629340    Top5 2.938368    
2021-11-16 08:31:37,035 - Test: [  100/  195]    Loss 6.876644    Top1 0.585938    Top5 2.875000    
2021-11-16 08:31:55,017 - Test: [  110/  195]    Loss 6.879742    Top1 0.557528    Top5 2.819602    
2021-11-16 08:32:13,086 - Test: [  120/  195]    Loss 6.880149    Top1 0.553385    Top5 2.845052    
2021-11-16 08:32:31,069 - Test: [  130/  195]    Loss 6.879837    Top1 0.534856    Top5 2.809495    
2021-11-16 08:32:49,420 - Test: [  140/  195]    Loss 6.877195    Top1 0.541295    Top5 2.834821    
2021-11-16 08:33:07,495 - Test: [  150/  195]    Loss 6.877388    Top1 0.523438    Top5 2.864583    
2021-11-16 08:33:25,467 - Test: [  160/  195]    Loss 6.878638    Top1 0.524902    Top5 2.873535    
2021-11-16 08:33:43,318 - Test: [  170/  195]    Loss 6.877625    Top1 0.535386    Top5 2.886029    
2021-11-16 08:34:01,344 - Test: [  180/  195]    Loss 6.877148    Top1 0.531684    Top5 2.886285    
2021-11-16 08:34:19,553 - Test: [  190/  195]    Loss 6.879950    Top1 0.522204    Top5 2.872122    
2021-11-16 08:34:29,216 - ==> Top1: 0.518    Top5: 2.850    Loss: 6.880

2021-11-16 08:34:32,332 - --- test ---------------------
2021-11-16 08:34:32,332 - 50000 samples (256 per mini-batch)
2021-11-16 08:34:53,023 - Test: [   10/  195]    Loss 6.891138    Top1 0.312500    Top5 2.460938    
2021-11-16 08:35:10,978 - Test: [   20/  195]    Loss 6.896202    Top1 0.332031    Top5 2.285156    
2021-11-16 08:35:29,103 - Test: [   30/  195]    Loss 6.899522    Top1 0.364583    Top5 2.161458    
2021-11-16 08:35:47,082 - Test: [   40/  195]    Loss 6.901408    Top1 0.380859    Top5 2.158203    
2021-11-16 08:36:05,231 - Test: [   50/  195]    Loss 6.901710    Top1 0.390625    Top5 2.132813    
2021-11-16 08:36:23,509 - Test: [   60/  195]    Loss 6.900856    Top1 0.384115    Top5 2.096354    
2021-11-16 08:36:41,714 - Test: [   70/  195]    Loss 6.898362    Top1 0.401786    Top5 2.137277    
2021-11-16 08:36:59,556 - Test: [   80/  195]    Loss 6.898142    Top1 0.419922    Top5 2.138672    
2021-11-16 08:37:17,609 - Test: [   90/  195]    Loss 6.896619    Top1 0.412326    Top5 2.122396    
2021-11-16 08:37:35,656 - Test: [  100/  195]    Loss 6.898117    Top1 0.414063    Top5 2.164062    
2021-11-16 08:37:53,567 - Test: [  110/  195]    Loss 6.897905    Top1 0.404830    Top5 2.123580    
2021-11-16 08:38:11,814 - Test: [  120/  195]    Loss 6.897688    Top1 0.416667    Top5 2.109375    
2021-11-16 08:38:29,860 - Test: [  130/  195]    Loss 6.894589    Top1 0.432692    Top5 2.142428    
2021-11-16 08:38:48,335 - Test: [  140/  195]    Loss 6.893075    Top1 0.443638    Top5 2.140067    
2021-11-16 08:39:06,366 - Test: [  150/  195]    Loss 6.893048    Top1 0.447917    Top5 2.143229    
2021-11-16 08:39:24,452 - Test: [  160/  195]    Loss 6.893207    Top1 0.463867    Top5 2.194824    
2021-11-16 08:39:42,519 - Test: [  170/  195]    Loss 6.894102    Top1 0.461857    Top5 2.189798    
2021-11-16 08:40:00,554 - Test: [  180/  195]    Loss 6.895020    Top1 0.447049    Top5 2.180990    
2021-11-16 08:40:18,499 - Test: [  190/  195]    Loss 6.894445    Top1 0.448191    Top5 2.177220    
2021-11-16 08:40:28,301 - ==> Top1: 0.446    Top5: 2.168    Loss: 6.895

2021-11-16 08:40:31,630 - --- test ---------------------
2021-11-16 08:40:31,631 - 50000 samples (256 per mini-batch)
2021-11-16 08:40:53,654 - Test: [   10/  195]    Loss 6.842872    Top1 0.390625    Top5 1.953125    
2021-11-16 08:41:11,848 - Test: [   20/  195]    Loss 6.829410    Top1 0.585938    Top5 2.421875    
2021-11-16 08:41:30,068 - Test: [   30/  195]    Loss 6.826350    Top1 0.585938    Top5 2.421875    
2021-11-16 08:41:48,181 - Test: [   40/  195]    Loss 6.829915    Top1 0.615234    Top5 2.275391    
2021-11-16 08:42:06,369 - Test: [   50/  195]    Loss 6.825874    Top1 0.640625    Top5 2.328125    
2021-11-16 08:42:24,682 - Test: [   60/  195]    Loss 6.829774    Top1 0.598958    Top5 2.259115    
2021-11-16 08:42:42,650 - Test: [   70/  195]    Loss 6.827944    Top1 0.585938    Top5 2.254464    
2021-11-16 08:43:00,788 - Test: [   80/  195]    Loss 6.828607    Top1 0.595703    Top5 2.221680    
2021-11-16 08:43:18,972 - Test: [   90/  195]    Loss 6.828840    Top1 0.598958    Top5 2.213542    
2021-11-16 08:43:37,124 - Test: [  100/  195]    Loss 6.830538    Top1 0.613281    Top5 2.214844    
2021-11-16 08:43:55,209 - Test: [  110/  195]    Loss 6.830737    Top1 0.603693    Top5 2.176847    
2021-11-16 08:44:13,365 - Test: [  120/  195]    Loss 6.831519    Top1 0.589193    Top5 2.161458    
2021-11-16 08:44:31,799 - Test: [  130/  195]    Loss 6.832242    Top1 0.567909    Top5 2.124399    
2021-11-16 08:44:49,791 - Test: [  140/  195]    Loss 6.833295    Top1 0.569196    Top5 2.087054    
2021-11-16 08:45:07,860 - Test: [  150/  195]    Loss 6.833843    Top1 0.554687    Top5 2.078125    
2021-11-16 08:45:25,872 - Test: [  160/  195]    Loss 6.834952    Top1 0.549316    Top5 2.048340    
2021-11-16 08:45:43,914 - Test: [  170/  195]    Loss 6.835181    Top1 0.553768    Top5 2.063419    
2021-11-16 08:46:01,989 - Test: [  180/  195]    Loss 6.835394    Top1 0.557726    Top5 2.070313    
2021-11-16 08:46:19,955 - Test: [  190/  195]    Loss 6.836126    Top1 0.565378    Top5 2.076480    
2021-11-16 08:46:29,674 - ==> Top1: 0.576    Top5: 2.084    Loss: 6.836

2021-11-16 08:46:32,858 - --- test ---------------------
2021-11-16 08:46:32,858 - 50000 samples (256 per mini-batch)
2021-11-16 08:46:54,261 - Test: [   10/  195]    Loss 6.955025    Top1 0.117188    Top5 0.703125    
2021-11-16 08:47:12,314 - Test: [   20/  195]    Loss 6.951594    Top1 0.136719    Top5 0.800781    
2021-11-16 08:47:30,386 - Test: [   30/  195]    Loss 6.951524    Top1 0.117188    Top5 0.781250    
2021-11-16 08:47:48,517 - Test: [   40/  195]    Loss 6.952285    Top1 0.107422    Top5 0.810547    
2021-11-16 08:48:06,507 - Test: [   50/  195]    Loss 6.954005    Top1 0.117188    Top5 0.757812    
2021-11-16 08:48:24,522 - Test: [   60/  195]    Loss 6.955242    Top1 0.110677    Top5 0.742188    
2021-11-16 08:48:42,832 - Test: [   70/  195]    Loss 6.953731    Top1 0.128348    Top5 0.736607    
2021-11-16 08:49:01,037 - Test: [   80/  195]    Loss 6.953036    Top1 0.117188    Top5 0.727539    
2021-11-16 08:49:19,157 - Test: [   90/  195]    Loss 6.952707    Top1 0.130208    Top5 0.720486    
2021-11-16 08:49:37,340 - Test: [  100/  195]    Loss 6.952803    Top1 0.140625    Top5 0.734375    
2021-11-16 08:49:55,632 - Test: [  110/  195]    Loss 6.953327    Top1 0.138494    Top5 0.724432    
2021-11-16 08:50:13,808 - Test: [  120/  195]    Loss 6.952216    Top1 0.143229    Top5 0.735677    
2021-11-16 08:50:31,985 - Test: [  130/  195]    Loss 6.951955    Top1 0.147236    Top5 0.745192    
2021-11-16 08:50:50,088 - Test: [  140/  195]    Loss 6.951886    Top1 0.156250    Top5 0.747768    
2021-11-16 08:51:08,260 - Test: [  150/  195]    Loss 6.952599    Top1 0.156250    Top5 0.734375    
2021-11-16 08:51:26,226 - Test: [  160/  195]    Loss 6.952087    Top1 0.158691    Top5 0.754395    
2021-11-16 08:51:44,379 - Test: [  170/  195]    Loss 6.952353    Top1 0.153952    Top5 0.749081    
2021-11-16 08:52:02,578 - Test: [  180/  195]    Loss 6.951961    Top1 0.167101    Top5 0.750868    
2021-11-16 08:52:20,617 - Test: [  190/  195]    Loss 6.951774    Top1 0.166530    Top5 0.754523    
2021-11-16 08:52:30,422 - ==> Top1: 0.170    Top5: 0.754    Loss: 6.952

2021-11-16 08:52:33,907 - --- test ---------------------
2021-11-16 08:52:33,907 - 50000 samples (256 per mini-batch)
2021-11-16 08:52:55,037 - Test: [   10/  195]    Loss 6.958845    Top1 0.117188    Top5 0.585938    
2021-11-16 08:53:12,972 - Test: [   20/  195]    Loss 6.960129    Top1 0.136719    Top5 0.625000    
2021-11-16 08:53:31,442 - Test: [   30/  195]    Loss 6.960306    Top1 0.169271    Top5 0.611979    
2021-11-16 08:53:49,921 - Test: [   40/  195]    Loss 6.960461    Top1 0.146484    Top5 0.546875    
2021-11-16 08:54:08,156 - Test: [   50/  195]    Loss 6.961951    Top1 0.140625    Top5 0.531250    
2021-11-16 08:54:26,376 - Test: [   60/  195]    Loss 6.961996    Top1 0.143229    Top5 0.572917    
2021-11-16 08:54:44,513 - Test: [   70/  195]    Loss 6.960657    Top1 0.167411    Top5 0.585938    
2021-11-16 08:55:02,868 - Test: [   80/  195]    Loss 6.960099    Top1 0.175781    Top5 0.605469    
2021-11-16 08:55:20,976 - Test: [   90/  195]    Loss 6.961063    Top1 0.169271    Top5 0.611979    
2021-11-16 08:55:39,265 - Test: [  100/  195]    Loss 6.959667    Top1 0.171875    Top5 0.636719    
2021-11-16 08:55:57,413 - Test: [  110/  195]    Loss 6.959792    Top1 0.166903    Top5 0.625000    
2021-11-16 08:56:15,663 - Test: [  120/  195]    Loss 6.959065    Top1 0.166016    Top5 0.625000    
2021-11-16 08:56:33,904 - Test: [  130/  195]    Loss 6.960005    Top1 0.156250    Top5 0.612981    
2021-11-16 08:56:52,001 - Test: [  140/  195]    Loss 6.960514    Top1 0.153460    Top5 0.602679    
2021-11-16 08:57:10,230 - Test: [  150/  195]    Loss 6.960326    Top1 0.151042    Top5 0.593750    
2021-11-16 08:57:28,317 - Test: [  160/  195]    Loss 6.959715    Top1 0.151367    Top5 0.603027    
2021-11-16 08:57:46,354 - Test: [  170/  195]    Loss 6.959053    Top1 0.149357    Top5 0.611213    
2021-11-16 08:58:04,513 - Test: [  180/  195]    Loss 6.959061    Top1 0.149740    Top5 0.605469    
2021-11-16 08:58:22,690 - Test: [  190/  195]    Loss 6.959032    Top1 0.145970    Top5 0.608553    
2021-11-16 08:58:32,747 - ==> Top1: 0.146    Top5: 0.610    Loss: 6.958

2021-11-16 08:58:36,639 - --- test ---------------------
2021-11-16 08:58:36,640 - 50000 samples (256 per mini-batch)
2021-11-16 08:58:58,836 - Test: [   10/  195]    Loss 6.943470    Top1 0.195312    Top5 0.781250    
2021-11-16 08:59:16,836 - Test: [   20/  195]    Loss 6.952645    Top1 0.175781    Top5 0.703125    
2021-11-16 08:59:35,029 - Test: [   30/  195]    Loss 6.953921    Top1 0.156250    Top5 0.716146    
2021-11-16 08:59:53,315 - Test: [   40/  195]    Loss 6.954892    Top1 0.136719    Top5 0.693359    
2021-11-16 09:00:11,647 - Test: [   50/  195]    Loss 6.955881    Top1 0.132813    Top5 0.718750    
2021-11-16 09:00:29,809 - Test: [   60/  195]    Loss 6.956274    Top1 0.123698    Top5 0.729167    
2021-11-16 09:00:48,043 - Test: [   70/  195]    Loss 6.956369    Top1 0.122768    Top5 0.714286    
2021-11-16 09:01:06,076 - Test: [   80/  195]    Loss 6.955296    Top1 0.122070    Top5 0.712891    
2021-11-16 09:01:24,313 - Test: [   90/  195]    Loss 6.955572    Top1 0.112847    Top5 0.694444    
2021-11-16 09:01:42,448 - Test: [  100/  195]    Loss 6.956081    Top1 0.105469    Top5 0.707031    
2021-11-16 09:02:00,576 - Test: [  110/  195]    Loss 6.956812    Top1 0.113636    Top5 0.699574    
2021-11-16 09:02:18,777 - Test: [  120/  195]    Loss 6.955859    Top1 0.120443    Top5 0.690104    
2021-11-16 09:02:36,978 - Test: [  130/  195]    Loss 6.955762    Top1 0.126202    Top5 0.694111    
2021-11-16 09:02:55,052 - Test: [  140/  195]    Loss 6.956044    Top1 0.125558    Top5 0.708705    
2021-11-16 09:03:13,218 - Test: [  150/  195]    Loss 6.955923    Top1 0.125000    Top5 0.690104    
2021-11-16 09:03:31,590 - Test: [  160/  195]    Loss 6.956315    Top1 0.131836    Top5 0.695801    
2021-11-16 09:03:49,705 - Test: [  170/  195]    Loss 6.957394    Top1 0.135570    Top5 0.684743    
2021-11-16 09:04:07,728 - Test: [  180/  195]    Loss 6.957806    Top1 0.141059    Top5 0.692274    
2021-11-16 09:04:25,864 - Test: [  190/  195]    Loss 6.958171    Top1 0.143914    Top5 0.707237    
2021-11-16 09:04:35,744 - ==> Top1: 0.148    Top5: 0.714    Loss: 6.959

2021-11-16 09:04:39,077 - --- test ---------------------
2021-11-16 09:04:39,077 - 50000 samples (256 per mini-batch)
2021-11-16 09:05:00,906 - Test: [   10/  195]    Loss 6.905347    Top1 0.156250    Top5 0.781250    
2021-11-16 09:05:19,009 - Test: [   20/  195]    Loss 6.912586    Top1 0.117188    Top5 0.664062    
2021-11-16 09:05:37,368 - Test: [   30/  195]    Loss 6.912178    Top1 0.156250    Top5 0.729167    
2021-11-16 09:05:55,490 - Test: [   40/  195]    Loss 6.915149    Top1 0.136719    Top5 0.771484    
2021-11-16 09:06:13,646 - Test: [   50/  195]    Loss 6.914713    Top1 0.148437    Top5 0.796875    
2021-11-16 09:06:31,706 - Test: [   60/  195]    Loss 6.913527    Top1 0.143229    Top5 0.833333    
2021-11-16 09:06:49,964 - Test: [   70/  195]    Loss 6.912948    Top1 0.150670    Top5 0.848214    
2021-11-16 09:07:08,365 - Test: [   80/  195]    Loss 6.913593    Top1 0.156250    Top5 0.854492    
2021-11-16 09:07:26,497 - Test: [   90/  195]    Loss 6.913614    Top1 0.160590    Top5 0.824653    
2021-11-16 09:07:44,591 - Test: [  100/  195]    Loss 6.914621    Top1 0.152344    Top5 0.816406    
2021-11-16 09:08:02,930 - Test: [  110/  195]    Loss 6.915468    Top1 0.145597    Top5 0.806108    
2021-11-16 09:08:21,188 - Test: [  120/  195]    Loss 6.915181    Top1 0.139974    Top5 0.787760    
2021-11-16 09:08:39,388 - Test: [  130/  195]    Loss 6.914919    Top1 0.129207    Top5 0.787260    
2021-11-16 09:08:57,499 - Test: [  140/  195]    Loss 6.914408    Top1 0.131138    Top5 0.770089    
2021-11-16 09:09:15,552 - Test: [  150/  195]    Loss 6.913623    Top1 0.138021    Top5 0.786458    
2021-11-16 09:09:33,662 - Test: [  160/  195]    Loss 6.913406    Top1 0.139160    Top5 0.783691    
2021-11-16 09:09:51,885 - Test: [  170/  195]    Loss 6.913450    Top1 0.144761    Top5 0.781250    
2021-11-16 09:10:10,142 - Test: [  180/  195]    Loss 6.913507    Top1 0.143229    Top5 0.776910    
2021-11-16 09:10:28,393 - Test: [  190/  195]    Loss 6.913285    Top1 0.143914    Top5 0.768914    
2021-11-16 09:10:38,341 - ==> Top1: 0.146    Top5: 0.764    Loss: 6.914

2021-11-16 09:10:42,038 - --- test ---------------------
2021-11-16 09:10:42,039 - 50000 samples (256 per mini-batch)
2021-11-16 09:11:04,205 - Test: [   10/  195]    Loss 6.998407    Top1 0.078125    Top5 0.351563    
2021-11-16 09:11:22,424 - Test: [   20/  195]    Loss 6.993641    Top1 0.156250    Top5 0.429687    
2021-11-16 09:11:40,597 - Test: [   30/  195]    Loss 7.001897    Top1 0.117188    Top5 0.442708    
2021-11-16 09:11:58,817 - Test: [   40/  195]    Loss 7.002306    Top1 0.126953    Top5 0.458984    
2021-11-16 09:12:17,072 - Test: [   50/  195]    Loss 7.002522    Top1 0.125000    Top5 0.476562    
2021-11-16 09:12:35,387 - Test: [   60/  195]    Loss 7.004321    Top1 0.110677    Top5 0.468750    
2021-11-16 09:12:53,820 - Test: [   70/  195]    Loss 7.004355    Top1 0.106027    Top5 0.485491    
2021-11-16 09:13:12,213 - Test: [   80/  195]    Loss 7.004617    Top1 0.097656    Top5 0.488281    
2021-11-16 09:13:30,321 - Test: [   90/  195]    Loss 7.004956    Top1 0.091146    Top5 0.516493    
2021-11-16 09:13:48,589 - Test: [  100/  195]    Loss 7.004192    Top1 0.105469    Top5 0.546875    
2021-11-16 09:14:07,028 - Test: [  110/  195]    Loss 7.004639    Top1 0.102983    Top5 0.546875    
2021-11-16 09:14:25,222 - Test: [  120/  195]    Loss 7.005308    Top1 0.094401    Top5 0.537109    
2021-11-16 09:14:43,589 - Test: [  130/  195]    Loss 7.005773    Top1 0.096154    Top5 0.531851    
2021-11-16 09:15:01,764 - Test: [  140/  195]    Loss 7.005198    Top1 0.103237    Top5 0.541295    
2021-11-16 09:15:19,957 - Test: [  150/  195]    Loss 7.005265    Top1 0.111979    Top5 0.546875    
2021-11-16 09:15:38,074 - Test: [  160/  195]    Loss 7.004976    Top1 0.114746    Top5 0.546875    
2021-11-16 09:15:56,181 - Test: [  170/  195]    Loss 7.005230    Top1 0.117188    Top5 0.549173    
2021-11-16 09:16:14,421 - Test: [  180/  195]    Loss 7.005020    Top1 0.115017    Top5 0.546875    
2021-11-16 09:16:32,781 - Test: [  190/  195]    Loss 7.005221    Top1 0.108964    Top5 0.548931    
2021-11-16 09:16:42,700 - ==> Top1: 0.108    Top5: 0.552    Loss: 7.005

2021-11-16 09:16:46,244 - --- test ---------------------
2021-11-16 09:16:46,244 - 50000 samples (256 per mini-batch)
2021-11-16 09:17:07,750 - Test: [   10/  195]    Loss 6.909331    Top1 0.078125    Top5 0.820312    
2021-11-16 09:17:25,869 - Test: [   20/  195]    Loss 6.904023    Top1 0.117188    Top5 0.898438    
2021-11-16 09:17:44,025 - Test: [   30/  195]    Loss 6.905838    Top1 0.143229    Top5 0.859375    
2021-11-16 09:18:02,332 - Test: [   40/  195]    Loss 6.904351    Top1 0.146484    Top5 0.820312    
2021-11-16 09:18:20,534 - Test: [   50/  195]    Loss 6.903351    Top1 0.156250    Top5 0.835937    
2021-11-16 09:18:38,711 - Test: [   60/  195]    Loss 6.903652    Top1 0.156250    Top5 0.872396    
2021-11-16 09:18:57,068 - Test: [   70/  195]    Loss 6.904936    Top1 0.167411    Top5 0.848214    
2021-11-16 09:19:15,342 - Test: [   80/  195]    Loss 6.904260    Top1 0.170898    Top5 0.898438    
2021-11-16 09:19:33,743 - Test: [   90/  195]    Loss 6.905140    Top1 0.164931    Top5 0.894097    
2021-11-16 09:19:52,193 - Test: [  100/  195]    Loss 6.903811    Top1 0.160156    Top5 0.867187    
2021-11-16 09:20:10,537 - Test: [  110/  195]    Loss 6.904674    Top1 0.152699    Top5 0.852273    
2021-11-16 09:20:28,852 - Test: [  120/  195]    Loss 6.903618    Top1 0.159505    Top5 0.839844    
2021-11-16 09:20:47,185 - Test: [  130/  195]    Loss 6.902795    Top1 0.168269    Top5 0.835337    
2021-11-16 09:21:05,569 - Test: [  140/  195]    Loss 6.902603    Top1 0.178571    Top5 0.842634    
2021-11-16 09:21:23,917 - Test: [  150/  195]    Loss 6.902873    Top1 0.171875    Top5 0.841146    
2021-11-16 09:21:42,241 - Test: [  160/  195]    Loss 6.903352    Top1 0.168457    Top5 0.822754    
2021-11-16 09:22:00,337 - Test: [  170/  195]    Loss 6.903037    Top1 0.174632    Top5 0.834099    
2021-11-16 09:22:18,572 - Test: [  180/  195]    Loss 6.903217    Top1 0.175781    Top5 0.822483    
2021-11-16 09:22:37,016 - Test: [  190/  195]    Loss 6.903210    Top1 0.170641    Top5 0.814145    
2021-11-16 09:22:46,962 - ==> Top1: 0.168    Top5: 0.808    Loss: 6.903

2021-11-16 09:22:50,974 - --- test ---------------------
2021-11-16 09:22:50,974 - 50000 samples (256 per mini-batch)
2021-11-16 09:23:12,329 - Test: [   10/  195]    Loss 6.955254    Top1 0.117188    Top5 0.664062    
2021-11-16 09:23:30,705 - Test: [   20/  195]    Loss 6.957499    Top1 0.136719    Top5 0.683594    
2021-11-16 09:23:49,081 - Test: [   30/  195]    Loss 6.959382    Top1 0.169271    Top5 0.664062    
2021-11-16 09:24:07,481 - Test: [   40/  195]    Loss 6.961438    Top1 0.166016    Top5 0.664062    
2021-11-16 09:24:25,769 - Test: [   50/  195]    Loss 6.957905    Top1 0.171875    Top5 0.695313    
2021-11-16 09:24:44,268 - Test: [   60/  195]    Loss 6.959365    Top1 0.214844    Top5 0.703125    
2021-11-16 09:25:02,704 - Test: [   70/  195]    Loss 6.958370    Top1 0.217634    Top5 0.691964    
2021-11-16 09:25:21,113 - Test: [   80/  195]    Loss 6.957382    Top1 0.200195    Top5 0.678711    
2021-11-16 09:25:39,472 - Test: [   90/  195]    Loss 6.958386    Top1 0.199653    Top5 0.690104    
2021-11-16 09:25:57,889 - Test: [  100/  195]    Loss 6.959369    Top1 0.199219    Top5 0.675781    
2021-11-16 09:26:16,198 - Test: [  110/  195]    Loss 6.959749    Top1 0.188210    Top5 0.660511    
2021-11-16 09:26:34,569 - Test: [  120/  195]    Loss 6.959849    Top1 0.185547    Top5 0.677083    
2021-11-16 09:26:53,093 - Test: [  130/  195]    Loss 6.959245    Top1 0.177284    Top5 0.685096    
2021-11-16 09:27:11,532 - Test: [  140/  195]    Loss 6.958919    Top1 0.184152    Top5 0.680804    
2021-11-16 09:27:29,745 - Test: [  150/  195]    Loss 6.958190    Top1 0.179688    Top5 0.682292    
2021-11-16 09:27:47,920 - Test: [  160/  195]    Loss 6.958526    Top1 0.185547    Top5 0.678711    
2021-11-16 09:28:06,132 - Test: [  170/  195]    Loss 6.957789    Top1 0.190717    Top5 0.687040    
2021-11-16 09:28:24,289 - Test: [  180/  195]    Loss 6.957213    Top1 0.199653    Top5 0.692274    
2021-11-16 09:28:42,674 - Test: [  190/  195]    Loss 6.957240    Top1 0.203536    Top5 0.694901    
2021-11-16 09:28:52,702 - ==> Top1: 0.200    Top5: 0.700    Loss: 6.958

2021-11-16 09:28:56,748 - --- test ---------------------
2021-11-16 09:28:56,748 - 50000 samples (256 per mini-batch)
2021-11-16 09:29:18,569 - Test: [   10/  195]    Loss 6.994320    Top1 0.039062    Top5 0.468750    
2021-11-16 09:29:36,876 - Test: [   20/  195]    Loss 6.999991    Top1 0.078125    Top5 0.527344    
2021-11-16 09:29:55,260 - Test: [   30/  195]    Loss 6.998831    Top1 0.065104    Top5 0.585938    
2021-11-16 09:30:13,583 - Test: [   40/  195]    Loss 6.997799    Top1 0.087891    Top5 0.625000    
2021-11-16 09:30:32,024 - Test: [   50/  195]    Loss 6.997791    Top1 0.093750    Top5 0.648437    
2021-11-16 09:30:50,464 - Test: [   60/  195]    Loss 6.995195    Top1 0.091146    Top5 0.611979    
2021-11-16 09:31:08,716 - Test: [   70/  195]    Loss 6.994554    Top1 0.083705    Top5 0.574777    
2021-11-16 09:31:26,988 - Test: [   80/  195]    Loss 6.993581    Top1 0.087891    Top5 0.590820    
2021-11-16 09:31:45,246 - Test: [   90/  195]    Loss 6.994570    Top1 0.091146    Top5 0.577257    
2021-11-16 09:32:03,576 - Test: [  100/  195]    Loss 6.994535    Top1 0.085937    Top5 0.593750    
2021-11-16 09:32:21,892 - Test: [  110/  195]    Loss 6.995763    Top1 0.095881    Top5 0.596591    
2021-11-16 09:32:40,253 - Test: [  120/  195]    Loss 6.995673    Top1 0.094401    Top5 0.582682    
2021-11-16 09:32:58,543 - Test: [  130/  195]    Loss 6.996395    Top1 0.093149    Top5 0.567909    
2021-11-16 09:33:16,812 - Test: [  140/  195]    Loss 6.995516    Top1 0.094866    Top5 0.569196    
2021-11-16 09:33:35,232 - Test: [  150/  195]    Loss 6.994948    Top1 0.101562    Top5 0.580729    
2021-11-16 09:33:53,368 - Test: [  160/  195]    Loss 6.994367    Top1 0.107422    Top5 0.573730    
2021-11-16 09:34:11,487 - Test: [  170/  195]    Loss 6.994518    Top1 0.110294    Top5 0.581342    
2021-11-16 09:34:29,861 - Test: [  180/  195]    Loss 6.994309    Top1 0.108507    Top5 0.570747    
2021-11-16 09:34:48,060 - Test: [  190/  195]    Loss 6.994667    Top1 0.108964    Top5 0.567434    
2021-11-16 09:34:58,096 - ==> Top1: 0.112    Top5: 0.580    Loss: 6.995

2021-11-16 09:35:01,371 - --- test ---------------------
2021-11-16 09:35:01,371 - 50000 samples (256 per mini-batch)
2021-11-16 09:35:23,325 - Test: [   10/  195]    Loss 7.037482    Top1 0.078125    Top5 0.742188    
2021-11-16 09:35:41,498 - Test: [   20/  195]    Loss 7.043806    Top1 0.117188    Top5 0.625000    
2021-11-16 09:35:59,696 - Test: [   30/  195]    Loss 7.039507    Top1 0.169271    Top5 0.677083    
2021-11-16 09:36:18,074 - Test: [   40/  195]    Loss 7.036989    Top1 0.136719    Top5 0.693359    
2021-11-16 09:36:36,483 - Test: [   50/  195]    Loss 7.036496    Top1 0.164062    Top5 0.671875    
2021-11-16 09:36:54,737 - Test: [   60/  195]    Loss 7.035555    Top1 0.195312    Top5 0.696615    
2021-11-16 09:37:13,161 - Test: [   70/  195]    Loss 7.037212    Top1 0.184152    Top5 0.669643    
2021-11-16 09:37:31,456 - Test: [   80/  195]    Loss 7.038356    Top1 0.175781    Top5 0.629883    
2021-11-16 09:37:49,660 - Test: [   90/  195]    Loss 7.038786    Top1 0.173611    Top5 0.642361    
2021-11-16 09:38:07,809 - Test: [  100/  195]    Loss 7.038605    Top1 0.183594    Top5 0.671875    
2021-11-16 09:38:26,128 - Test: [  110/  195]    Loss 7.038316    Top1 0.191761    Top5 0.656960    
2021-11-16 09:38:44,355 - Test: [  120/  195]    Loss 7.038418    Top1 0.188802    Top5 0.654297    
2021-11-16 09:39:02,533 - Test: [  130/  195]    Loss 7.038015    Top1 0.186298    Top5 0.655048    
2021-11-16 09:39:20,864 - Test: [  140/  195]    Loss 7.037199    Top1 0.178571    Top5 0.666853    
2021-11-16 09:39:39,092 - Test: [  150/  195]    Loss 7.036205    Top1 0.171875    Top5 0.664062    
2021-11-16 09:39:57,344 - Test: [  160/  195]    Loss 7.035477    Top1 0.170898    Top5 0.656738    
2021-11-16 09:40:15,560 - Test: [  170/  195]    Loss 7.035446    Top1 0.170037    Top5 0.643382    
2021-11-16 09:40:33,635 - Test: [  180/  195]    Loss 7.035344    Top1 0.167101    Top5 0.635851    
2021-11-16 09:40:51,779 - Test: [  190/  195]    Loss 7.035529    Top1 0.164474    Top5 0.635280    
2021-11-16 09:41:01,625 - ==> Top1: 0.168    Top5: 0.650    Loss: 7.034

2021-11-16 09:41:05,081 - --- test ---------------------
2021-11-16 09:41:05,082 - 50000 samples (256 per mini-batch)
2021-11-16 09:41:26,942 - Test: [   10/  195]    Loss 7.042387    Top1 0.078125    Top5 0.585938    
2021-11-16 09:41:45,204 - Test: [   20/  195]    Loss 7.042604    Top1 0.097656    Top5 0.742188    
2021-11-16 09:42:03,461 - Test: [   30/  195]    Loss 7.039603    Top1 0.130208    Top5 0.729167    
2021-11-16 09:42:21,726 - Test: [   40/  195]    Loss 7.040539    Top1 0.107422    Top5 0.673828    
2021-11-16 09:42:40,092 - Test: [   50/  195]    Loss 7.042778    Top1 0.093750    Top5 0.648437    
2021-11-16 09:42:58,272 - Test: [   60/  195]    Loss 7.046506    Top1 0.091146    Top5 0.638021    
2021-11-16 09:43:16,450 - Test: [   70/  195]    Loss 7.046862    Top1 0.089286    Top5 0.608259    
2021-11-16 09:43:34,697 - Test: [   80/  195]    Loss 7.048919    Top1 0.083008    Top5 0.590820    
2021-11-16 09:43:52,991 - Test: [   90/  195]    Loss 7.048488    Top1 0.086806    Top5 0.616319    
2021-11-16 09:44:11,236 - Test: [  100/  195]    Loss 7.051352    Top1 0.082031    Top5 0.589844    
2021-11-16 09:44:29,482 - Test: [  110/  195]    Loss 7.053158    Top1 0.088778    Top5 0.575284    
2021-11-16 09:44:47,679 - Test: [  120/  195]    Loss 7.053433    Top1 0.104167    Top5 0.582682    
2021-11-16 09:45:05,840 - Test: [  130/  195]    Loss 7.053415    Top1 0.105168    Top5 0.582933    
2021-11-16 09:45:24,107 - Test: [  140/  195]    Loss 7.054103    Top1 0.103237    Top5 0.569196    
2021-11-16 09:45:42,331 - Test: [  150/  195]    Loss 7.053974    Top1 0.106771    Top5 0.575521    
2021-11-16 09:46:00,527 - Test: [  160/  195]    Loss 7.054078    Top1 0.112305    Top5 0.581055    
2021-11-16 09:46:18,689 - Test: [  170/  195]    Loss 7.053041    Top1 0.114890    Top5 0.590533    
2021-11-16 09:46:36,944 - Test: [  180/  195]    Loss 7.053216    Top1 0.117188    Top5 0.588108    
2021-11-16 09:46:55,156 - Test: [  190/  195]    Loss 7.053155    Top1 0.115132    Top5 0.625000    
2021-11-16 09:47:05,056 - ==> Top1: 0.114    Top5: 0.622    Loss: 7.053

2021-11-16 09:47:08,268 - --- test ---------------------
2021-11-16 09:47:08,269 - 50000 samples (256 per mini-batch)
2021-11-16 09:47:29,027 - Test: [   10/  195]    Loss 6.952296    Top1 0.117188    Top5 0.937500    
2021-11-16 09:47:47,212 - Test: [   20/  195]    Loss 6.965823    Top1 0.117188    Top5 0.722656    
2021-11-16 09:48:05,380 - Test: [   30/  195]    Loss 6.964822    Top1 0.156250    Top5 0.768229    
2021-11-16 09:48:23,639 - Test: [   40/  195]    Loss 6.965121    Top1 0.166016    Top5 0.810547    
2021-11-16 09:48:42,000 - Test: [   50/  195]    Loss 6.965491    Top1 0.171875    Top5 0.835937    
2021-11-16 09:49:00,180 - Test: [   60/  195]    Loss 6.967137    Top1 0.162760    Top5 0.807292    
2021-11-16 09:49:18,560 - Test: [   70/  195]    Loss 6.968277    Top1 0.156250    Top5 0.753348    
2021-11-16 09:49:36,830 - Test: [   80/  195]    Loss 6.968926    Top1 0.151367    Top5 0.766602    
2021-11-16 09:49:55,052 - Test: [   90/  195]    Loss 6.968879    Top1 0.147569    Top5 0.794271    
2021-11-16 09:50:13,524 - Test: [  100/  195]    Loss 6.967535    Top1 0.148437    Top5 0.800781    
2021-11-16 09:50:31,839 - Test: [  110/  195]    Loss 6.966216    Top1 0.156250    Top5 0.813210    
2021-11-16 09:50:50,096 - Test: [  120/  195]    Loss 6.965997    Top1 0.162760    Top5 0.813802    
2021-11-16 09:51:08,276 - Test: [  130/  195]    Loss 6.965242    Top1 0.186298    Top5 0.838341    
2021-11-16 09:51:26,559 - Test: [  140/  195]    Loss 6.965482    Top1 0.181362    Top5 0.820312    
2021-11-16 09:51:44,963 - Test: [  150/  195]    Loss 6.964106    Top1 0.177083    Top5 0.841146    
2021-11-16 09:52:03,167 - Test: [  160/  195]    Loss 6.963768    Top1 0.175781    Top5 0.844727    
2021-11-16 09:52:21,246 - Test: [  170/  195]    Loss 6.963410    Top1 0.170037    Top5 0.863971    
2021-11-16 09:52:39,496 - Test: [  180/  195]    Loss 6.963157    Top1 0.171441    Top5 0.861545    
2021-11-16 09:52:57,669 - Test: [  190/  195]    Loss 6.964250    Top1 0.164474    Top5 0.849095    
2021-11-16 09:53:07,630 - ==> Top1: 0.164    Top5: 0.844    Loss: 6.964

2021-11-16 09:53:10,946 - --- test ---------------------
2021-11-16 09:53:10,946 - 50000 samples (256 per mini-batch)
2021-11-16 09:53:33,037 - Test: [   10/  195]    Loss 7.124890    Top1 0.156250    Top5 0.781250    
2021-11-16 09:53:51,347 - Test: [   20/  195]    Loss 7.127599    Top1 0.136719    Top5 0.605469    
2021-11-16 09:54:09,603 - Test: [   30/  195]    Loss 7.128696    Top1 0.156250    Top5 0.520833    
2021-11-16 09:54:27,992 - Test: [   40/  195]    Loss 7.123957    Top1 0.195312    Top5 0.615234    
2021-11-16 09:54:46,219 - Test: [   50/  195]    Loss 7.123782    Top1 0.164062    Top5 0.617188    
2021-11-16 09:55:04,531 - Test: [   60/  195]    Loss 7.124874    Top1 0.169271    Top5 0.605469    
2021-11-16 09:55:22,945 - Test: [   70/  195]    Loss 7.126410    Top1 0.156250    Top5 0.563616    
2021-11-16 09:55:41,273 - Test: [   80/  195]    Loss 7.123532    Top1 0.151367    Top5 0.576172    
2021-11-16 09:55:59,604 - Test: [   90/  195]    Loss 7.123115    Top1 0.143229    Top5 0.568576    
2021-11-16 09:56:18,101 - Test: [  100/  195]    Loss 7.120809    Top1 0.140625    Top5 0.589844    
2021-11-16 09:56:36,563 - Test: [  110/  195]    Loss 7.120409    Top1 0.131392    Top5 0.578835    
2021-11-16 09:56:54,975 - Test: [  120/  195]    Loss 7.121185    Top1 0.126953    Top5 0.559896    
2021-11-16 09:57:13,158 - Test: [  130/  195]    Loss 7.121657    Top1 0.126202    Top5 0.558894    
2021-11-16 09:57:31,448 - Test: [  140/  195]    Loss 7.120618    Top1 0.131138    Top5 0.577567    
2021-11-16 09:57:49,864 - Test: [  150/  195]    Loss 7.122235    Top1 0.130208    Top5 0.567708    
2021-11-16 09:58:08,336 - Test: [  160/  195]    Loss 7.122494    Top1 0.131836    Top5 0.566406    
2021-11-16 09:58:26,545 - Test: [  170/  195]    Loss 7.122048    Top1 0.140165    Top5 0.567555    
2021-11-16 09:58:44,756 - Test: [  180/  195]    Loss 7.121863    Top1 0.138889    Top5 0.568576    
2021-11-16 09:59:02,887 - Test: [  190/  195]    Loss 7.121654    Top1 0.141859    Top5 0.571546    
2021-11-16 09:59:12,800 - ==> Top1: 0.140    Top5: 0.566    Loss: 7.122

2021-11-16 09:59:16,253 - --- test ---------------------
2021-11-16 09:59:16,253 - 50000 samples (256 per mini-batch)
2021-11-16 09:59:37,499 - Test: [   10/  195]    Loss 6.909660    Top1 0.312500    Top5 1.054687    
2021-11-16 09:59:55,644 - Test: [   20/  195]    Loss 6.911074    Top1 0.253906    Top5 0.859375    
2021-11-16 10:00:14,009 - Test: [   30/  195]    Loss 6.909869    Top1 0.247396    Top5 0.833333    
2021-11-16 10:00:32,396 - Test: [   40/  195]    Loss 6.910464    Top1 0.253906    Top5 0.820312    
2021-11-16 10:00:50,687 - Test: [   50/  195]    Loss 6.909223    Top1 0.257812    Top5 0.796875    
2021-11-16 10:01:09,169 - Test: [   60/  195]    Loss 6.909624    Top1 0.253906    Top5 0.820312    
2021-11-16 10:01:27,537 - Test: [   70/  195]    Loss 6.910749    Top1 0.239955    Top5 0.809152    
2021-11-16 10:01:45,865 - Test: [   80/  195]    Loss 6.909653    Top1 0.244141    Top5 0.815430    
2021-11-16 10:02:04,152 - Test: [   90/  195]    Loss 6.909994    Top1 0.256076    Top5 0.789931    
2021-11-16 10:02:22,477 - Test: [  100/  195]    Loss 6.909473    Top1 0.265625    Top5 0.781250    
2021-11-16 10:02:40,884 - Test: [  110/  195]    Loss 6.910671    Top1 0.245028    Top5 0.777699    
2021-11-16 10:02:59,364 - Test: [  120/  195]    Loss 6.911229    Top1 0.240885    Top5 0.784505    
2021-11-16 10:03:17,580 - Test: [  130/  195]    Loss 6.911921    Top1 0.240385    Top5 0.784255    
2021-11-16 10:03:35,803 - Test: [  140/  195]    Loss 6.911879    Top1 0.239955    Top5 0.797991    
2021-11-16 10:03:54,088 - Test: [  150/  195]    Loss 6.911774    Top1 0.234375    Top5 0.804688    
2021-11-16 10:04:12,297 - Test: [  160/  195]    Loss 6.912495    Top1 0.236816    Top5 0.810547    
2021-11-16 10:04:30,609 - Test: [  170/  195]    Loss 6.913113    Top1 0.241268    Top5 0.827206    
2021-11-16 10:04:48,828 - Test: [  180/  195]    Loss 6.913256    Top1 0.236545    Top5 0.811632    
2021-11-16 10:05:06,981 - Test: [  190/  195]    Loss 6.913015    Top1 0.236431    Top5 0.824424    
2021-11-16 10:05:16,953 - ==> Top1: 0.234    Top5: 0.826    Loss: 6.913

2021-11-16 10:05:20,791 - --- test ---------------------
2021-11-16 10:05:20,792 - 50000 samples (256 per mini-batch)
2021-11-16 10:05:43,086 - Test: [   10/  195]    Loss 6.928645    Top1 0.273437    Top5 0.781250    
2021-11-16 10:06:01,265 - Test: [   20/  195]    Loss 6.934212    Top1 0.195312    Top5 0.664062    
2021-11-16 10:06:19,497 - Test: [   30/  195]    Loss 6.937098    Top1 0.182292    Top5 0.625000    
2021-11-16 10:06:37,843 - Test: [   40/  195]    Loss 6.935921    Top1 0.136719    Top5 0.585938    
2021-11-16 10:06:56,223 - Test: [   50/  195]    Loss 6.932416    Top1 0.148437    Top5 0.632813    
2021-11-16 10:07:14,577 - Test: [   60/  195]    Loss 6.931389    Top1 0.149740    Top5 0.618490    
2021-11-16 10:07:32,865 - Test: [   70/  195]    Loss 6.931349    Top1 0.133929    Top5 0.602679    
2021-11-16 10:07:51,110 - Test: [   80/  195]    Loss 6.932301    Top1 0.117188    Top5 0.571289    
2021-11-16 10:08:09,698 - Test: [   90/  195]    Loss 6.933131    Top1 0.125868    Top5 0.577257    
2021-11-16 10:08:28,000 - Test: [  100/  195]    Loss 6.933516    Top1 0.117188    Top5 0.562500    
2021-11-16 10:08:46,463 - Test: [  110/  195]    Loss 6.933573    Top1 0.110085    Top5 0.557528    
2021-11-16 10:09:04,932 - Test: [  120/  195]    Loss 6.933587    Top1 0.110677    Top5 0.559896    
2021-11-16 10:09:23,415 - Test: [  130/  195]    Loss 6.933635    Top1 0.114183    Top5 0.564904    
2021-11-16 10:09:41,667 - Test: [  140/  195]    Loss 6.933804    Top1 0.111607    Top5 0.560826    
2021-11-16 10:09:59,921 - Test: [  150/  195]    Loss 6.933922    Top1 0.109375    Top5 0.546875    
2021-11-16 10:10:18,360 - Test: [  160/  195]    Loss 6.934019    Top1 0.107422    Top5 0.551758    
2021-11-16 10:10:36,542 - Test: [  170/  195]    Loss 6.933585    Top1 0.112592    Top5 0.562960    
2021-11-16 10:10:54,799 - Test: [  180/  195]    Loss 6.933404    Top1 0.110677    Top5 0.564236    
2021-11-16 10:11:13,129 - Test: [  190/  195]    Loss 6.933406    Top1 0.113076    Top5 0.557155    
2021-11-16 10:11:23,135 - ==> Top1: 0.110    Top5: 0.552    Loss: 6.933

2021-11-16 10:11:27,119 - --- test ---------------------
2021-11-16 10:11:27,120 - 50000 samples (256 per mini-batch)
2021-11-16 10:11:49,702 - Test: [   10/  195]    Loss 6.949524    Top1 0.117188    Top5 0.781250    
2021-11-16 10:12:07,981 - Test: [   20/  195]    Loss 6.945782    Top1 0.136719    Top5 0.898438    
2021-11-16 10:12:26,258 - Test: [   30/  195]    Loss 6.943731    Top1 0.169271    Top5 0.911458    
2021-11-16 10:12:44,588 - Test: [   40/  195]    Loss 6.946626    Top1 0.146484    Top5 0.830078    
2021-11-16 10:13:02,899 - Test: [   50/  195]    Loss 6.944339    Top1 0.156250    Top5 0.867187    
2021-11-16 10:13:21,300 - Test: [   60/  195]    Loss 6.946273    Top1 0.156250    Top5 0.859375    
2021-11-16 10:13:39,539 - Test: [   70/  195]    Loss 6.943700    Top1 0.150670    Top5 0.859375    
2021-11-16 10:13:58,041 - Test: [   80/  195]    Loss 6.944586    Top1 0.146484    Top5 0.820312    
2021-11-16 10:14:16,455 - Test: [   90/  195]    Loss 6.943462    Top1 0.138889    Top5 0.811632    
2021-11-16 10:14:34,777 - Test: [  100/  195]    Loss 6.942245    Top1 0.148437    Top5 0.832031    
2021-11-16 10:14:53,163 - Test: [  110/  195]    Loss 6.942685    Top1 0.170455    Top5 0.838068    
2021-11-16 10:15:11,392 - Test: [  120/  195]    Loss 6.943429    Top1 0.166016    Top5 0.833333    
2021-11-16 10:15:29,790 - Test: [  130/  195]    Loss 6.944031    Top1 0.162260    Top5 0.820312    
2021-11-16 10:15:48,191 - Test: [  140/  195]    Loss 6.943621    Top1 0.167411    Top5 0.809152    
2021-11-16 10:16:06,586 - Test: [  150/  195]    Loss 6.943167    Top1 0.161458    Top5 0.807292    
2021-11-16 10:16:25,073 - Test: [  160/  195]    Loss 6.943048    Top1 0.156250    Top5 0.817871    
2021-11-16 10:16:43,286 - Test: [  170/  195]    Loss 6.943161    Top1 0.151654    Top5 0.799632    
2021-11-16 10:17:01,509 - Test: [  180/  195]    Loss 6.942474    Top1 0.151910    Top5 0.807292    
2021-11-16 10:17:19,905 - Test: [  190/  195]    Loss 6.942002    Top1 0.145970    Top5 0.799753    
2021-11-16 10:17:30,042 - ==> Top1: 0.152    Top5: 0.792    Loss: 6.942

2021-11-16 10:17:34,006 - --- test ---------------------
2021-11-16 10:17:34,006 - 50000 samples (256 per mini-batch)
2021-11-16 10:17:55,337 - Test: [   10/  195]    Loss 6.921853    Top1 0.195312    Top5 0.664062    
2021-11-16 10:18:13,809 - Test: [   20/  195]    Loss 6.924176    Top1 0.195312    Top5 0.625000    
2021-11-16 10:18:31,956 - Test: [   30/  195]    Loss 6.927357    Top1 0.169271    Top5 0.546875    
2021-11-16 10:18:50,391 - Test: [   40/  195]    Loss 6.928280    Top1 0.136719    Top5 0.556641    
2021-11-16 10:19:08,788 - Test: [   50/  195]    Loss 6.926823    Top1 0.171875    Top5 0.593750    
2021-11-16 10:19:27,104 - Test: [   60/  195]    Loss 6.926993    Top1 0.156250    Top5 0.585938    
2021-11-16 10:19:45,532 - Test: [   70/  195]    Loss 6.927197    Top1 0.150670    Top5 0.580357    
2021-11-16 10:20:03,832 - Test: [   80/  195]    Loss 6.926371    Top1 0.151367    Top5 0.620117    
2021-11-16 10:20:22,081 - Test: [   90/  195]    Loss 6.925553    Top1 0.147569    Top5 0.594618    
2021-11-16 10:20:40,313 - Test: [  100/  195]    Loss 6.926001    Top1 0.156250    Top5 0.625000    
2021-11-16 10:20:58,494 - Test: [  110/  195]    Loss 6.925732    Top1 0.156250    Top5 0.632102    
2021-11-16 10:21:16,980 - Test: [  120/  195]    Loss 6.925995    Top1 0.175781    Top5 0.634766    
2021-11-16 10:21:35,139 - Test: [  130/  195]    Loss 6.925890    Top1 0.177284    Top5 0.649038    
2021-11-16 10:21:53,529 - Test: [  140/  195]    Loss 6.927284    Top1 0.181362    Top5 0.650112    
2021-11-16 10:22:11,714 - Test: [  150/  195]    Loss 6.926827    Top1 0.182292    Top5 0.656250    
2021-11-16 10:22:30,026 - Test: [  160/  195]    Loss 6.926784    Top1 0.192871    Top5 0.681152    
2021-11-16 10:22:48,333 - Test: [  170/  195]    Loss 6.926922    Top1 0.193015    Top5 0.684743    
2021-11-16 10:23:06,480 - Test: [  180/  195]    Loss 6.926698    Top1 0.193142    Top5 0.687934    
2021-11-16 10:23:24,680 - Test: [  190/  195]    Loss 6.926253    Top1 0.185033    Top5 0.690789    
2021-11-16 10:23:34,611 - ==> Top1: 0.180    Top5: 0.684    Loss: 6.926

2021-11-16 10:23:38,311 - --- test ---------------------
2021-11-16 10:23:38,311 - 50000 samples (256 per mini-batch)
2021-11-16 10:24:00,285 - Test: [   10/  195]    Loss 7.018332    Top1 0.273437    Top5 0.625000    
2021-11-16 10:24:18,522 - Test: [   20/  195]    Loss 7.025425    Top1 0.214844    Top5 0.800781    
2021-11-16 10:24:36,833 - Test: [   30/  195]    Loss 7.038204    Top1 0.182292    Top5 0.625000    
2021-11-16 10:24:55,294 - Test: [   40/  195]    Loss 7.040741    Top1 0.166016    Top5 0.664062    
2021-11-16 10:25:13,582 - Test: [   50/  195]    Loss 7.041272    Top1 0.140625    Top5 0.648437    
2021-11-16 10:25:32,025 - Test: [   60/  195]    Loss 7.041887    Top1 0.149740    Top5 0.625000    
2021-11-16 10:25:50,265 - Test: [   70/  195]    Loss 7.041106    Top1 0.156250    Top5 0.641741    
2021-11-16 10:26:08,581 - Test: [   80/  195]    Loss 7.039976    Top1 0.170898    Top5 0.659180    
2021-11-16 10:26:26,826 - Test: [   90/  195]    Loss 7.040969    Top1 0.169271    Top5 0.651042    
2021-11-16 10:26:45,134 - Test: [  100/  195]    Loss 7.040880    Top1 0.167969    Top5 0.667969    
2021-11-16 10:27:03,562 - Test: [  110/  195]    Loss 7.041231    Top1 0.166903    Top5 0.681818    
2021-11-16 10:27:22,018 - Test: [  120/  195]    Loss 7.041602    Top1 0.152995    Top5 0.696615    
2021-11-16 10:27:40,303 - Test: [  130/  195]    Loss 7.041102    Top1 0.162260    Top5 0.724159    
2021-11-16 10:27:58,469 - Test: [  140/  195]    Loss 7.041236    Top1 0.164621    Top5 0.728237    
2021-11-16 10:28:16,864 - Test: [  150/  195]    Loss 7.040697    Top1 0.158854    Top5 0.731771    
2021-11-16 10:28:35,024 - Test: [  160/  195]    Loss 7.041807    Top1 0.156250    Top5 0.725098    
2021-11-16 10:28:53,158 - Test: [  170/  195]    Loss 7.042704    Top1 0.149357    Top5 0.712316    
2021-11-16 10:29:11,391 - Test: [  180/  195]    Loss 7.043584    Top1 0.145399    Top5 0.705295    
2021-11-16 10:29:29,725 - Test: [  190/  195]    Loss 7.043245    Top1 0.145970    Top5 0.694901    
2021-11-16 10:29:39,770 - ==> Top1: 0.146    Top5: 0.706    Loss: 7.043

2021-11-16 10:29:43,535 - --- test ---------------------
2021-11-16 10:29:43,535 - 50000 samples (256 per mini-batch)
2021-11-16 10:30:05,648 - Test: [   10/  195]    Loss 6.946152    Top1 0.234375    Top5 1.132813    
2021-11-16 10:30:24,077 - Test: [   20/  195]    Loss 6.949665    Top1 0.234375    Top5 0.917969    
2021-11-16 10:30:42,613 - Test: [   30/  195]    Loss 6.957857    Top1 0.195312    Top5 0.833333    
2021-11-16 10:31:00,896 - Test: [   40/  195]    Loss 6.958323    Top1 0.224609    Top5 0.791016    
2021-11-16 10:31:19,308 - Test: [   50/  195]    Loss 6.957877    Top1 0.226563    Top5 0.804688    
2021-11-16 10:31:37,745 - Test: [   60/  195]    Loss 6.954371    Top1 0.240885    Top5 0.813802    
2021-11-16 10:31:56,018 - Test: [   70/  195]    Loss 6.953510    Top1 0.245536    Top5 0.820312    
2021-11-16 10:32:14,284 - Test: [   80/  195]    Loss 6.953525    Top1 0.224609    Top5 0.830078    
2021-11-16 10:32:32,721 - Test: [   90/  195]    Loss 6.953107    Top1 0.212674    Top5 0.837674    
2021-11-16 10:32:51,148 - Test: [  100/  195]    Loss 6.952484    Top1 0.214844    Top5 0.843750    
2021-11-16 10:33:09,557 - Test: [  110/  195]    Loss 6.951365    Top1 0.213068    Top5 0.820312    
2021-11-16 10:33:27,861 - Test: [  120/  195]    Loss 6.952403    Top1 0.205078    Top5 0.794271    
2021-11-16 10:33:46,120 - Test: [  130/  195]    Loss 6.951631    Top1 0.198317    Top5 0.793269    
2021-11-16 10:34:04,365 - Test: [  140/  195]    Loss 6.951435    Top1 0.195312    Top5 0.795201    
2021-11-16 10:34:22,797 - Test: [  150/  195]    Loss 6.951270    Top1 0.190104    Top5 0.776042    
2021-11-16 10:34:41,007 - Test: [  160/  195]    Loss 6.950965    Top1 0.187988    Top5 0.778809    
2021-11-16 10:34:59,336 - Test: [  170/  195]    Loss 6.951279    Top1 0.181526    Top5 0.778952    
2021-11-16 10:35:17,528 - Test: [  180/  195]    Loss 6.952079    Top1 0.182292    Top5 0.772569    
2021-11-16 10:35:35,746 - Test: [  190/  195]    Loss 6.951485    Top1 0.185033    Top5 0.777138    
2021-11-16 10:35:45,642 - ==> Top1: 0.182    Top5: 0.778    Loss: 6.952

2021-11-16 10:35:49,691 - --- test ---------------------
2021-11-16 10:35:49,692 - 50000 samples (256 per mini-batch)
2021-11-16 10:36:11,993 - Test: [   10/  195]    Loss 6.935540    Top1 0.234375    Top5 0.625000    
2021-11-16 10:36:30,080 - Test: [   20/  195]    Loss 6.940182    Top1 0.175781    Top5 0.644531    
2021-11-16 10:36:48,609 - Test: [   30/  195]    Loss 6.934352    Top1 0.182292    Top5 0.768229    
2021-11-16 10:37:06,860 - Test: [   40/  195]    Loss 6.933816    Top1 0.185547    Top5 0.830078    
2021-11-16 10:37:25,274 - Test: [   50/  195]    Loss 6.932688    Top1 0.164062    Top5 0.781250    
2021-11-16 10:37:43,488 - Test: [   60/  195]    Loss 6.930582    Top1 0.162760    Top5 0.846354    
2021-11-16 10:38:01,960 - Test: [   70/  195]    Loss 6.929735    Top1 0.172991    Top5 0.831473    
2021-11-16 10:38:20,280 - Test: [   80/  195]    Loss 6.931138    Top1 0.166016    Top5 0.795898    
2021-11-16 10:38:38,794 - Test: [   90/  195]    Loss 6.932452    Top1 0.160590    Top5 0.785590    
2021-11-16 10:38:57,177 - Test: [  100/  195]    Loss 6.932755    Top1 0.167969    Top5 0.812500    
2021-11-16 10:39:15,368 - Test: [  110/  195]    Loss 6.932429    Top1 0.159801    Top5 0.802557    
2021-11-16 10:39:33,737 - Test: [  120/  195]    Loss 6.931735    Top1 0.166016    Top5 0.843099    
2021-11-16 10:39:51,981 - Test: [  130/  195]    Loss 6.931446    Top1 0.168269    Top5 0.838341    
2021-11-16 10:40:10,312 - Test: [  140/  195]    Loss 6.930499    Top1 0.167411    Top5 0.848214    
2021-11-16 10:40:28,741 - Test: [  150/  195]    Loss 6.930964    Top1 0.171875    Top5 0.861979    
2021-11-16 10:40:47,257 - Test: [  160/  195]    Loss 6.931079    Top1 0.173340    Top5 0.856934    
2021-11-16 10:41:05,325 - Test: [  170/  195]    Loss 6.930599    Top1 0.179228    Top5 0.863971    
2021-11-16 10:41:23,578 - Test: [  180/  195]    Loss 6.930284    Top1 0.184462    Top5 0.855035    
2021-11-16 10:41:41,801 - Test: [  190/  195]    Loss 6.930189    Top1 0.182977    Top5 0.853207    
2021-11-16 10:41:51,787 - ==> Top1: 0.180    Top5: 0.848    Loss: 6.930

2021-11-16 10:41:55,317 - --- test ---------------------
2021-11-16 10:41:55,317 - 50000 samples (256 per mini-batch)
2021-11-16 10:42:17,538 - Test: [   10/  195]    Loss 7.042385    Top1 0.156250    Top5 0.468750    
2021-11-16 10:42:35,561 - Test: [   20/  195]    Loss 7.051906    Top1 0.156250    Top5 0.527344    
2021-11-16 10:42:53,856 - Test: [   30/  195]    Loss 7.050721    Top1 0.130208    Top5 0.533854    
2021-11-16 10:43:12,459 - Test: [   40/  195]    Loss 7.047766    Top1 0.136719    Top5 0.595703    
2021-11-16 10:43:30,795 - Test: [   50/  195]    Loss 7.047342    Top1 0.125000    Top5 0.578125    
2021-11-16 10:43:49,061 - Test: [   60/  195]    Loss 7.044771    Top1 0.130208    Top5 0.631510    
2021-11-16 10:44:07,465 - Test: [   70/  195]    Loss 7.042493    Top1 0.156250    Top5 0.630580    
2021-11-16 10:44:25,819 - Test: [   80/  195]    Loss 7.042048    Top1 0.141602    Top5 0.625000    
2021-11-16 10:44:44,200 - Test: [   90/  195]    Loss 7.042617    Top1 0.147569    Top5 0.638021    
2021-11-16 10:45:02,430 - Test: [  100/  195]    Loss 7.042706    Top1 0.164062    Top5 0.640625    
2021-11-16 10:45:20,724 - Test: [  110/  195]    Loss 7.042915    Top1 0.166903    Top5 0.649858    
2021-11-16 10:45:39,022 - Test: [  120/  195]    Loss 7.040205    Top1 0.169271    Top5 0.660807    
2021-11-16 10:45:57,351 - Test: [  130/  195]    Loss 7.039100    Top1 0.174279    Top5 0.655048    
2021-11-16 10:46:15,568 - Test: [  140/  195]    Loss 7.039603    Top1 0.170201    Top5 0.664062    
2021-11-16 10:46:33,999 - Test: [  150/  195]    Loss 7.039317    Top1 0.177083    Top5 0.658854    
2021-11-16 10:46:52,069 - Test: [  160/  195]    Loss 7.038505    Top1 0.183105    Top5 0.666504    
2021-11-16 10:47:10,452 - Test: [  170/  195]    Loss 7.039142    Top1 0.179228    Top5 0.654871    
2021-11-16 10:47:28,573 - Test: [  180/  195]    Loss 7.040464    Top1 0.177951    Top5 0.655382    
2021-11-16 10:47:46,844 - Test: [  190/  195]    Loss 7.041023    Top1 0.172697    Top5 0.662007    
2021-11-16 10:47:56,763 - ==> Top1: 0.168    Top5: 0.658    Loss: 7.041

2021-11-16 10:48:00,184 - --- test ---------------------
2021-11-16 10:48:00,184 - 50000 samples (256 per mini-batch)
2021-11-16 10:48:22,038 - Test: [   10/  195]    Loss 6.973532    Top1 0.039062    Top5 0.390625    
2021-11-16 10:48:40,216 - Test: [   20/  195]    Loss 6.973516    Top1 0.078125    Top5 0.449219    
2021-11-16 10:48:58,756 - Test: [   30/  195]    Loss 6.974840    Top1 0.091146    Top5 0.429687    
2021-11-16 10:49:17,150 - Test: [   40/  195]    Loss 6.973551    Top1 0.097656    Top5 0.458984    
2021-11-16 10:49:35,408 - Test: [   50/  195]    Loss 6.971762    Top1 0.117188    Top5 0.500000    
2021-11-16 10:49:53,676 - Test: [   60/  195]    Loss 6.973226    Top1 0.110677    Top5 0.501302    
2021-11-16 10:50:12,035 - Test: [   70/  195]    Loss 6.974514    Top1 0.117188    Top5 0.502232    
2021-11-16 10:50:30,281 - Test: [   80/  195]    Loss 6.973147    Top1 0.122070    Top5 0.498047    
2021-11-16 10:50:48,476 - Test: [   90/  195]    Loss 6.972226    Top1 0.117188    Top5 0.494792    
2021-11-16 10:51:06,964 - Test: [  100/  195]    Loss 6.973042    Top1 0.117188    Top5 0.480469    
2021-11-16 10:51:25,179 - Test: [  110/  195]    Loss 6.971775    Top1 0.117188    Top5 0.479403    
2021-11-16 10:51:43,528 - Test: [  120/  195]    Loss 6.971918    Top1 0.117188    Top5 0.494792    
2021-11-16 10:52:01,846 - Test: [  130/  195]    Loss 6.971726    Top1 0.114183    Top5 0.486779    
2021-11-16 10:52:20,188 - Test: [  140/  195]    Loss 6.971333    Top1 0.114397    Top5 0.499442    
2021-11-16 10:52:38,604 - Test: [  150/  195]    Loss 6.971288    Top1 0.119792    Top5 0.513021    
2021-11-16 10:52:44,706 - 
2021-11-16 10:52:44,706 - Log file for this run: /home/th.nguyen/drift-encode/logs/resnet50-imagenet-baseline___2021.11.15-224215/resnet50-imagenet-baseline___2021.11.15-224215.log
